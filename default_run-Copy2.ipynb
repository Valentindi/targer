{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_sequences_train ['miro', \"'\", 's', 'favorite', 'things', ':', 'color', ':', 'blue', 'team', 'growing', 'up', ':', 'czechoslovakian', 'national', 'team', 'player', 'growing', 'up', ':', 'mario', 'lemieux', 'arena', 'outside', 'long', 'island', ':', 'bell', 'centre', '(', 'montreal', ')', 'food', ':', 'italian', 'movie', ':', 'big', 'lebowski', 'car', ':', 'mercedes', 'benz', 'brand', 'of', 'skates', ':', 'bauer', 'brand', 'of', 'hockey', 'stick', ':', 'reebok', 'former', 'islander', ':', 'mike', 'bossy', 'board', 'game', ':', 'chess', 'sport', '(', 'other', 'than', 'hockey', '):', 'golf', 'band', ':', 'guns', 'n', \"'\", 'roses', 'vacation', 'spot', ':', 'italy', 'and', 'mexico', 'non', '-', 'north', 'american', 'city', '(', 'not', 'in', 'slovakia', '):', 'rome', 'stadium', 'food', ':', 'popcorn']\n",
      "tag_sequences_train ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-OBJ', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-OBJ', 'O', 'B-OBJ', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      " -- {'<pad>': 0, 'O': 1, 'B-OBJ': 2, 'B-PREDFULL': 3, 'I-PREDFULL': 4, 'I-OBJ': 5}\n"
     ]
    }
   ],
   "source": [
    "! python3 main.py --train \"/home/vika/targer/data/NER/Varvara_v2/train_pred_full.tsv\" --dev \"/home/vika/targer/data/NER/Varvara_v2/dev_pred_full.tsv\" --data-io connl-ner-2003 --evaluator f1-alpha-match-10 --model BiRNN --opt adam --save-best yes --patience 20 --rnn-hidden-dim 200 --gpu 2 --test \"/home/vika/targer/data/NER/Varvara_v1/test_pred_full.tsv\" --elmo False --epoch-num 50 --evaluator f1-macro --bert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_sequences_train ['i', 'have', 'always', 'heard', 'that', 'motrin', 'is', 'better', 'than', 'advil', 'for', 'fevers', ',', 'and', 'that', 'advil', 'works', 'better', 'for', 'body', 'aches', 'and', 'pains', '.']\n",
      "tag_sequences_train ['O', 'O', 'O', 'O', 'O', 'B-OBJ', 'O', 'O', 'O', 'B-OBJ', 'O', 'O', 'O', 'O', 'O', 'B-OBJ', 'O', 'B-PREDFULL', 'I-PREDFULL', 'I-PREDFULL', 'I-PREDFULL', 'I-PREDFULL', 'I-PREDFULL', 'O']\n",
      " -- {'<pad>': 0, 'O': 1, 'B-OBJ': 2, 'B-PREDFULL': 3, 'I-PREDFULL': 4, 'I-OBJ': 5}\n"
     ]
    }
   ],
   "source": [
    "! python3 main.py --train \"/home/vika/targer/data/NER/Varvara_v1/train_pred_full.tsv\" --dev \"/home/vika/targer/data/NER/Varvara_v1/dev_pred_full.tsv\" --data-io connl-ner-2003 --evaluator f1-alpha-match-10 --model BiRNN --opt adam --save-best yes --patience 20 --rnn-hidden-dim 200 --gpu 2 --test \"/home/vika/targer/data/NER/Varvara_v1/test_pred_full.tsv\" --elmo False --lr 0.00001 --epoch-num 150 --evaluator f1-macro --bert True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Oct 25 09:13:20 2019       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 390.87                 Driver Version: 390.87                    |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 108...  Off  | 00000000:05:00.0 Off |                  N/A |\n",
      "| 46%   67C    P2    66W / 250W |   3756MiB / 11170MiB |      9%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce GTX 108...  Off  | 00000000:06:00.0 Off |                  N/A |\n",
      "| 41%   61C    P2    59W / 250W |  10067MiB / 11178MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce GTX 108...  Off  | 00000000:09:00.0 Off |                  N/A |\n",
      "| 25%   44C    P8    16W / 250W |     10MiB / 11178MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  GeForce GTX 108...  Off  | 00000000:0A:00.0 Off |                  N/A |\n",
      "| 25%   44C    P8    17W / 250W |     10MiB / 11178MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([39, 55])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "эмбеддинг оставила"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " for batch_i in range(len(self.word_sequences)): #batch_size\n",
    "    token_embeddings = []\n",
    "    for token_i in range(self.tokens_tensor.shape[1]):  #number of token in batch element\n",
    "        hidden_layers = [] \n",
    "        for layer_i in range(len(encoded_layers)):\n",
    "            vec = encoded_layers[layer_i][batch_i][token_i]\n",
    "            hidden_layers.append(vec)\n",
    "        token_embeddings.append(hidden_layers)\n",
    "    summed_last_4_layers = [torch.sum(torch.stack(layer)[-4:], 0) for layer in token_embeddings]\n",
    "    summed_last_4_layers = torch.stack(summed_last_4_layers)\n",
    "    batch_embeddings.append(summed_last_4_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([39, 55, 768])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "c = torch.load('fnm.pth')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.load('answer.pth')[0]\n",
    "index = torch.load('index.pth')[0]\n",
    "self_tensor1 = torch.load('self_tensor1.pth')[0]\n",
    "token_tensor = torch.load('token_tensor.pth')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([39, 55])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6372, -1.8235,  0.1793,  5.3915, -1.2148],\n",
       "        [-0.6372, -1.8235,  0.1793,  5.3915, -1.2148],\n",
       "        [-0.6372, -1.8235,  0.1793,  5.3915, -1.2148],\n",
       "        [-0.6372, -1.8235,  0.1793,  5.3916, -1.2148],\n",
       "        [-0.6372, -1.8235,  0.1793,  5.3915, -1.2148],\n",
       "        [-0.6372, -1.8235,  0.1793,  5.3915, -1.2148],\n",
       "        [-0.6372, -1.8235,  0.1793,  5.3915, -1.2148],\n",
       "        [-0.6372, -1.8235,  0.1793,  5.3915, -1.2148],\n",
       "        [-0.6372, -1.8235,  0.1793,  5.3915, -1.2148],\n",
       "        [-0.6372, -1.8235,  0.1793,  5.3915, -1.2148],\n",
       "        [-0.6372, -1.8235,  0.1793,  5.3915, -1.2148],\n",
       "        [-0.6372, -1.8235,  0.1793,  5.3915, -1.2148],\n",
       "        [-0.6372, -1.8235,  0.1793,  5.3915, -1.2148],\n",
       "        [-0.6372, -1.8235,  0.1793,  5.3915, -1.2148],\n",
       "        [-0.6372, -1.8235,  0.1793,  5.3915, -1.2148],\n",
       "        [-0.6372, -1.8235,  0.1793,  5.3915, -1.2148],\n",
       "        [-0.6372, -1.8235,  0.1793,  5.3915, -1.2148],\n",
       "        [-0.6372, -1.8235,  0.1793,  5.3915, -1.2148],\n",
       "        [-0.6372, -1.8235,  0.1793,  5.3915, -1.2148],\n",
       "        [-0.6372, -1.8235,  0.1793,  5.3915, -1.2148],\n",
       "        [-0.6372, -1.8235,  0.1793,  5.3915, -1.2148],\n",
       "        [-0.6372, -1.8235,  0.1793,  5.3915, -1.2148],\n",
       "        [-0.6372, -1.8235,  0.1793,  5.3915, -1.2148],\n",
       "        [-0.6372, -1.8235,  0.1793,  5.3915, -1.2148],\n",
       "        [-0.6372, -1.8235,  0.1793,  5.3915, -1.2148],\n",
       "        [-0.6372, -1.8235,  0.1793,  5.3915, -1.2148],\n",
       "        [-0.6372, -1.8235,  0.1793,  5.3915, -1.2148],\n",
       "        [-0.6372, -1.8235,  0.1793,  5.3915, -1.2148],\n",
       "        [-0.6372, -1.8235,  0.1793,  5.3915, -1.2148],\n",
       "        [-0.6372, -1.8235,  0.1793,  5.3916, -1.2148],\n",
       "        [-0.6372, -1.8235,  0.1793,  5.3915, -1.2148],\n",
       "        [-0.6372, -1.8235,  0.1793,  5.3915, -1.2148],\n",
       "        [-0.6372, -1.8235,  0.1793,  5.3915, -1.2148],\n",
       "        [-0.6372, -1.8235,  0.1793,  5.3915, -1.2148],\n",
       "        [-0.6372, -1.8235,  0.1793,  5.3915, -1.2148],\n",
       "        [-0.6372, -1.8235,  0.1793,  5.3915, -1.2148],\n",
       "        [-0.6372, -1.8235,  0.1793,  5.3915, -1.2148],\n",
       "        [-0.6372, -1.8235,  0.1793,  5.3915, -1.2148],\n",
       "        [-0.6372, -1.8235,  0.1793,  5.3915, -1.2148],\n",
       "        [-0.6372, -1.8235,  0.1793,  5.3915, -1.2148],\n",
       "        [-0.6372, -1.8235,  0.1793,  5.3915, -1.2148],\n",
       "        [-0.6372, -1.8235,  0.1793,  5.3915, -1.2148],\n",
       "        [-0.6372, -1.8235,  0.1793,  5.3915, -1.2148],\n",
       "        [-0.6372, -1.8235,  0.1793,  5.3915, -1.2148],\n",
       "        [-0.6372, -1.8235,  0.1793,  5.3915, -1.2148],\n",
       "        [-0.6372, -1.8235,  0.1793,  5.3915, -1.2148],\n",
       "        [-0.6372, -1.8235,  0.1793,  5.3915, -1.2148],\n",
       "        [-0.6372, -1.8235,  0.1793,  5.3915, -1.2148],\n",
       "        [-0.6372, -1.8235,  0.1793,  5.3915, -1.2148],\n",
       "        [-0.6372, -1.8235,  0.1793,  5.3915, -1.2148],\n",
       "        [-0.6372, -1.8235,  0.1793,  5.3915, -1.2148],\n",
       "        [-0.6372, -1.8235,  0.1793,  5.3915, -1.2148],\n",
       "        [-0.6372, -1.8235,  0.1793,  5.3915, -1.2148],\n",
       "        [-0.6372, -1.8235,  0.1793,  5.3915, -1.2148],\n",
       "        [-0.6372, -1.8235,  0.1793,  5.3915, -1.2148]],\n",
       "       device='cuda:0', grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0][0,:,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0,  0,  0],\n",
       "        [ 1,  1,  1,  1,  1],\n",
       "        [ 2,  2,  2,  2,  2],\n",
       "        [ 3,  3,  3,  3,  3],\n",
       "        [ 4,  4,  4,  4,  4],\n",
       "        [ 5,  5,  5,  5,  5],\n",
       "        [ 6,  6,  6,  6,  6],\n",
       "        [ 7,  7,  7,  7,  7],\n",
       "        [ 8,  8,  8,  8,  8],\n",
       "        [ 9,  9,  9,  9,  9],\n",
       "        [10, 10, 10, 10, 10],\n",
       "        [10, 10, 10, 10, 10],\n",
       "        [10, 10, 10, 10, 10],\n",
       "        [11, 11, 11, 11, 11],\n",
       "        [12, 12, 12, 12, 12],\n",
       "        [13, 13, 13, 13, 13],\n",
       "        [14, 14, 14, 14, 14],\n",
       "        [15, 15, 15, 15, 15],\n",
       "        [16, 16, 16, 16, 16],\n",
       "        [17, 17, 17, 17, 17],\n",
       "        [18, 18, 18, 18, 18],\n",
       "        [19, 19, 19, 19, 19],\n",
       "        [20, 20, 20, 20, 20],\n",
       "        [21, 21, 21, 21, 21],\n",
       "        [22, 22, 22, 22, 22],\n",
       "        [23, 23, 23, 23, 23],\n",
       "        [24, 24, 24, 24, 24],\n",
       "        [25, 25, 25, 25, 25],\n",
       "        [26, 26, 26, 26, 26],\n",
       "        [27, 27, 27, 27, 27],\n",
       "        [28, 28, 28, 28, 28],\n",
       "        [29, 29, 29, 29, 29],\n",
       "        [30, 30, 30, 30, 30],\n",
       "        [31, 31, 31, 31, 31],\n",
       "        [32, 32, 32, 32, 32],\n",
       "        [33, 33, 33, 33, 33],\n",
       "        [34, 34, 34, 34, 34],\n",
       "        [35, 35, 35, 35, 35],\n",
       "        [36, 36, 36, 36, 36],\n",
       "        [37, 37, 37, 37, 37],\n",
       "        [38, 38, 38, 38, 38],\n",
       "        [39, 39, 39, 39, 39],\n",
       "        [39, 39, 39, 39, 39],\n",
       "        [39, 39, 39, 39, 39],\n",
       "        [39, 39, 39, 39, 39],\n",
       "        [39, 39, 39, 39, 39],\n",
       "        [39, 39, 39, 39, 39],\n",
       "        [39, 39, 39, 39, 39],\n",
       "        [39, 39, 39, 39, 39],\n",
       "        [39, 39, 39, 39, 39],\n",
       "        [39, 39, 39, 39, 39],\n",
       "        [39, 39, 39, 39, 39],\n",
       "        [39, 39, 39, 39, 39],\n",
       "        [39, 39, 39, 39, 39],\n",
       "        [39, 39, 39, 39, 39]], device='cuda:0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0][0,:,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Oct 23 08:24:50 2019       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 390.87                 Driver Version: 390.87                    |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 108...  Off  | 00000000:05:00.0 Off |                  N/A |\n",
      "| 36%   56C    P8    19W / 250W |   1169MiB / 11170MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce GTX 108...  Off  | 00000000:06:00.0 Off |                  N/A |\n",
      "| 47%   69C    P2    62W / 250W |   5405MiB / 11178MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce GTX 108...  Off  | 00000000:09:00.0 Off |                  N/A |\n",
      "| 53%   74C    P2    77W / 250W |   1412MiB / 11178MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  GeForce GTX 108...  Off  | 00000000:0A:00.0 Off |                  N/A |\n",
      "| 68%   83C    P2   227W / 250W |   8938MiB / 11178MiB |     99%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2017 NVIDIA Corporation\n",
      "Built on Fri_Sep__1_21:08:03_CDT_2017\n",
      "Cuda compilation tools, release 9.0, V9.0.176\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'python'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-44328987fa11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_dim_ordering\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'python'"
     ]
    }
   ],
   "source": [
    "tensorflow.python.keras.backend.image_dim_ordering()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Oct 13 23:41:19 2019       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 390.87                 Driver Version: 390.87                    |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 108...  Off  | 00000000:05:00.0 Off |                  N/A |\n",
      "| 46%   67C    P8    21W / 250W |   2301MiB / 11170MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce GTX 108...  Off  | 00000000:06:00.0 Off |                  N/A |\n",
      "| 84%   90C    P2   100W / 250W |   8247MiB / 11178MiB |    100%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce GTX 108...  Off  | 00000000:09:00.0 Off |                  N/A |\n",
      "| 80%   89C    P2   176W / 250W |   8235MiB / 11178MiB |    100%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  GeForce GTX 108...  Off  | 00000000:0A:00.0 Off |                  N/A |\n",
      "| 80%   87C    P2   153W / 250W |   8439MiB / 11178MiB |    100%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4])\n",
      "torch.Size([4, 4])\n",
      "tensor([[1., 2., 3., 4.],\n",
      "        [1., 2., 3., 4.],\n",
      "        [1., 2., 3., 3.],\n",
      "        [0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "seq = torch.Tensor([[1,2,3, 4], [1,2,3, 4], [1,2,3, 3]]) \n",
    "print (seq.shape)# seq of variable length\n",
    "seq = F.pad(seq, pad=(0, 0, 0, 1), mode='constant', value=0)\n",
    "print (seq.shape)\n",
    "print (seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "unexpected EOF. The file might be corrupted.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-fef9fb09cc25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmask_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mask_tensor.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module)\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_fd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(f, map_location, pickle_module)\u001b[0m\n\u001b[1;32m    547\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdeserialized_storage_keys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdeserialized_objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mdeserialized_objects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_from_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_should_read_directly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m         \u001b[0moffset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: unexpected EOF. The file might be corrupted."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "mask_tensor = torch.load(\"mask_tensor.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "self_tensor = F.pad(self_tensor, [0,0,0,1,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Invalid index in scatterAdd at /pytorch/aten/src/TH/generic/THTensorMath.cpp:680",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-d307cb02ff22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mself_tensor1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mscatter_add\u001b[0;34m(self, dim, index, source)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mscatter_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter_add_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmasked_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Invalid index in scatterAdd at /pytorch/aten/src/TH/generic/THTensorMath.cpp:680"
     ]
    }
   ],
   "source": [
    "self_tensor1 = self_tensor.scatter_add(1, index[..., None], answer)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "index 44 is out of bounds for dimension 0 with size 10",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-eca28e03bb41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mself_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: index 44 is out of bounds for dimension 0 with size 10"
     ]
    }
   ],
   "source": [
    "self_tensor[index, :] = answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "t = torch.tensor([[1,2],[3,4]])\n",
    "r = torch.gather(t, 0, torch.tensor([[0,0],[1,0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 2]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self shape  torch.Size([2, 4])\n",
      "indexes shape  torch.Size([2, 4])\n",
      "source  torch.Size([2, 5])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.,  2.,  3.,  1.],\n",
       "        [14.,  9.,  6.,  1.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.tensor([[0, 1, 2, 3, 4], [5, 6, 7, 8, 9]]).float()\n",
    "\n",
    "a = torch.ones(2, 4)\n",
    "\n",
    "\n",
    "indexes = torch.tensor([[0, 1, 2, 0], [2, 0, 0, 1]])\n",
    "print (\"self shape \", a.shape)\n",
    "print (\"indexes shape \", indexes.shape)\n",
    "print (\"source \", x.shape)\n",
    "a.scatter_add_(1, torch.tensor([[0, 1, 2, 0], [2, 0, 0, 1]]), x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: export: en_US.UTF-8: bad variable name\n"
     ]
    }
   ],
   "source": [
    "!export LC_ALL= en_US.UTF-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "unsupported locale setting",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-133cbb354620>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlocale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetlocale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLC_ALL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'en_US.UTF-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/locale.py\u001b[0m in \u001b[0;36msetlocale\u001b[0;34m(category, locale)\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0;31m# convert to string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0mlocale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_build_localename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_setlocale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mresetlocale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLC_ALL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mError\u001b[0m: unsupported locale setting"
     ]
    }
   ],
   "source": [
    "locale.setlocale(locale.LC_ALL, str('en_US.UTF-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "unsupported locale setting",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-dd5e8ee5bb02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlocale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetlocale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLC_ALL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'es_ES.UTF8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/locale.py\u001b[0m in \u001b[0;36msetlocale\u001b[0;34m(category, locale)\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0;31m# convert to string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0mlocale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_build_localename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_setlocale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mresetlocale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLC_ALL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mError\u001b[0m: unsupported locale setting"
     ]
    }
   ],
   "source": [
    "locale.setlocale(locale.LC_ALL, 'es_ES.UTF8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export LC_ALL=\"en_US.UTF-8\"\n",
    "!export LC_CTYPE=\"en_US.UTF-8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preço\n"
     ]
    }
   ],
   "source": [
    "print(\"preço\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/sbin/dpkg-reconfigure must be run as root\n"
     ]
    }
   ],
   "source": [
    "!dpkg-reconfigure locales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "LANG=\"en_US.UTF-8\"\n",
    "LANGUAGE=\"en_US:en\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LANG=\n",
      "LANGUAGE=\n",
      "LC_CTYPE=\"POSIX\"\n",
      "LC_NUMERIC=\"POSIX\"\n",
      "LC_TIME=\"POSIX\"\n",
      "LC_COLLATE=\"POSIX\"\n",
      "LC_MONETARY=\"POSIX\"\n",
      "LC_MESSAGES=\"POSIX\"\n",
      "LC_PAPER=\"POSIX\"\n",
      "LC_NAME=\"POSIX\"\n",
      "LC_ADDRESS=\"POSIX\"\n",
      "LC_TELEPHONE=\"POSIX\"\n",
      "LC_MEASUREMENT=\"POSIX\"\n",
      "LC_IDENTIFICATION=\"POSIX\"\n",
      "LC_ALL=\n"
     ]
    }
   ],
   "source": [
    "!locale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export LANG=en_US.UTF-8 LC_ALL=en_US.UTF-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C\n",
      "C.UTF-8\n",
      "POSIX\n"
     ]
    }
   ],
   "source": [
    "!locale -a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export LANG=en_US.UTF-8 LANGUAGE=en_US.en LC_ALL=en_US.UTF-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading vocabulary file rr\n"
     ]
    }
   ],
   "source": [
    " print (\"loading vocabulary file %s\"%a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
    "from src.tokenizers import tokenizer_custom_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading vocabulary file /home/vika/targer/pretrained/uncased_L-12_H-768_A-12/vocab.txt\n",
      "resolved voc file /home/vika/targer/pretrained/uncased_L-12_H-768_A-12/vocab.txt\n"
     ]
    }
   ],
   "source": [
    "a = tokenizer_custom_bert.BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1tb of mechanical storage is n't bad , mini-wan but toshiba hard drives really are n't what we want to be seeing as they tend to be a bit slower than competing drives from hgst , western digital , samsung , and seagate .  amazon is another good choice , and i actually prefer their interface better than itunes\n",
      "2 1tb of mechanical storage is n't bad , mini-wan but toshiba hard drives really are n't what we want to be seeing as they tend to be a bit slower than competing drives from hgst , western digital , samsung , and seagate .  amazon is another good choice , and i actually prefer their interface better than itunes\n",
      "3 ['1tb', 'of', 'mechanical', 'storage', 'is', \"n't\", 'bad', ',', 'mini-wan', 'but', 'toshiba', 'hard', 'drives', 'really', 'are', \"n't\", 'what', 'we', 'want', 'to', 'be', 'seeing', 'as', 'they', 'tend', 'to', 'be', 'a', 'bit', 'slower', 'than', 'competing', 'drives', 'from', 'hgst', ',', 'western', 'digital', ',', 'samsung', ',', 'and', 'seagate', '.', 'amazon', 'is', 'another', 'good', 'choice', ',', 'and', 'i', 'actually', 'prefer', 'their', 'interface', 'better', 'than', 'itunes']\n",
      "5 ['1tb', 'of', 'mechanical', 'storage', 'is', \"n't\", 'bad', ',', 'mini-wan', 'but', 'toshiba', 'hard', 'drives', 'really', 'are', \"n't\", 'what', 'we', 'want', 'to', 'be', 'seeing', 'as', 'they', 'tend', 'to', 'be', 'a', 'bit', 'slower', 'than', 'competing', 'drives', 'from', 'hgst', ',', 'western', 'digital', ',', 'samsung', ',', 'and', 'seagate', '.', 'amazon', 'is', 'another', 'good', 'choice', ',', 'and', 'i', 'actually', 'prefer', 'their', 'interface', 'better', 'than', 'itunes']\n",
      "5 ['1tb', 'of', 'mechanical', 'storage', 'is', \"n't\", 'bad', ',', 'mini-wan', 'but', 'toshiba', 'hard', 'drives', 'really', 'are', \"n't\", 'what', 'we', 'want', 'to', 'be', 'seeing', 'as', 'they', 'tend', 'to', 'be', 'a', 'bit', 'slower', 'than', 'competing', 'drives', 'from', 'hgst', ',', 'western', 'digital', ',', 'samsung', ',', 'and', 'seagate', '.', 'amazon', 'is', 'another', 'good', 'choice', ',', 'and', 'i', 'actually', 'prefer', 'their', 'interface', 'better', 'than', 'itunes']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " '##t',\n",
       " '##b',\n",
       " 'of',\n",
       " 'mechanical',\n",
       " 'storage',\n",
       " 'is',\n",
       " 'n',\n",
       " \"##'\",\n",
       " '##t',\n",
       " 'bad',\n",
       " ',',\n",
       " 'mini',\n",
       " '##-',\n",
       " '##wan',\n",
       " 'but',\n",
       " 'to',\n",
       " '##shi',\n",
       " '##ba',\n",
       " 'hard',\n",
       " 'drives',\n",
       " 'really',\n",
       " 'are',\n",
       " 'n',\n",
       " \"##'\",\n",
       " '##t',\n",
       " 'what',\n",
       " 'we',\n",
       " 'want',\n",
       " 'to',\n",
       " 'be',\n",
       " 'seeing',\n",
       " 'as',\n",
       " 'they',\n",
       " 'tend',\n",
       " 'to',\n",
       " 'be',\n",
       " 'a',\n",
       " 'bit',\n",
       " 'slower',\n",
       " 'than',\n",
       " 'competing',\n",
       " 'drives',\n",
       " 'from',\n",
       " 'h',\n",
       " '##gs',\n",
       " '##t',\n",
       " ',',\n",
       " 'western',\n",
       " 'digital',\n",
       " ',',\n",
       " 'samsung',\n",
       " ',',\n",
       " 'and',\n",
       " 'sea',\n",
       " '##gate',\n",
       " '.',\n",
       " 'amazon',\n",
       " 'is',\n",
       " 'another',\n",
       " 'good',\n",
       " 'choice',\n",
       " ',',\n",
       " 'and',\n",
       " 'i',\n",
       " 'actually',\n",
       " 'prefer',\n",
       " 'their',\n",
       " 'interface',\n",
       " 'better',\n",
       " 'than',\n",
       " 'itunes']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"1tb of mechanical storage is n't bad , mini-wan but toshiba hard drives really are n't what we want to be seeing as they tend to be a bit slower than competing drives from hgst , western digital , samsung , and seagate .  amazon is another good choice , and i actually prefer their interface better than itunes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_b = BasicTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "args train = /home/vika/targer/data/NER/Varvara/train.csv\n",
      "Loading from /home/vika/targer/data/NER/Varvara/train.csv: 2433 samples, 68029 words.\n",
      "Loading from /home/vika/targer/data/NER/Varvara/dev.csv: 358 samples, 9091 words.\n",
      "Loading from /home/vika/targer/data/NER/Varvara/test.csv: 369 samples, 10163 words.\n",
      "DatasetsBank: len(unique_words_list) = 7276 unique words.\n",
      "DatasetsBank: len(unique_words_list) = 8004 unique words.\n",
      "DatasetsBank: len(unique_words_list) = 8570 unique words.\n",
      "qu True\n",
      "True\n",
      "False\n",
      "2\n",
      "create seq indexer elmo!\n",
      "\n",
      "load_vocabulary_from_tag_sequences:\n",
      " -- class_num = 5\n",
      " -- {'<pad>': 0, 'O': 1, 'B-OBJ': 2, 'B-PREDFULL': 3, 'I-PREDFULL': 4, 'I-OBJ': 5}\n",
      "LayerContextWordEmbeddings init\n",
      "\n",
      "Start training...\n",
      "\n",
      "\n",
      "\n",
      "++ predicting, batch 243/243 (100.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 4.93, precision = 4.06, recall = 6.27\n",
      "     B-PREDFULL = f1 = 2.70, precision = 1.38, recall = 60.95\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 0.23, precision = 0.12, recall = 5.23\n",
      "              O = f1 = 10.29, precision = 87.75, recall = 5.46\n",
      "------------------------\n",
      "Macro-F1 = 3.630Macro-Prescion = 18.662Macro-Recall = 15.583\n",
      "\n",
      "\n",
      "++ predicting, batch 35/35 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 1.60, precision = 1.87, recall = 1.39\n",
      "     B-PREDFULL = f1 = 2.79, precision = 1.42, recall = 65.06\n",
      "          I-OBJ = f1 = 0.08, precision = 0.04, recall = 100.00\n",
      "     I-PREDFULL = f1 = 0.48, precision = 0.25, recall = 8.33\n",
      "              O = f1 = 6.53, precision = 95.17, recall = 3.38\n",
      "------------------------\n",
      "Macro-F1 = 2.297Macro-Prescion = 19.751Macro-Recall = 35.634\n",
      "\n",
      "\n",
      "++ predicting, batch 36/36 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 7.68, precision = 6.04, recall = 10.54\n",
      "     B-PREDFULL = f1 = 3.00, precision = 1.53, recall = 71.96\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 0.54, precision = 0.28, recall = 8.16\n",
      "              O = f1 = 4.17, precision = 85.59, recall = 2.14\n",
      "------------------------\n",
      "Macro-F1 = 3.077Macro-Prescion = 18.687Macro-Recall = 18.561\n",
      "\n",
      "== eval epoch 0/100 \"f1-macro\" train / dev / test | 3.63 / 2.30 / 3.08.\n",
      "## [BEST epoch], 51 seconds.\n",
      "\n",
      "-- train epoch 1/100, batch 243/243 (100.00%), loss = 15.63.\n",
      "\n",
      "++ predicting, batch 243/243 (100.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 84.15, precision = 81.93, recall = 86.49\n",
      "     B-PREDFULL = f1 = 53.47, precision = 46.09, recall = 63.65\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 44.82, precision = 32.42, recall = 72.62\n",
      "              O = f1 = 97.53, precision = 98.27, recall = 96.80\n",
      "------------------------\n",
      "Macro-F1 = 55.994Macro-Prescion = 51.742Macro-Recall = 63.912\n",
      "\n",
      "\n",
      "++ predicting, batch 35/35 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 53.37, precision = 72.71, recall = 42.15\n",
      "     B-PREDFULL = f1 = 50.00, precision = 41.60, recall = 62.65\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 63.91, precision = 49.54, recall = 90.00\n",
      "              O = f1 = 95.48, precision = 94.11, recall = 96.90\n",
      "------------------------\n",
      "Macro-F1 = 52.551Macro-Prescion = 51.591Macro-Recall = 58.340\n",
      "\n",
      "\n",
      "++ predicting, batch 36/36 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 61.64, precision = 79.35, recall = 50.39\n",
      "     B-PREDFULL = f1 = 50.91, precision = 49.56, recall = 52.34\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 59.85, precision = 46.59, recall = 83.67\n",
      "              O = f1 = 96.18, precision = 94.66, recall = 97.76\n",
      "------------------------\n",
      "Macro-F1 = 53.717Macro-Prescion = 54.031Macro-Recall = 56.832\n",
      "\n",
      "== eval epoch 1/100 \"f1-macro\" train / dev / test | 55.99 / 52.55 / 53.72.\n",
      "## [BEST epoch], 94 seconds.\n",
      "\n",
      "-- train epoch 2/100, batch 243/243 (100.00%), loss = 7.99.\n",
      "\n",
      "++ predicting, batch 243/243 (100.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 86.71, precision = 85.11, recall = 88.37\n",
      "     B-PREDFULL = f1 = 24.90, precision = 75.20, recall = 14.92\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 25.84, precision = 80.65, recall = 15.38\n",
      "              O = f1 = 98.14, precision = 97.68, recall = 98.60\n",
      "------------------------\n",
      "Macro-F1 = 47.117Macro-Prescion = 67.727Macro-Recall = 43.454\n",
      "\n",
      "\n",
      "++ predicting, batch 35/35 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 51.02, precision = 72.06, recall = 39.49\n",
      "     B-PREDFULL = f1 = 22.92, precision = 84.62, recall = 13.25\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 18.18, precision = 100.00, recall = 10.00\n",
      "              O = f1 = 95.67, precision = 93.00, recall = 98.49\n",
      "------------------------\n",
      "Macro-F1 = 37.557Macro-Prescion = 69.934Macro-Recall = 32.248\n",
      "\n",
      "\n",
      "++ predicting, batch 36/36 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 68.50, precision = 81.16, recall = 59.25\n",
      "     B-PREDFULL = f1 = 19.05, precision = 63.16, recall = 11.21\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 14.81, precision = 80.00, recall = 8.16\n",
      "              O = f1 = 96.62, precision = 94.58, recall = 98.75\n",
      "------------------------\n",
      "Macro-F1 = 39.796Macro-Prescion = 63.779Macro-Recall = 35.476\n",
      "\n",
      "== eval epoch 2/100 \"f1-macro\" train / dev / test | 47.12 / 37.56 / 39.80.\n",
      "## [no improvement micro-f1 on DEV during the last 1 epochs (best_f1_dev=52.55), 91 seconds].\n",
      "\n",
      "-- train epoch 3/100, batch 243/243 (100.00%), loss = 6.37.\n",
      "\n",
      "++ predicting, batch 243/243 (100.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 89.77, precision = 87.21, recall = 92.48\n",
      "     B-PREDFULL = f1 = 54.14, precision = 65.39, recall = 46.19\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 44.00, precision = 29.40, recall = 87.38\n",
      "              O = f1 = 98.09, precision = 98.70, recall = 97.48\n",
      "------------------------\n",
      "Macro-F1 = 57.198Macro-Prescion = 56.141Macro-Recall = 64.707\n",
      "\n",
      "\n",
      "++ predicting, batch 35/35 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 56.35, precision = 75.53, recall = 44.94\n",
      "     B-PREDFULL = f1 = 50.00, precision = 53.42, recall = 46.99\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 58.82, precision = 41.67, recall = 100.00\n",
      "              O = f1 = 95.77, precision = 94.36, recall = 97.22\n",
      "------------------------\n",
      "Macro-F1 = 52.188Macro-Prescion = 52.997Macro-Recall = 57.828\n",
      "\n",
      "\n",
      "++ predicting, batch 36/36 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 69.24, precision = 81.79, recall = 60.03\n",
      "     B-PREDFULL = f1 = 43.93, precision = 57.58, recall = 35.51\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 54.55, precision = 38.79, recall = 91.84\n",
      "              O = f1 = 96.52, precision = 95.27, recall = 97.80\n",
      "------------------------\n",
      "Macro-F1 = 52.846Macro-Prescion = 54.685Macro-Recall = 57.035\n",
      "\n",
      "== eval epoch 3/100 \"f1-macro\" train / dev / test | 57.20 / 52.19 / 52.85.\n",
      "## [no improvement micro-f1 on DEV during the last 2 epochs (best_f1_dev=52.55), 88 seconds].\n",
      "\n",
      "-- train epoch 4/100, batch 243/243 (100.00%), loss = 6.29.\n",
      "\n",
      "++ predicting, batch 243/243 (100.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 89.27, precision = 82.20, recall = 97.67\n",
      "     B-PREDFULL = f1 = 40.18, precision = 71.54, recall = 27.94\n",
      "          I-OBJ = f1 = 50.00, precision = 100.00, recall = 33.33\n",
      "     I-PREDFULL = f1 = 41.93, precision = 96.67, recall = 26.77\n",
      "              O = f1 = 98.36, precision = 98.66, recall = 98.07\n",
      "------------------------\n",
      "Macro-F1 = 63.950Macro-Prescion = 89.816Macro-Recall = 56.756\n",
      "\n",
      "\n",
      "++ predicting, batch 35/35 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 68.04, precision = 74.25, recall = 62.78\n",
      "     B-PREDFULL = f1 = 19.80, precision = 55.56, recall = 12.05\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 9.52, precision = 100.00, recall = 5.00\n",
      "              O = f1 = 96.35, precision = 94.94, recall = 97.79\n",
      "------------------------\n",
      "Macro-F1 = 38.742Macro-Prescion = 64.950Macro-Recall = 35.525\n",
      "\n",
      "\n",
      "++ predicting, batch 36/36 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 76.56, precision = 74.91, recall = 78.28\n",
      "     B-PREDFULL = f1 = 17.19, precision = 52.38, recall = 10.28\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "              O = f1 = 96.79, precision = 95.97, recall = 97.63\n",
      "------------------------\n",
      "Macro-F1 = 38.107Macro-Prescion = 44.651Macro-Recall = 37.238\n",
      "\n",
      "== eval epoch 4/100 \"f1-macro\" train / dev / test | 63.95 / 38.74 / 38.11.\n",
      "## [no improvement micro-f1 on DEV during the last 3 epochs (best_f1_dev=52.55), 91 seconds].\n",
      "\n",
      "-- train epoch 5/100, batch 243/243 (100.00%), loss = 5.81.\n",
      "\n",
      "++ predicting, batch 243/243 (100.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 93.37, precision = 90.29, recall = 96.66\n",
      "     B-PREDFULL = f1 = 36.12, precision = 76.41, recall = 23.65\n",
      "          I-OBJ = f1 = 80.00, precision = 100.00, recall = 66.67\n",
      "     I-PREDFULL = f1 = 48.21, precision = 87.80, recall = 33.23\n",
      "              O = f1 = 98.80, precision = 98.59, recall = 99.01\n",
      "------------------------\n",
      "Macro-F1 = 71.300Macro-Prescion = 90.618Macro-Recall = 63.844\n",
      "\n",
      "\n",
      "++ predicting, batch 35/35 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 39.89, precision = 74.65, recall = 27.22\n",
      "     B-PREDFULL = f1 = 11.24, precision = 83.33, recall = 6.02\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 12.50, precision = 100.00, recall = 6.67\n",
      "              O = f1 = 95.37, precision = 91.93, recall = 99.09\n",
      "------------------------\n",
      "Macro-F1 = 31.800Macro-Prescion = 69.982Macro-Recall = 27.800\n",
      "\n",
      "\n",
      "++ predicting, batch 36/36 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 62.61, precision = 83.01, recall = 50.26\n",
      "     B-PREDFULL = f1 = 11.11, precision = 36.84, recall = 6.54\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "              O = f1 = 96.34, precision = 93.82, recall = 99.00\n",
      "------------------------\n",
      "Macro-F1 = 34.012Macro-Prescion = 42.735Macro-Recall = 31.159\n",
      "\n",
      "== eval epoch 5/100 \"f1-macro\" train / dev / test | 71.30 / 31.80 / 34.01.\n",
      "## [no improvement micro-f1 on DEV during the last 4 epochs (best_f1_dev=52.55), 95 seconds].\n",
      "\n",
      "-- train epoch 6/100, batch 243/243 (100.00%), loss = 5.14.\n",
      "\n",
      "++ predicting, batch 243/243 (100.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 94.32, precision = 94.37, recall = 94.28\n",
      "     B-PREDFULL = f1 = 68.17, precision = 64.67, recall = 72.06\n",
      "          I-OBJ = f1 = 69.57, precision = 100.00, recall = 53.33\n",
      "     I-PREDFULL = f1 = 65.82, precision = 60.62, recall = 72.00\n",
      "              O = f1 = 98.97, precision = 99.07, recall = 98.87\n",
      "------------------------\n",
      "Macro-F1 = 79.369Macro-Prescion = 83.745Macro-Recall = 78.109\n",
      "\n",
      "\n",
      "++ predicting, batch 35/35 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 27.15, precision = 74.86, recall = 16.58\n",
      "     B-PREDFULL = f1 = 55.29, precision = 54.02, recall = 56.63\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 66.67, precision = 72.55, recall = 61.67\n",
      "              O = f1 = 95.18, precision = 91.81, recall = 98.80\n",
      "------------------------\n",
      "Macro-F1 = 48.857Macro-Prescion = 58.648Macro-Recall = 46.735\n",
      "\n",
      "\n",
      "++ predicting, batch 36/36 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 50.00, precision = 83.23, recall = 35.73\n",
      "     B-PREDFULL = f1 = 64.17, precision = 57.89, recall = 71.96\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 59.52, precision = 71.43, recall = 51.02\n",
      "              O = f1 = 96.09, precision = 93.63, recall = 98.68\n",
      "------------------------\n",
      "Macro-F1 = 53.956Macro-Prescion = 61.238Macro-Recall = 51.479\n",
      "\n",
      "== eval epoch 6/100 \"f1-macro\" train / dev / test | 79.37 / 48.86 / 53.96.\n",
      "## [no improvement micro-f1 on DEV during the last 5 epochs (best_f1_dev=52.55), 94 seconds].\n",
      "\n",
      "-- train epoch 7/100, batch 243/243 (100.00%), loss = 4.23.\n",
      "\n",
      "++ predicting, batch 243/243 (100.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 93.69, precision = 93.16, recall = 94.22\n",
      "     B-PREDFULL = f1 = 64.60, precision = 66.44, recall = 62.86\n",
      "          I-OBJ = f1 = 75.00, precision = 100.00, recall = 60.00\n",
      "     I-PREDFULL = f1 = 70.94, precision = 58.48, recall = 90.15\n",
      "              O = f1 = 98.90, precision = 99.06, recall = 98.74\n",
      "------------------------\n",
      "Macro-F1 = 80.626Macro-Prescion = 83.428Macro-Recall = 81.195\n",
      "\n",
      "\n",
      "++ predicting, batch 35/35 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 47.34, precision = 78.99, recall = 33.80\n",
      "     B-PREDFULL = f1 = 52.02, precision = 50.00, recall = 54.22\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 75.00, precision = 61.96, recall = 95.00\n",
      "              O = f1 = 95.73, precision = 93.42, recall = 98.16\n",
      "------------------------\n",
      "Macro-F1 = 54.019Macro-Prescion = 56.874Macro-Recall = 56.235\n",
      "\n",
      "\n",
      "++ predicting, batch 36/36 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 64.64, precision = 82.31, recall = 53.21\n",
      "     B-PREDFULL = f1 = 58.22, precision = 58.49, recall = 57.94\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 65.04, precision = 54.05, recall = 81.63\n",
      "              O = f1 = 96.55, precision = 94.96, recall = 98.20\n",
      "------------------------\n",
      "Macro-F1 = 56.889Macro-Prescion = 57.962Macro-Recall = 58.198\n",
      "\n",
      "== eval epoch 7/100 \"f1-macro\" train / dev / test | 80.63 / 54.02 / 56.89.\n",
      "## [BEST epoch], 90 seconds.\n",
      "\n",
      "-- train epoch 8/100, batch 243/243 (100.00%), loss = 3.81.\n",
      "\n",
      "++ predicting, batch 243/243 (100.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 95.25, precision = 94.32, recall = 96.21\n",
      "     B-PREDFULL = f1 = 57.65, precision = 77.13, recall = 46.03\n",
      "          I-OBJ = f1 = 92.86, precision = 100.00, recall = 86.67\n",
      "     I-PREDFULL = f1 = 67.20, precision = 59.11, recall = 77.85\n",
      "              O = f1 = 99.04, precision = 99.01, recall = 99.08\n",
      "------------------------\n",
      "Macro-F1 = 82.401Macro-Prescion = 85.913Macro-Recall = 81.167\n",
      "\n",
      "\n",
      "++ predicting, batch 35/35 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 49.91, precision = 81.61, recall = 35.95\n",
      "     B-PREDFULL = f1 = 43.08, precision = 59.57, recall = 33.73\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 58.82, precision = 48.39, recall = 75.00\n",
      "              O = f1 = 95.78, precision = 93.29, recall = 98.39\n",
      "------------------------\n",
      "Macro-F1 = 49.518Macro-Prescion = 56.573Macro-Recall = 48.616\n",
      "\n",
      "\n",
      "++ predicting, batch 36/36 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 64.03, precision = 86.27, recall = 50.90\n",
      "     B-PREDFULL = f1 = 34.94, precision = 49.15, recall = 27.10\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 57.94, precision = 53.45, recall = 63.27\n",
      "              O = f1 = 96.48, precision = 94.37, recall = 98.69\n",
      "------------------------\n",
      "Macro-F1 = 50.678Macro-Prescion = 56.649Macro-Recall = 47.992\n",
      "\n",
      "== eval epoch 8/100 \"f1-macro\" train / dev / test | 82.40 / 49.52 / 50.68.\n",
      "## [no improvement micro-f1 on DEV during the last 1 epochs (best_f1_dev=54.02), 89 seconds].\n",
      "\n",
      "-- train epoch 9/100, batch 243/243 (100.00%), loss = 3.36.\n",
      "\n",
      "++ predicting, batch 243/243 (100.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 95.93, precision = 93.72, recall = 98.26\n",
      "     B-PREDFULL = f1 = 67.24, precision = 61.53, recall = 74.13\n",
      "          I-OBJ = f1 = 92.86, precision = 100.00, recall = 86.67\n",
      "     I-PREDFULL = f1 = 75.17, precision = 82.66, recall = 68.92\n",
      "              O = f1 = 99.15, precision = 99.42, recall = 98.89\n",
      "------------------------\n",
      "Macro-F1 = 86.071Macro-Prescion = 87.465Macro-Recall = 85.372\n",
      "\n",
      "\n",
      "++ predicting, batch 35/35 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 32.43, precision = 68.29, recall = 21.27\n",
      "     B-PREDFULL = f1 = 53.33, precision = 49.48, recall = 57.83\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 37.65, precision = 64.00, recall = 26.67\n",
      "              O = f1 = 95.04, precision = 91.95, recall = 98.33\n",
      "------------------------\n",
      "Macro-F1 = 43.690Macro-Prescion = 54.746Macro-Recall = 40.819\n",
      "\n",
      "\n",
      "++ predicting, batch 36/36 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 58.25, precision = 81.34, recall = 45.37\n",
      "     B-PREDFULL = f1 = 58.01, precision = 54.03, recall = 62.62\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 38.46, precision = 51.72, recall = 30.61\n",
      "              O = f1 = 96.20, precision = 94.14, recall = 98.34\n",
      "------------------------\n",
      "Macro-F1 = 50.183Macro-Prescion = 56.247Macro-Recall = 47.389\n",
      "\n",
      "== eval epoch 9/100 \"f1-macro\" train / dev / test | 86.07 / 43.69 / 50.18.\n",
      "## [no improvement micro-f1 on DEV during the last 2 epochs (best_f1_dev=54.02), 88 seconds].\n",
      "\n",
      "-- train epoch 10/100, batch 243/243 (100.00%), loss = 2.19.\n",
      "\n",
      "++ predicting, batch 243/243 (100.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 95.51, precision = 94.71, recall = 96.32\n",
      "     B-PREDFULL = f1 = 54.47, precision = 86.81, recall = 39.68\n",
      "          I-OBJ = f1 = 80.00, precision = 100.00, recall = 66.67\n",
      "     I-PREDFULL = f1 = 59.78, precision = 99.29, recall = 42.77\n",
      "              O = f1 = 99.12, precision = 98.77, recall = 99.47\n",
      "------------------------\n",
      "Macro-F1 = 77.776Macro-Prescion = 95.913Macro-Recall = 68.983\n",
      "\n",
      "\n",
      "++ predicting, batch 35/35 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 48.08, precision = 77.09, recall = 34.94\n",
      "     B-PREDFULL = f1 = 18.75, precision = 69.23, recall = 10.84\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 15.38, precision = 100.00, recall = 8.33\n",
      "              O = f1 = 95.67, precision = 92.61, recall = 98.95\n",
      "------------------------\n",
      "Macro-F1 = 35.578Macro-Prescion = 67.787Macro-Recall = 30.612\n",
      "\n",
      "\n",
      "++ predicting, batch 36/36 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 62.62, precision = 81.02, recall = 51.03\n",
      "     B-PREDFULL = f1 = 44.57, precision = 57.35, recall = 36.45\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "              O = f1 = 96.36, precision = 94.17, recall = 98.66\n",
      "------------------------\n",
      "Macro-F1 = 40.710Macro-Prescion = 46.508Macro-Recall = 37.227\n",
      "\n",
      "== eval epoch 10/100 \"f1-macro\" train / dev / test | 77.78 / 35.58 / 40.71.\n",
      "## [no improvement micro-f1 on DEV during the last 3 epochs (best_f1_dev=54.02), 89 seconds].\n",
      "\n",
      "-- train epoch 11/100, batch 243/243 (100.00%), loss = 3.33.\n",
      "\n",
      "++ predicting, batch 243/243 (100.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 95.90, precision = 96.79, recall = 95.03\n",
      "     B-PREDFULL = f1 = 73.51, precision = 71.58, recall = 75.56\n",
      "          I-OBJ = f1 = 80.00, precision = 100.00, recall = 66.67\n",
      "     I-PREDFULL = f1 = 79.46, precision = 87.73, recall = 72.62\n",
      "              O = f1 = 99.27, precision = 99.17, recall = 99.37\n",
      "------------------------\n",
      "Macro-F1 = 85.630Macro-Prescion = 91.055Macro-Recall = 81.847\n",
      "\n",
      "\n",
      "++ predicting, batch 35/35 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 20.67, precision = 69.06, recall = 12.15\n",
      "     B-PREDFULL = f1 = 45.21, precision = 52.38, recall = 39.76\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 49.41, precision = 84.00, recall = 35.00\n",
      "              O = f1 = 94.94, precision = 91.16, recall = 99.06\n",
      "------------------------\n",
      "Macro-F1 = 42.045Macro-Prescion = 59.320Macro-Recall = 37.193\n",
      "\n",
      "\n",
      "++ predicting, batch 36/36 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 27.83, precision = 72.43, recall = 17.22\n",
      "     B-PREDFULL = f1 = 51.35, precision = 49.57, recall = 53.27\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 33.77, precision = 46.43, recall = 26.53\n",
      "              O = f1 = 95.18, precision = 91.95, recall = 98.65\n",
      "------------------------\n",
      "Macro-F1 = 41.625Macro-Prescion = 52.075Macro-Recall = 39.135\n",
      "\n",
      "== eval epoch 11/100 \"f1-macro\" train / dev / test | 85.63 / 42.05 / 41.63.\n",
      "## [no improvement micro-f1 on DEV during the last 4 epochs (best_f1_dev=54.02), 87 seconds].\n",
      "\n",
      "-- train epoch 12/100, batch 243/243 (100.00%), loss = 2.49.\n",
      "\n",
      "++ predicting, batch 243/243 (100.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 96.45, precision = 95.58, recall = 97.34\n",
      "     B-PREDFULL = f1 = 79.23, precision = 71.78, recall = 88.41\n",
      "          I-OBJ = f1 = 88.89, precision = 100.00, recall = 80.00\n",
      "     I-PREDFULL = f1 = 80.34, precision = 90.38, recall = 72.31\n",
      "              O = f1 = 99.36, precision = 99.50, recall = 99.22\n",
      "------------------------\n",
      "Macro-F1 = 88.855Macro-Prescion = 91.449Macro-Recall = 87.455\n",
      "\n",
      "\n",
      "++ predicting, batch 35/35 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 30.23, precision = 72.25, recall = 19.11\n",
      "     B-PREDFULL = f1 = 51.09, precision = 46.53, recall = 56.63\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 48.19, precision = 86.96, recall = 33.33\n",
      "              O = f1 = 95.09, precision = 91.82, recall = 98.59\n",
      "------------------------\n",
      "Macro-F1 = 44.919Macro-Prescion = 59.513Macro-Recall = 41.533\n",
      "\n",
      "\n",
      "++ predicting, batch 36/36 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 42.99, precision = 76.14, recall = 29.95\n",
      "     B-PREDFULL = f1 = 63.54, precision = 51.76, recall = 82.24\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 37.50, precision = 48.39, recall = 30.61\n",
      "              O = f1 = 95.59, precision = 93.16, recall = 98.13\n",
      "------------------------\n",
      "Macro-F1 = 47.922Macro-Prescion = 53.892Macro-Recall = 48.188\n",
      "\n",
      "== eval epoch 12/100 \"f1-macro\" train / dev / test | 88.85 / 44.92 / 47.92.\n",
      "## [no improvement micro-f1 on DEV during the last 5 epochs (best_f1_dev=54.02), 93 seconds].\n",
      "\n",
      "-- train epoch 13/100, batch 243/243 (100.00%), loss = 2.85.\n",
      "\n",
      "++ predicting, batch 243/243 (100.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 96.31, precision = 94.01, recall = 98.72\n",
      "     B-PREDFULL = f1 = 75.78, precision = 74.16, recall = 77.46\n",
      "          I-OBJ = f1 = 88.89, precision = 100.00, recall = 80.00\n",
      "     I-PREDFULL = f1 = 80.41, precision = 76.10, recall = 85.23\n",
      "              O = f1 = 99.31, precision = 99.58, recall = 99.04\n",
      "------------------------\n",
      "Macro-F1 = 88.139Macro-Prescion = 88.771Macro-Recall = 88.092\n",
      "\n",
      "\n",
      "++ predicting, batch 35/35 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 28.74, precision = 69.76, recall = 18.10\n",
      "     B-PREDFULL = f1 = 48.65, precision = 55.38, recall = 43.37\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 57.14, precision = 61.54, recall = 53.33\n",
      "              O = f1 = 95.08, precision = 91.77, recall = 98.65\n",
      "------------------------\n",
      "Macro-F1 = 45.924Macro-Prescion = 55.689Macro-Recall = 42.692\n",
      "\n",
      "\n",
      "++ predicting, batch 36/36 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 52.67, precision = 79.69, recall = 39.33\n",
      "     B-PREDFULL = f1 = 54.13, precision = 53.15, recall = 55.14\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 48.28, precision = 55.26, recall = 42.86\n",
      "              O = f1 = 95.97, precision = 93.67, recall = 98.40\n",
      "------------------------\n",
      "Macro-F1 = 50.209Macro-Prescion = 56.354Macro-Recall = 47.145\n",
      "\n",
      "== eval epoch 13/100 \"f1-macro\" train / dev / test | 88.14 / 45.92 / 50.21.\n",
      "## [no improvement micro-f1 on DEV during the last 6 epochs (best_f1_dev=54.02), 89 seconds].\n",
      "\n",
      "-- train epoch 14/100, batch 243/243 (100.00%), loss = 2.84.\n",
      "\n",
      "++ predicting, batch 243/243 (100.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 96.18, precision = 95.04, recall = 97.35\n",
      "     B-PREDFULL = f1 = 78.90, precision = 71.03, recall = 88.73\n",
      "          I-OBJ = f1 = 88.89, precision = 100.00, recall = 80.00\n",
      "     I-PREDFULL = f1 = 83.09, precision = 80.23, recall = 86.15\n",
      "              O = f1 = 99.33, precision = 99.58, recall = 99.08\n",
      "------------------------\n",
      "Macro-F1 = 89.278Macro-Prescion = 89.175Macro-Recall = 90.265\n",
      "\n",
      "\n",
      "++ predicting, batch 35/35 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 31.45, precision = 71.95, recall = 20.13\n",
      "     B-PREDFULL = f1 = 54.32, precision = 55.70, recall = 53.01\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 75.47, precision = 86.96, recall = 66.67\n",
      "              O = f1 = 95.30, precision = 92.10, recall = 98.74\n",
      "------------------------\n",
      "Macro-F1 = 51.310Macro-Prescion = 61.339Macro-Recall = 47.709\n",
      "\n",
      "\n",
      "++ predicting, batch 36/36 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 56.76, precision = 81.84, recall = 43.44\n",
      "     B-PREDFULL = f1 = 59.85, precision = 50.32, recall = 73.83\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 60.22, precision = 63.64, recall = 57.14\n",
      "              O = f1 = 96.15, precision = 94.23, recall = 98.16\n",
      "------------------------\n",
      "Macro-F1 = 54.595Macro-Prescion = 58.005Macro-Recall = 54.515\n",
      "\n",
      "== eval epoch 14/100 \"f1-macro\" train / dev / test | 89.28 / 51.31 / 54.60.\n",
      "## [no improvement micro-f1 on DEV during the last 7 epochs (best_f1_dev=54.02), 96 seconds].\n",
      "\n",
      "-- train epoch 15/100, batch 243/243 (100.00%), loss = 2.08.\n",
      "\n",
      "++ predicting, batch 243/243 (100.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 97.10, precision = 95.60, recall = 98.65\n",
      "     B-PREDFULL = f1 = 78.88, precision = 71.84, recall = 87.46\n",
      "          I-OBJ = f1 = 92.86, precision = 100.00, recall = 86.67\n",
      "     I-PREDFULL = f1 = 83.56, precision = 83.44, recall = 83.69\n",
      "              O = f1 = 99.42, precision = 99.67, recall = 99.18\n",
      "------------------------\n",
      "Macro-F1 = 90.365Macro-Prescion = 90.109Macro-Recall = 91.129\n",
      "\n",
      "\n",
      "++ predicting, batch 35/35 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 36.80, precision = 74.52, recall = 24.43\n",
      "     B-PREDFULL = f1 = 55.74, precision = 51.00, recall = 61.45\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 61.86, precision = 81.08, recall = 50.00\n",
      "              O = f1 = 95.36, precision = 92.41, recall = 98.50\n",
      "------------------------\n",
      "Macro-F1 = 49.950Macro-Prescion = 59.802Macro-Recall = 46.876\n",
      "\n",
      "\n",
      "++ predicting, batch 36/36 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 50.27, precision = 81.98, recall = 36.25\n",
      "     B-PREDFULL = f1 = 62.12, precision = 52.23, recall = 76.64\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 48.78, precision = 60.61, recall = 40.82\n",
      "              O = f1 = 95.95, precision = 93.64, recall = 98.36\n",
      "------------------------\n",
      "Macro-F1 = 51.423Macro-Prescion = 57.691Macro-Recall = 50.412\n",
      "\n",
      "== eval epoch 15/100 \"f1-macro\" train / dev / test | 90.37 / 49.95 / 51.42.\n",
      "## [no improvement micro-f1 on DEV during the last 8 epochs (best_f1_dev=54.02), 92 seconds].\n",
      "\n",
      "-- train epoch 16/100, batch 243/243 (100.00%), loss = 2.21.\n",
      "\n",
      "++ predicting, batch 243/243 (100.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 97.07, precision = 96.98, recall = 97.15\n",
      "     B-PREDFULL = f1 = 81.73, precision = 79.46, recall = 84.13\n",
      "          I-OBJ = f1 = 92.86, precision = 100.00, recall = 86.67\n",
      "     I-PREDFULL = f1 = 82.27, precision = 74.81, recall = 91.38\n",
      "              O = f1 = 99.45, precision = 99.54, recall = 99.36\n",
      "------------------------\n",
      "Macro-F1 = 90.674Macro-Prescion = 90.160Macro-Recall = 91.737\n",
      "\n",
      "\n",
      "++ predicting, batch 35/35 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 16.10, precision = 62.39, recall = 9.24\n",
      "     B-PREDFULL = f1 = 50.57, precision = 48.35, recall = 53.01\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 70.87, precision = 67.16, recall = 75.00\n",
      "              O = f1 = 94.79, precision = 91.24, recall = 98.61\n",
      "------------------------\n",
      "Macro-F1 = 46.465Macro-Prescion = 53.830Macro-Recall = 47.173\n",
      "\n",
      "\n",
      "++ predicting, batch 36/36 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 34.52, precision = 74.15, recall = 22.49\n",
      "     B-PREDFULL = f1 = 66.67, precision = 61.42, recall = 72.90\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 65.26, precision = 67.39, recall = 63.27\n",
      "              O = f1 = 95.58, precision = 92.70, recall = 98.64\n",
      "------------------------\n",
      "Macro-F1 = 52.405Macro-Prescion = 59.132Macro-Recall = 51.458\n",
      "\n",
      "== eval epoch 16/100 \"f1-macro\" train / dev / test | 90.67 / 46.46 / 52.40.\n",
      "## [no improvement micro-f1 on DEV during the last 9 epochs (best_f1_dev=54.02), 90 seconds].\n",
      "\n",
      "-- train epoch 17/100, batch 243/243 (100.00%), loss = 1.78.\n",
      "\n",
      "++ predicting, batch 243/243 (100.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 97.37, precision = 96.07, recall = 98.71\n",
      "     B-PREDFULL = f1 = 79.52, precision = 75.39, recall = 84.13\n",
      "          I-OBJ = f1 = 92.86, precision = 100.00, recall = 86.67\n",
      "     I-PREDFULL = f1 = 86.09, precision = 93.19, recall = 80.00\n",
      "              O = f1 = 99.48, precision = 99.62, recall = 99.34\n",
      "------------------------\n",
      "Macro-F1 = 91.065Macro-Prescion = 92.855Macro-Recall = 89.769\n",
      "\n",
      "\n",
      "++ predicting, batch 35/35 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 25.00, precision = 67.98, recall = 15.32\n",
      "     B-PREDFULL = f1 = 48.24, precision = 47.13, recall = 49.40\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 29.73, precision = 78.57, recall = 18.33\n",
      "              O = f1 = 94.89, precision = 91.36, recall = 98.70\n",
      "------------------------\n",
      "Macro-F1 = 39.571Macro-Prescion = 57.008Macro-Recall = 36.350\n",
      "\n",
      "\n",
      "++ predicting, batch 36/36 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 38.47, precision = 75.28, recall = 25.84\n",
      "     B-PREDFULL = f1 = 59.59, precision = 52.90, recall = 68.22\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 13.79, precision = 44.44, recall = 8.16\n",
      "              O = f1 = 95.49, precision = 92.64, recall = 98.52\n",
      "------------------------\n",
      "Macro-F1 = 41.468Macro-Prescion = 53.052Macro-Recall = 40.148\n",
      "\n",
      "== eval epoch 17/100 \"f1-macro\" train / dev / test | 91.06 / 39.57 / 41.47.\n",
      "## [no improvement micro-f1 on DEV during the last 10 epochs (best_f1_dev=54.02), 88 seconds].\n",
      "\n",
      "-- train epoch 18/100, batch 243/243 (100.00%), loss = 2.02.\n",
      "\n",
      "++ predicting, batch 243/243 (100.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 97.57, precision = 97.05, recall = 98.11\n",
      "     B-PREDFULL = f1 = 76.95, precision = 87.15, recall = 68.89\n",
      "          I-OBJ = f1 = 92.86, precision = 100.00, recall = 86.67\n",
      "     I-PREDFULL = f1 = 87.31, precision = 93.97, recall = 81.54\n",
      "              O = f1 = 99.52, precision = 99.42, recall = 99.61\n",
      "------------------------\n",
      "Macro-F1 = 90.843Macro-Prescion = 95.518Macro-Recall = 86.963\n",
      "\n",
      "\n",
      "++ predicting, batch 35/35 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 31.75, precision = 73.39, recall = 20.25\n",
      "     B-PREDFULL = f1 = 33.93, precision = 65.52, recall = 22.89\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 46.51, precision = 76.92, recall = 33.33\n",
      "              O = f1 = 95.23, precision = 91.66, recall = 99.09\n",
      "------------------------\n",
      "Macro-F1 = 41.484Macro-Prescion = 61.500Macro-Recall = 35.114\n",
      "\n",
      "\n",
      "++ predicting, batch 36/36 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 54.62, precision = 83.38, recall = 40.62\n",
      "     B-PREDFULL = f1 = 45.03, precision = 51.19, recall = 40.19\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 32.35, precision = 57.89, recall = 22.45\n",
      "              O = f1 = 96.08, precision = 93.53, recall = 98.78\n",
      "------------------------\n",
      "Macro-F1 = 45.618Macro-Prescion = 57.199Macro-Recall = 40.406\n",
      "\n",
      "== eval epoch 18/100 \"f1-macro\" train / dev / test | 90.84 / 41.48 / 45.62.\n",
      "## [no improvement micro-f1 on DEV during the last 11 epochs (best_f1_dev=54.02), 92 seconds].\n",
      "\n",
      "-- train epoch 19/100, batch 243/243 (100.00%), loss = 1.81.\n",
      "\n",
      "++ predicting, batch 243/243 (100.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 97.49, precision = 96.54, recall = 98.46\n",
      "     B-PREDFULL = f1 = 85.91, precision = 82.58, recall = 89.52\n",
      "          I-OBJ = f1 = 84.85, precision = 77.78, recall = 93.33\n",
      "     I-PREDFULL = f1 = 88.41, precision = 95.70, recall = 82.15\n",
      "              O = f1 = 99.58, precision = 99.67, recall = 99.48\n",
      "------------------------\n",
      "Macro-F1 = 91.248Macro-Prescion = 90.453Macro-Recall = 92.591\n",
      "\n",
      "\n",
      "++ predicting, batch 35/35 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 31.38, precision = 72.81, recall = 20.00\n",
      "     B-PREDFULL = f1 = 45.52, precision = 53.23, recall = 39.76\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 29.73, precision = 78.57, recall = 18.33\n",
      "              O = f1 = 95.15, precision = 91.68, recall = 98.88\n",
      "------------------------\n",
      "Macro-F1 = 40.355Macro-Prescion = 59.258Macro-Recall = 35.395\n",
      "\n",
      "\n",
      "++ predicting, batch 36/36 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 48.42, precision = 80.78, recall = 34.58\n",
      "     B-PREDFULL = f1 = 56.52, precision = 52.85, recall = 60.75\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 26.23, precision = 66.67, recall = 16.33\n",
      "              O = f1 = 95.86, precision = 93.25, recall = 98.63\n",
      "------------------------\n",
      "Macro-F1 = 45.408Macro-Prescion = 58.709Macro-Recall = 42.055\n",
      "\n",
      "== eval epoch 19/100 \"f1-macro\" train / dev / test | 91.25 / 40.35 / 45.41.\n",
      "## [no improvement micro-f1 on DEV during the last 12 epochs (best_f1_dev=54.02), 95 seconds].\n",
      "\n",
      "-- train epoch 20/100, batch 243/243 (100.00%), loss = 1.81.\n",
      "\n",
      "++ predicting, batch 243/243 (100.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 97.31, precision = 95.62, recall = 99.06\n",
      "     B-PREDFULL = f1 = 82.35, precision = 74.39, recall = 92.22\n",
      "          I-OBJ = f1 = 96.55, precision = 100.00, recall = 93.33\n",
      "     I-PREDFULL = f1 = 80.00, precision = 99.09, recall = 67.08\n",
      "              O = f1 = 99.47, precision = 99.66, recall = 99.28\n",
      "------------------------\n",
      "Macro-F1 = 91.137Macro-Prescion = 93.753Macro-Recall = 90.195\n",
      "\n",
      "\n",
      "++ predicting, batch 35/35 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 42.42, precision = 77.26, recall = 29.24\n",
      "     B-PREDFULL = f1 = 44.71, precision = 43.68, recall = 45.78\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 9.52, precision = 100.00, recall = 5.00\n",
      "              O = f1 = 95.38, precision = 92.39, recall = 98.57\n",
      "------------------------\n",
      "Macro-F1 = 38.407Macro-Prescion = 62.666Macro-Recall = 35.718\n",
      "\n",
      "\n",
      "++ predicting, batch 36/36 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 56.01, precision = 81.02, recall = 42.80\n",
      "     B-PREDFULL = f1 = 55.81, precision = 47.68, recall = 67.29\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "              O = f1 = 96.01, precision = 93.84, recall = 98.29\n",
      "------------------------\n",
      "Macro-F1 = 41.568Macro-Prescion = 44.510Macro-Recall = 41.676\n",
      "\n",
      "== eval epoch 20/100 \"f1-macro\" train / dev / test | 91.14 / 38.41 / 41.57.\n",
      "## [no improvement micro-f1 on DEV during the last 13 epochs (best_f1_dev=54.02), 93 seconds].\n",
      "\n",
      "-- train epoch 21/100, batch 243/243 (100.00%), loss = 1.74.\n",
      "\n",
      "++ predicting, batch 243/243 (100.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 97.80, precision = 96.85, recall = 98.76\n",
      "     B-PREDFULL = f1 = 80.91, precision = 90.23, recall = 73.33\n",
      "          I-OBJ = f1 = 96.55, precision = 100.00, recall = 93.33\n",
      "     I-PREDFULL = f1 = 89.52, precision = 92.46, recall = 86.77\n",
      "              O = f1 = 99.58, precision = 99.55, recall = 99.61\n",
      "------------------------\n",
      "Macro-F1 = 92.873Macro-Prescion = 95.820Macro-Recall = 90.361\n",
      "\n",
      "\n",
      "++ predicting, batch 35/35 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 32.47, precision = 76.17, recall = 20.63\n",
      "     B-PREDFULL = f1 = 36.36, precision = 57.89, recall = 26.51\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 41.98, precision = 80.95, recall = 28.33\n",
      "              O = f1 = 95.27, precision = 91.70, recall = 99.13\n",
      "------------------------\n",
      "Macro-F1 = 41.216Macro-Prescion = 61.343Macro-Recall = 34.920\n",
      "\n",
      "\n",
      "++ predicting, batch 36/36 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 48.66, precision = 79.36, recall = 35.09\n",
      "     B-PREDFULL = f1 = 46.49, precision = 55.13, recall = 40.19\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 36.36, precision = 70.59, recall = 24.49\n",
      "              O = f1 = 95.88, precision = 93.13, recall = 98.79\n",
      "------------------------\n",
      "Macro-F1 = 45.478Macro-Prescion = 59.641Macro-Recall = 39.711\n",
      "\n",
      "== eval epoch 21/100 \"f1-macro\" train / dev / test | 92.87 / 41.22 / 45.48.\n",
      "## [no improvement micro-f1 on DEV during the last 14 epochs (best_f1_dev=54.02), 88 seconds].\n",
      "\n",
      "-- train epoch 22/100, batch 243/243 (100.00%), loss = 1.46.\n",
      "\n",
      "++ predicting, batch 243/243 (100.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 98.21, precision = 97.66, recall = 98.76\n",
      "     B-PREDFULL = f1 = 84.75, precision = 76.04, recall = 95.71\n",
      "          I-OBJ = f1 = 96.55, precision = 100.00, recall = 93.33\n",
      "     I-PREDFULL = f1 = 89.95, precision = 96.81, recall = 84.00\n",
      "              O = f1 = 99.62, precision = 99.76, recall = 99.48\n",
      "------------------------\n",
      "Macro-F1 = 93.816Macro-Prescion = 94.055Macro-Recall = 94.257\n",
      "\n",
      "\n",
      "++ predicting, batch 35/35 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 31.98, precision = 74.19, recall = 20.38\n",
      "     B-PREDFULL = f1 = 48.45, precision = 42.34, recall = 56.63\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 32.43, precision = 85.71, recall = 20.00\n",
      "              O = f1 = 95.06, precision = 91.84, recall = 98.50\n",
      "------------------------\n",
      "Macro-F1 = 41.583Macro-Prescion = 58.818Macro-Recall = 39.102\n",
      "\n",
      "\n",
      "++ predicting, batch 36/36 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 48.21, precision = 79.59, recall = 34.58\n",
      "     B-PREDFULL = f1 = 62.64, precision = 52.53, recall = 77.57\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 22.95, precision = 58.33, recall = 14.29\n",
      "              O = f1 = 95.82, precision = 93.40, recall = 98.37\n",
      "------------------------\n",
      "Macro-F1 = 45.925Macro-Prescion = 56.771Macro-Recall = 44.961\n",
      "\n",
      "== eval epoch 22/100 \"f1-macro\" train / dev / test | 93.82 / 41.58 / 45.92.\n",
      "## [no improvement micro-f1 on DEV during the last 15 epochs (best_f1_dev=54.02), 90 seconds].\n",
      "\n",
      "-- train epoch 23/100, batch 243/243 (100.00%), loss = 1.62.\n",
      "\n",
      "++ predicting, batch 243/243 (100.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 97.82, precision = 96.33, recall = 99.36\n",
      "     B-PREDFULL = f1 = 87.38, precision = 84.78, recall = 90.16\n",
      "          I-OBJ = f1 = 92.86, precision = 100.00, recall = 86.67\n",
      "     I-PREDFULL = f1 = 88.55, precision = 99.62, recall = 79.69\n",
      "              O = f1 = 99.62, precision = 99.74, recall = 99.51\n",
      "------------------------\n",
      "Macro-F1 = 93.246Macro-Prescion = 96.091Macro-Recall = 91.078\n",
      "\n",
      "\n",
      "++ predicting, batch 35/35 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 45.85, precision = 77.64, recall = 32.53\n",
      "     B-PREDFULL = f1 = 47.13, precision = 50.00, recall = 44.58\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 30.56, precision = 91.67, recall = 18.33\n",
      "              O = f1 = 95.60, precision = 92.75, recall = 98.63\n",
      "------------------------\n",
      "Macro-F1 = 43.828Macro-Prescion = 62.412Macro-Recall = 38.814\n",
      "\n",
      "\n",
      "++ predicting, batch 36/36 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 59.71, precision = 80.57, recall = 47.43\n",
      "     B-PREDFULL = f1 = 55.02, precision = 51.64, recall = 58.88\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 25.00, precision = 53.33, recall = 16.33\n",
      "              O = f1 = 96.22, precision = 94.20, recall = 98.32\n",
      "------------------------\n",
      "Macro-F1 = 47.189Macro-Prescion = 55.948Macro-Recall = 44.191\n",
      "\n",
      "== eval epoch 23/100 \"f1-macro\" train / dev / test | 93.25 / 43.83 / 47.19.\n",
      "## [no improvement micro-f1 on DEV during the last 16 epochs (best_f1_dev=54.02), 91 seconds].\n",
      "\n",
      "-- train epoch 24/100, batch 243/243 (100.00%), loss = 1.20.\n",
      "\n",
      "++ predicting, batch 243/243 (100.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 98.16, precision = 97.38, recall = 98.95\n",
      "     B-PREDFULL = f1 = 88.24, precision = 85.54, recall = 91.11\n",
      "          I-OBJ = f1 = 92.86, precision = 100.00, recall = 86.67\n",
      "     I-PREDFULL = f1 = 90.57, precision = 100.00, recall = 82.77\n",
      "              O = f1 = 99.67, precision = 99.73, recall = 99.61\n",
      "------------------------\n",
      "Macro-F1 = 93.899Macro-Prescion = 96.530Macro-Recall = 91.822\n",
      "\n",
      "\n",
      "++ predicting, batch 35/35 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 22.32, precision = 66.25, recall = 13.42\n",
      "     B-PREDFULL = f1 = 44.59, precision = 50.77, recall = 39.76\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 25.35, precision = 81.82, recall = 15.00\n",
      "              O = f1 = 94.86, precision = 91.12, recall = 98.92\n",
      "------------------------\n",
      "Macro-F1 = 37.425Macro-Prescion = 57.992Macro-Recall = 33.420\n",
      "\n",
      "\n",
      "++ predicting, batch 36/36 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 33.27, precision = 69.67, recall = 21.85\n",
      "     B-PREDFULL = f1 = 54.08, precision = 50.00, recall = 58.88\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 30.30, precision = 58.82, recall = 20.41\n",
      "              O = f1 = 95.26, precision = 92.30, recall = 98.43\n",
      "------------------------\n",
      "Macro-F1 = 42.583Macro-Prescion = 54.159Macro-Recall = 39.913\n",
      "\n",
      "== eval epoch 24/100 \"f1-macro\" train / dev / test | 93.90 / 37.42 / 42.58.\n",
      "## [no improvement micro-f1 on DEV during the last 17 epochs (best_f1_dev=54.02), 90 seconds].\n",
      "\n",
      "-- train epoch 25/100, batch 243/243 (100.00%), loss = 1.59.\n",
      "\n",
      "++ predicting, batch 243/243 (100.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 98.20, precision = 97.24, recall = 99.17\n",
      "     B-PREDFULL = f1 = 89.00, precision = 83.17, recall = 95.71\n",
      "          I-OBJ = f1 = 96.55, precision = 100.00, recall = 93.33\n",
      "     I-PREDFULL = f1 = 92.71, precision = 91.59, recall = 93.85\n",
      "              O = f1 = 99.68, precision = 99.85, recall = 99.51\n",
      "------------------------\n",
      "Macro-F1 = 95.228Macro-Prescion = 94.371Macro-Recall = 96.316\n",
      "\n",
      "\n",
      "++ predicting, batch 35/35 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 35.96, precision = 74.80, recall = 23.67\n",
      "     B-PREDFULL = f1 = 47.19, precision = 44.21, recall = 50.60\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 72.07, precision = 78.43, recall = 66.67\n",
      "              O = f1 = 95.30, precision = 92.35, recall = 98.44\n",
      "------------------------\n",
      "Macro-F1 = 50.105Macro-Prescion = 57.959Macro-Recall = 47.877\n",
      "\n",
      "\n",
      "++ predicting, batch 36/36 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 37.26, precision = 71.53, recall = 25.19\n",
      "     B-PREDFULL = f1 = 59.35, precision = 52.52, recall = 68.22\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 64.52, precision = 68.18, recall = 61.22\n",
      "              O = f1 = 95.47, precision = 92.82, recall = 98.28\n",
      "------------------------\n",
      "Macro-F1 = 51.320Macro-Prescion = 57.010Macro-Recall = 50.584\n",
      "\n",
      "== eval epoch 25/100 \"f1-macro\" train / dev / test | 95.23 / 50.10 / 51.32.\n",
      "## [no improvement micro-f1 on DEV during the last 18 epochs (best_f1_dev=54.02), 92 seconds].\n",
      "\n",
      "-- train epoch 26/100, batch 243/243 (100.00%), loss = 1.10.\n",
      "\n",
      "++ predicting, batch 243/243 (100.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 98.30, precision = 97.07, recall = 99.55\n",
      "     B-PREDFULL = f1 = 85.90, precision = 78.23, recall = 95.24\n",
      "          I-OBJ = f1 = 96.55, precision = 100.00, recall = 93.33\n",
      "     I-PREDFULL = f1 = 94.90, precision = 95.34, recall = 94.46\n",
      "              O = f1 = 99.66, precision = 99.88, recall = 99.45\n",
      "------------------------\n",
      "Macro-F1 = 95.062Macro-Prescion = 94.105Macro-Recall = 96.406\n",
      "\n",
      "\n",
      "++ predicting, batch 35/35 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 40.41, precision = 77.42, recall = 27.34\n",
      "     B-PREDFULL = f1 = 53.97, precision = 48.11, recall = 61.45\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 62.39, precision = 69.39, recall = 56.67\n",
      "              O = f1 = 95.44, precision = 92.69, recall = 98.37\n",
      "------------------------\n",
      "Macro-F1 = 50.442Macro-Prescion = 57.522Macro-Recall = 48.765\n",
      "\n",
      "\n",
      "++ predicting, batch 36/36 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 48.23, precision = 77.12, recall = 35.09\n",
      "     B-PREDFULL = f1 = 62.84, precision = 53.25, recall = 76.64\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 64.65, precision = 64.00, recall = 65.31\n",
      "              O = f1 = 95.86, precision = 93.67, recall = 98.15\n",
      "------------------------\n",
      "Macro-F1 = 54.314Macro-Prescion = 57.607Macro-Recall = 55.035\n",
      "\n",
      "== eval epoch 26/100 \"f1-macro\" train / dev / test | 95.06 / 50.44 / 54.31.\n",
      "## [no improvement micro-f1 on DEV during the last 19 epochs (best_f1_dev=54.02), 91 seconds].\n",
      "\n",
      "-- train epoch 27/100, batch 243/243 (100.00%), loss = 1.27.\n",
      "\n",
      "++ predicting, batch 243/243 (100.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 98.58, precision = 98.36, recall = 98.80\n",
      "     B-PREDFULL = f1 = 90.84, precision = 88.19, recall = 93.65\n",
      "          I-OBJ = f1 = 96.55, precision = 100.00, recall = 93.33\n",
      "     I-PREDFULL = f1 = 94.26, precision = 95.00, recall = 93.54\n",
      "              O = f1 = 99.75, precision = 99.80, recall = 99.71\n",
      "------------------------\n",
      "Macro-F1 = 95.997Macro-Prescion = 96.269Macro-Recall = 95.805\n",
      "\n",
      "\n",
      "++ predicting, batch 35/35 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 26.60, precision = 71.67, recall = 16.33\n",
      "     B-PREDFULL = f1 = 40.27, precision = 45.45, recall = 36.14\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 54.55, precision = 69.23, recall = 45.00\n",
      "              O = f1 = 95.01, precision = 91.51, recall = 98.79\n",
      "------------------------\n",
      "Macro-F1 = 43.284Macro-Prescion = 55.572Macro-Recall = 39.252\n",
      "\n",
      "\n",
      "++ predicting, batch 36/36 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 31.70, precision = 72.15, recall = 20.31\n",
      "     B-PREDFULL = f1 = 54.47, precision = 48.20, recall = 62.62\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 71.29, precision = 69.23, recall = 73.47\n",
      "              O = f1 = 95.33, precision = 92.46, recall = 98.37\n",
      "------------------------\n",
      "Macro-F1 = 50.556Macro-Prescion = 56.408Macro-Recall = 50.954\n",
      "\n",
      "== eval epoch 27/100 \"f1-macro\" train / dev / test | 96.00 / 43.28 / 50.56.\n",
      "## [no improvement micro-f1 on DEV during the last 20 epochs (best_f1_dev=54.02), 95 seconds].\n",
      "\n",
      "-- train epoch 28/100, batch 243/243 (100.00%), loss = 0.96.\n",
      "\n",
      "++ predicting, batch 243/243 (100.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 98.53, precision = 97.85, recall = 99.21\n",
      "     B-PREDFULL = f1 = 90.86, precision = 94.36, recall = 87.62\n",
      "          I-OBJ = f1 = 92.86, precision = 100.00, recall = 86.67\n",
      "     I-PREDFULL = f1 = 95.73, precision = 98.38, recall = 93.23\n",
      "              O = f1 = 99.76, precision = 99.77, recall = 99.75\n",
      "------------------------\n",
      "Macro-F1 = 95.549Macro-Prescion = 98.072Macro-Recall = 93.296\n",
      "\n",
      "\n",
      "++ predicting, batch 35/35 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 31.98, precision = 74.19, recall = 20.38\n",
      "     B-PREDFULL = f1 = 41.54, precision = 57.45, recall = 32.53\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 40.51, precision = 84.21, recall = 26.67\n",
      "              O = f1 = 95.23, precision = 91.71, recall = 99.03\n",
      "------------------------\n",
      "Macro-F1 = 41.850Macro-Prescion = 61.513Macro-Recall = 35.722\n",
      "\n",
      "\n",
      "++ predicting, batch 36/36 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 36.80, precision = 71.22, recall = 24.81\n",
      "     B-PREDFULL = f1 = 53.20, precision = 56.25, recall = 50.47\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 50.67, precision = 73.08, recall = 38.78\n",
      "              O = f1 = 95.47, precision = 92.53, recall = 98.61\n",
      "------------------------\n",
      "Macro-F1 = 47.228Macro-Prescion = 58.615Macro-Recall = 42.533\n",
      "\n",
      "== eval epoch 28/100 \"f1-macro\" train / dev / test | 95.55 / 41.85 / 47.23.\n",
      "## [no improvement micro-f1 on DEV during the last 21 epochs (best_f1_dev=54.02), 90 seconds].\n",
      "\n",
      "-- train epoch 29/100, batch 243/243 (100.00%), loss = 1.16.\n",
      "\n",
      "++ predicting, batch 243/243 (100.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 98.79, precision = 98.15, recall = 99.44\n",
      "     B-PREDFULL = f1 = 91.89, precision = 90.34, recall = 93.49\n",
      "          I-OBJ = f1 = 92.86, precision = 100.00, recall = 86.67\n",
      "     I-PREDFULL = f1 = 95.64, precision = 96.85, recall = 94.46\n",
      "              O = f1 = 99.79, precision = 99.85, recall = 99.72\n",
      "------------------------\n",
      "Macro-F1 = 95.792Macro-Prescion = 97.037Macro-Recall = 94.756\n",
      "\n",
      "\n",
      "++ predicting, batch 35/35 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 22.95, precision = 68.12, recall = 13.80\n",
      "     B-PREDFULL = f1 = 45.51, precision = 45.24, recall = 45.78\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 59.26, precision = 66.67, recall = 53.33\n",
      "              O = f1 = 94.88, precision = 91.42, recall = 98.61\n",
      "------------------------\n",
      "Macro-F1 = 44.519Macro-Prescion = 54.290Macro-Recall = 42.306\n",
      "\n",
      "\n",
      "++ predicting, batch 36/36 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 37.67, precision = 73.51, recall = 25.32\n",
      "     B-PREDFULL = f1 = 64.14, precision = 58.46, recall = 71.03\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 66.67, precision = 66.00, recall = 67.35\n",
      "              O = f1 = 95.59, precision = 92.90, recall = 98.45\n",
      "------------------------\n",
      "Macro-F1 = 52.813Macro-Prescion = 58.173Macro-Recall = 52.429\n",
      "\n",
      "== eval epoch 29/100 \"f1-macro\" train / dev / test | 95.79 / 44.52 / 52.81.\n",
      "## [no improvement micro-f1 on DEV during the last 22 epochs (best_f1_dev=54.02), 90 seconds].\n",
      "\n",
      "-- train epoch 30/100, batch 243/243 (100.00%), loss = 0.72.\n",
      "\n",
      "++ predicting, batch 243/243 (100.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 98.78, precision = 97.93, recall = 99.64\n",
      "     B-PREDFULL = f1 = 91.69, precision = 91.47, recall = 91.90\n",
      "          I-OBJ = f1 = 92.86, precision = 100.00, recall = 86.67\n",
      "     I-PREDFULL = f1 = 96.24, precision = 98.08, recall = 94.46\n",
      "              O = f1 = 99.79, precision = 99.86, recall = 99.72\n",
      "------------------------\n",
      "Macro-F1 = 95.871Macro-Prescion = 97.469Macro-Recall = 94.480\n",
      "\n",
      "\n",
      "++ predicting, batch 35/35 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 35.33, precision = 74.39, recall = 23.16\n",
      "     B-PREDFULL = f1 = 48.15, precision = 49.37, recall = 46.99\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 58.49, precision = 67.39, recall = 51.67\n",
      "              O = f1 = 95.27, precision = 92.19, recall = 98.55\n",
      "------------------------\n",
      "Macro-F1 = 47.447Macro-Prescion = 56.668Macro-Recall = 44.075\n",
      "\n",
      "\n",
      "++ predicting, batch 36/36 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 46.95, precision = 77.51, recall = 33.68\n",
      "     B-PREDFULL = f1 = 61.28, precision = 56.25, recall = 67.29\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 63.16, precision = 65.22, recall = 61.22\n",
      "              O = f1 = 95.86, precision = 93.45, recall = 98.39\n",
      "------------------------\n",
      "Macro-F1 = 53.449Macro-Prescion = 58.487Macro-Recall = 52.115\n",
      "\n",
      "== eval epoch 30/100 \"f1-macro\" train / dev / test | 95.87 / 47.45 / 53.45.\n",
      "## [no improvement micro-f1 on DEV during the last 23 epochs (best_f1_dev=54.02), 92 seconds].\n",
      "\n",
      "-- train epoch 31/100, batch 243/243 (100.00%), loss = 0.90.\n",
      "\n",
      "++ predicting, batch 243/243 (100.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 99.03, precision = 98.66, recall = 99.40\n",
      "     B-PREDFULL = f1 = 90.97, precision = 90.82, recall = 91.11\n",
      "          I-OBJ = f1 = 92.86, precision = 100.00, recall = 86.67\n",
      "     I-PREDFULL = f1 = 89.69, precision = 81.93, recall = 99.08\n",
      "              O = f1 = 99.76, precision = 99.85, recall = 99.68\n",
      "------------------------\n",
      "Macro-F1 = 94.462Macro-Prescion = 94.253Macro-Recall = 95.186\n",
      "\n",
      "\n",
      "++ predicting, batch 35/35 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 22.69, precision = 66.67, recall = 13.67\n",
      "     B-PREDFULL = f1 = 53.80, precision = 52.27, recall = 55.42\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 67.04, precision = 50.42, recall = 100.00\n",
      "              O = f1 = 94.83, precision = 91.76, recall = 98.11\n",
      "------------------------\n",
      "Macro-F1 = 47.671Macro-Prescion = 52.223Macro-Recall = 53.441\n",
      "\n",
      "\n",
      "++ predicting, batch 36/36 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 40.26, precision = 76.07, recall = 27.38\n",
      "     B-PREDFULL = f1 = 63.48, precision = 59.35, recall = 68.22\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 68.70, precision = 54.88, recall = 91.84\n",
      "              O = f1 = 95.66, precision = 93.14, recall = 98.33\n",
      "------------------------\n",
      "Macro-F1 = 53.622Macro-Prescion = 56.688Macro-Recall = 57.154\n",
      "\n",
      "== eval epoch 31/100 \"f1-macro\" train / dev / test | 94.46 / 47.67 / 53.62.\n",
      "## [no improvement micro-f1 on DEV during the last 24 epochs (best_f1_dev=54.02), 93 seconds].\n",
      "\n",
      "-- train epoch 32/100, batch 243/243 (100.00%), loss = 0.64.\n",
      "\n",
      "++ predicting, batch 243/243 (100.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 99.20, precision = 98.86, recall = 99.53\n",
      "     B-PREDFULL = f1 = 92.45, precision = 92.53, recall = 92.38\n",
      "          I-OBJ = f1 = 92.86, precision = 100.00, recall = 86.67\n",
      "     I-PREDFULL = f1 = 97.65, precision = 99.68, recall = 95.69\n",
      "              O = f1 = 99.84, precision = 99.86, recall = 99.83\n",
      "------------------------\n",
      "Macro-F1 = 96.399Macro-Prescion = 98.186Macro-Recall = 94.819\n",
      "\n",
      "\n",
      "++ predicting, batch 35/35 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 22.97, precision = 68.55, recall = 13.80\n",
      "     B-PREDFULL = f1 = 33.60, precision = 50.00, recall = 25.30\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 49.44, precision = 75.86, recall = 36.67\n",
      "              O = f1 = 94.95, precision = 91.17, recall = 99.04\n",
      "------------------------\n",
      "Macro-F1 = 40.191Macro-Prescion = 57.118Macro-Recall = 34.962\n",
      "\n",
      "\n",
      "++ predicting, batch 36/36 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 40.30, precision = 75.35, recall = 27.51\n",
      "     B-PREDFULL = f1 = 52.97, precision = 51.79, recall = 54.21\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 56.82, precision = 64.10, recall = 51.02\n",
      "              O = f1 = 95.57, precision = 92.81, recall = 98.49\n",
      "------------------------\n",
      "Macro-F1 = 49.132Macro-Prescion = 56.811Macro-Recall = 46.245\n",
      "\n",
      "== eval epoch 32/100 \"f1-macro\" train / dev / test | 96.40 / 40.19 / 49.13.\n",
      "## [no improvement micro-f1 on DEV during the last 25 epochs (best_f1_dev=54.02), 90 seconds].\n",
      "\n",
      "-- train epoch 33/100, batch 243/243 (100.00%), loss = 0.77.\n",
      "\n",
      "++ predicting, batch 243/243 (100.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 99.09, precision = 98.73, recall = 99.46\n",
      "     B-PREDFULL = f1 = 91.41, precision = 97.31, recall = 86.19\n",
      "          I-OBJ = f1 = 92.86, precision = 100.00, recall = 86.67\n",
      "     I-PREDFULL = f1 = 98.14, precision = 98.75, recall = 97.54\n",
      "              O = f1 = 99.83, precision = 99.80, recall = 99.86\n",
      "------------------------\n",
      "Macro-F1 = 96.268Macro-Prescion = 98.920Macro-Recall = 93.943\n",
      "\n",
      "\n",
      "++ predicting, batch 35/35 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 22.69, precision = 66.67, recall = 13.67\n",
      "     B-PREDFULL = f1 = 43.41, precision = 60.87, recall = 33.73\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 60.19, precision = 72.09, recall = 51.67\n",
      "              O = f1 = 94.99, precision = 91.32, recall = 98.97\n",
      "------------------------\n",
      "Macro-F1 = 44.257Macro-Prescion = 58.191Macro-Recall = 39.609\n",
      "\n",
      "\n",
      "++ predicting, batch 36/36 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 51.70, precision = 80.05, recall = 38.17\n",
      "     B-PREDFULL = f1 = 55.32, precision = 64.20, recall = 48.60\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 65.26, precision = 67.39, recall = 63.27\n",
      "              O = f1 = 96.10, precision = 93.63, recall = 98.71\n",
      "------------------------\n",
      "Macro-F1 = 53.676Macro-Prescion = 61.054Macro-Recall = 49.750\n",
      "\n",
      "== eval epoch 33/100 \"f1-macro\" train / dev / test | 96.27 / 44.26 / 53.68.\n",
      "## [no improvement micro-f1 on DEV during the last 26 epochs (best_f1_dev=54.02), 93 seconds].\n",
      "\n",
      "-- train epoch 34/100, batch 243/243 (100.00%), loss = 0.60.\n",
      "\n",
      "++ predicting, batch 243/243 (100.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 99.21, precision = 98.88, recall = 99.53\n",
      "     B-PREDFULL = f1 = 93.54, precision = 91.76, recall = 95.40\n",
      "          I-OBJ = f1 = 92.86, precision = 100.00, recall = 86.67\n",
      "     I-PREDFULL = f1 = 98.15, precision = 98.45, recall = 97.85\n",
      "              O = f1 = 99.85, precision = 99.90, recall = 99.81\n",
      "------------------------\n",
      "Macro-F1 = 96.721Macro-Prescion = 97.798Macro-Recall = 95.850\n",
      "\n",
      "\n",
      "++ predicting, batch 35/35 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 25.75, precision = 69.06, recall = 15.82\n",
      "     B-PREDFULL = f1 = 44.72, precision = 46.15, recall = 43.37\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 54.17, precision = 72.22, recall = 43.33\n",
      "              O = f1 = 94.96, precision = 91.51, recall = 98.68\n",
      "------------------------\n",
      "Macro-F1 = 43.918Macro-Prescion = 55.789Macro-Recall = 40.241\n",
      "\n",
      "\n",
      "++ predicting, batch 36/36 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 39.59, precision = 72.35, recall = 27.25\n",
      "     B-PREDFULL = f1 = 62.55, precision = 55.88, recall = 71.03\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 69.31, precision = 67.31, recall = 71.43\n",
      "              O = f1 = 95.60, precision = 93.06, recall = 98.29\n",
      "------------------------\n",
      "Macro-F1 = 53.410Macro-Prescion = 57.721Macro-Recall = 53.599\n",
      "\n",
      "== eval epoch 34/100 \"f1-macro\" train / dev / test | 96.72 / 43.92 / 53.41.\n",
      "## [no improvement micro-f1 on DEV during the last 27 epochs (best_f1_dev=54.02), 91 seconds].\n",
      "\n",
      "-- train epoch 35/100, batch 243/243 (100.00%), loss = 1.15.\n",
      "\n",
      "++ predicting, batch 243/243 (100.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 99.28, precision = 98.92, recall = 99.64\n",
      "     B-PREDFULL = f1 = 94.74, precision = 95.19, recall = 94.29\n",
      "          I-OBJ = f1 = 100.00, precision = 100.00, recall = 100.00\n",
      "     I-PREDFULL = f1 = 95.87, precision = 92.07, recall = 100.00\n",
      "              O = f1 = 99.86, precision = 99.91, recall = 99.81\n",
      "------------------------\n",
      "Macro-F1 = 97.950Macro-Prescion = 97.218Macro-Recall = 98.748\n",
      "\n",
      "\n",
      "++ predicting, batch 35/35 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 17.55, precision = 60.90, recall = 10.25\n",
      "     B-PREDFULL = f1 = 37.31, precision = 49.02, recall = 30.12\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 75.00, precision = 64.29, recall = 90.00\n",
      "              O = f1 = 94.81, precision = 91.23, recall = 98.68\n",
      "------------------------\n",
      "Macro-F1 = 44.934Macro-Prescion = 53.087Macro-Recall = 45.810\n",
      "\n",
      "\n",
      "++ predicting, batch 36/36 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 36.22, precision = 70.11, recall = 24.42\n",
      "     B-PREDFULL = f1 = 58.41, precision = 55.46, recall = 61.68\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 66.15, precision = 53.09, recall = 87.76\n",
      "              O = f1 = 95.39, precision = 92.81, recall = 98.12\n",
      "------------------------\n",
      "Macro-F1 = 51.236Macro-Prescion = 54.294Macro-Recall = 54.397\n",
      "\n",
      "== eval epoch 35/100 \"f1-macro\" train / dev / test | 97.95 / 44.93 / 51.24.\n",
      "## [no improvement micro-f1 on DEV during the last 28 epochs (best_f1_dev=54.02), 95 seconds].\n",
      "\n",
      "-- train epoch 36/100, batch 243/243 (100.00%), loss = 0.66.\n",
      "\n",
      "++ predicting, batch 243/243 (100.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 99.44, precision = 99.07, recall = 99.81\n",
      "     B-PREDFULL = f1 = 95.53, precision = 97.84, recall = 93.33\n",
      "          I-OBJ = f1 = 100.00, precision = 100.00, recall = 100.00\n",
      "     I-PREDFULL = f1 = 99.54, precision = 99.09, recall = 100.00\n",
      "              O = f1 = 99.90, precision = 99.92, recall = 99.89\n",
      "------------------------\n",
      "Macro-F1 = 98.883Macro-Prescion = 99.181Macro-Recall = 98.608\n",
      "\n",
      "\n",
      "++ predicting, batch 35/35 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 21.21, precision = 65.36, recall = 12.66\n",
      "     B-PREDFULL = f1 = 37.50, precision = 53.33, recall = 28.92\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 66.02, precision = 79.07, recall = 56.67\n",
      "              O = f1 = 94.95, precision = 91.23, recall = 98.98\n",
      "------------------------\n",
      "Macro-F1 = 43.935Macro-Prescion = 57.799Macro-Recall = 39.445\n",
      "\n",
      "\n",
      "++ predicting, batch 36/36 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 43.39, precision = 74.61, recall = 30.59\n",
      "     B-PREDFULL = f1 = 57.42, precision = 58.82, recall = 56.07\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 66.67, precision = 62.50, recall = 71.43\n",
      "              O = f1 = 95.73, precision = 93.17, recall = 98.44\n",
      "------------------------\n",
      "Macro-F1 = 52.641Macro-Prescion = 57.819Macro-Recall = 51.307\n",
      "\n",
      "== eval epoch 36/100 \"f1-macro\" train / dev / test | 98.88 / 43.94 / 52.64.\n",
      "## [no improvement micro-f1 on DEV during the last 29 epochs (best_f1_dev=54.02), 95 seconds].\n",
      "\n",
      "-- train epoch 37/100, batch 243/243 (100.00%), loss = 0.60.\n",
      "\n",
      "++ predicting, batch 243/243 (100.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 99.45, precision = 99.29, recall = 99.61\n",
      "     B-PREDFULL = f1 = 96.40, precision = 97.10, recall = 95.71\n",
      "          I-OBJ = f1 = 100.00, precision = 100.00, recall = 100.00\n",
      "     I-PREDFULL = f1 = 99.69, precision = 99.69, recall = 99.69\n",
      "              O = f1 = 99.91, precision = 99.92, recall = 99.91\n",
      "------------------------\n",
      "Macro-F1 = 99.091Macro-Prescion = 99.201Macro-Recall = 98.984\n",
      "\n",
      "\n",
      "++ predicting, batch 35/35 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 12.87, precision = 52.25, recall = 7.34\n",
      "     B-PREDFULL = f1 = 48.23, precision = 58.62, recall = 40.96\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 61.22, precision = 78.95, recall = 50.00\n",
      "              O = f1 = 94.74, precision = 90.86, recall = 98.96\n",
      "------------------------\n",
      "Macro-F1 = 43.412Macro-Prescion = 56.136Macro-Recall = 39.453\n",
      "\n",
      "\n",
      "++ predicting, batch 36/36 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 35.29, precision = 70.66, recall = 23.52\n",
      "     B-PREDFULL = f1 = 54.03, precision = 54.81, recall = 53.27\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 69.90, precision = 66.67, recall = 73.47\n",
      "              O = f1 = 95.45, precision = 92.61, recall = 98.46\n",
      "------------------------\n",
      "Macro-F1 = 50.935Macro-Prescion = 56.949Macro-Recall = 49.745\n",
      "\n",
      "== eval epoch 37/100 \"f1-macro\" train / dev / test | 99.09 / 43.41 / 50.93.\n",
      "## [no improvement micro-f1 on DEV during the last 30 epochs (best_f1_dev=54.02), 92 seconds].\n",
      "\n",
      "-- train epoch 38/100, batch 243/243 (100.00%), loss = 0.49.\n",
      "\n",
      "++ predicting, batch 243/243 (100.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 99.49, precision = 99.14, recall = 99.83\n",
      "     B-PREDFULL = f1 = 95.76, precision = 96.46, recall = 95.08\n",
      "          I-OBJ = f1 = 100.00, precision = 100.00, recall = 100.00\n",
      "     I-PREDFULL = f1 = 99.38, precision = 99.69, recall = 99.08\n",
      "              O = f1 = 99.91, precision = 99.93, recall = 99.89\n",
      "------------------------\n",
      "Macro-F1 = 98.908Macro-Prescion = 99.044Macro-Recall = 98.775\n",
      "\n",
      "\n",
      "++ predicting, batch 35/35 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 25.92, precision = 66.84, recall = 16.08\n",
      "     B-PREDFULL = f1 = 43.55, precision = 65.85, recall = 32.53\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 56.52, precision = 81.25, recall = 43.33\n",
      "              O = f1 = 95.07, precision = 91.46, recall = 98.98\n",
      "------------------------\n",
      "Macro-F1 = 44.212Macro-Prescion = 61.081Macro-Recall = 38.184\n",
      "\n",
      "\n",
      "++ predicting, batch 36/36 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 46.02, precision = 75.81, recall = 33.03\n",
      "     B-PREDFULL = f1 = 51.82, precision = 50.44, recall = 53.27\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 66.67, precision = 68.09, recall = 65.31\n",
      "              O = f1 = 95.75, precision = 93.28, recall = 98.34\n",
      "------------------------\n",
      "Macro-F1 = 52.049Macro-Prescion = 57.525Macro-Recall = 49.990\n",
      "\n",
      "== eval epoch 38/100 \"f1-macro\" train / dev / test | 98.91 / 44.21 / 52.05.\n",
      "## [no improvement micro-f1 on DEV during the last 31 epochs (best_f1_dev=54.02), 91 seconds].\n",
      "\n",
      "-- train epoch 39/100, batch 243/243 (100.00%), loss = 0.40.\n",
      "\n",
      "++ predicting, batch 243/243 (100.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 99.49, precision = 99.31, recall = 99.68\n",
      "     B-PREDFULL = f1 = 96.21, precision = 97.71, recall = 94.76\n",
      "          I-OBJ = f1 = 100.00, precision = 100.00, recall = 100.00\n",
      "     I-PREDFULL = f1 = 99.39, precision = 99.08, recall = 99.69\n",
      "              O = f1 = 99.91, precision = 99.92, recall = 99.91\n",
      "------------------------\n",
      "Macro-F1 = 99.002Macro-Prescion = 99.203Macro-Recall = 98.810\n",
      "\n",
      "\n",
      "++ predicting, batch 35/35 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 25.49, precision = 67.76, recall = 15.70\n",
      "     B-PREDFULL = f1 = 43.70, precision = 72.22, recall = 31.33\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 68.63, precision = 83.33, recall = 58.33\n",
      "              O = f1 = 95.14, precision = 91.52, recall = 99.07\n",
      "------------------------\n",
      "Macro-F1 = 46.591Macro-Prescion = 62.967Macro-Recall = 40.885\n",
      "\n",
      "\n",
      "++ predicting, batch 36/36 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 42.53, precision = 74.12, recall = 29.82\n",
      "     B-PREDFULL = f1 = 51.43, precision = 52.43, recall = 50.47\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 69.23, precision = 65.45, recall = 73.47\n",
      "              O = f1 = 95.65, precision = 93.06, recall = 98.39\n",
      "------------------------\n",
      "Macro-F1 = 51.767Macro-Prescion = 57.012Macro-Recall = 50.428\n",
      "\n",
      "== eval epoch 39/100 \"f1-macro\" train / dev / test | 99.00 / 46.59 / 51.77.\n",
      "## [no improvement micro-f1 on DEV during the last 32 epochs (best_f1_dev=54.02), 91 seconds].\n",
      "\n",
      "-- train epoch 40/100, batch 243/243 (100.00%), loss = 0.34.\n",
      "\n",
      "++ predicting, batch 243/243 (100.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 99.50, precision = 99.33, recall = 99.68\n",
      "     B-PREDFULL = f1 = 96.40, precision = 97.25, recall = 95.56\n",
      "          I-OBJ = f1 = 100.00, precision = 100.00, recall = 100.00\n",
      "     I-PREDFULL = f1 = 99.22, precision = 100.00, recall = 98.46\n",
      "              O = f1 = 99.92, precision = 99.92, recall = 99.91\n",
      "------------------------\n",
      "Macro-F1 = 99.008Macro-Prescion = 99.300Macro-Recall = 98.722\n",
      "\n",
      "\n",
      "++ predicting, batch 35/35 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 20.62, precision = 64.24, recall = 12.28\n",
      "     B-PREDFULL = f1 = 50.68, precision = 58.73, recall = 44.58\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 65.26, precision = 88.57, recall = 51.67\n",
      "              O = f1 = 94.98, precision = 91.30, recall = 98.97\n",
      "------------------------\n",
      "Macro-F1 = 46.309Macro-Prescion = 60.569Macro-Recall = 41.499\n",
      "\n",
      "\n",
      "++ predicting, batch 36/36 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 46.32, precision = 76.79, recall = 33.16\n",
      "     B-PREDFULL = f1 = 57.89, precision = 54.55, recall = 61.68\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 65.98, precision = 66.67, recall = 65.31\n",
      "              O = f1 = 95.82, precision = 93.38, recall = 98.39\n",
      "------------------------\n",
      "Macro-F1 = 53.203Macro-Prescion = 58.276Macro-Recall = 51.707\n",
      "\n",
      "== eval epoch 40/100 \"f1-macro\" train / dev / test | 99.01 / 46.31 / 53.20.\n",
      "## [no improvement micro-f1 on DEV during the last 33 epochs (best_f1_dev=54.02), 92 seconds].\n",
      "\n",
      "-- train epoch 41/100, batch 243/243 (100.00%), loss = 0.36.\n",
      "\n",
      "++ predicting, batch 243/243 (100.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 99.62, precision = 99.44, recall = 99.79\n",
      "     B-PREDFULL = f1 = 97.46, precision = 97.46, recall = 97.46\n",
      "          I-OBJ = f1 = 96.55, precision = 100.00, recall = 93.33\n",
      "     I-PREDFULL = f1 = 99.54, precision = 100.00, recall = 99.08\n",
      "              O = f1 = 99.94, precision = 99.95, recall = 99.93\n",
      "------------------------\n",
      "Macro-F1 = 98.621Macro-Prescion = 99.370Macro-Recall = 97.918\n",
      "\n",
      "\n",
      "++ predicting, batch 35/35 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 21.85, precision = 67.32, recall = 13.04\n",
      "     B-PREDFULL = f1 = 53.99, precision = 55.00, recall = 53.01\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 64.58, precision = 86.11, recall = 51.67\n",
      "              O = f1 = 95.01, precision = 91.43, recall = 98.88\n",
      "------------------------\n",
      "Macro-F1 = 47.086Macro-Prescion = 59.972Macro-Recall = 43.320\n",
      "\n",
      "\n",
      "++ predicting, batch 36/36 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 37.14, precision = 71.69, recall = 25.06\n",
      "     B-PREDFULL = f1 = 63.33, precision = 57.14, recall = 71.03\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 69.31, precision = 67.31, recall = 71.43\n",
      "              O = f1 = 95.55, precision = 92.90, recall = 98.36\n",
      "------------------------\n",
      "Macro-F1 = 53.068Macro-Prescion = 57.809Macro-Recall = 53.177\n",
      "\n",
      "== eval epoch 41/100 \"f1-macro\" train / dev / test | 98.62 / 47.09 / 53.07.\n",
      "## [no improvement micro-f1 on DEV during the last 34 epochs (best_f1_dev=54.02), 94 seconds].\n",
      "\n",
      "-- train epoch 42/100, batch 243/243 (100.00%), loss = 0.32.\n",
      "\n",
      "++ predicting, batch 243/243 (100.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 99.71, precision = 99.64, recall = 99.77\n",
      "     B-PREDFULL = f1 = 97.24, precision = 96.56, recall = 97.94\n",
      "          I-OBJ = f1 = 100.00, precision = 100.00, recall = 100.00\n",
      "     I-PREDFULL = f1 = 99.39, precision = 99.08, recall = 99.69\n",
      "              O = f1 = 99.94, precision = 99.96, recall = 99.93\n",
      "------------------------\n",
      "Macro-F1 = 99.256Macro-Prescion = 99.048Macro-Recall = 99.466\n",
      "\n",
      "\n",
      "++ predicting, batch 35/35 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 19.87, precision = 63.70, recall = 11.77\n",
      "     B-PREDFULL = f1 = 55.56, precision = 56.96, recall = 54.22\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 69.09, precision = 76.00, recall = 63.33\n",
      "              O = f1 = 94.95, precision = 91.40, recall = 98.79\n",
      "------------------------\n",
      "Macro-F1 = 47.894Macro-Prescion = 57.613Macro-Recall = 45.622\n",
      "\n",
      "\n",
      "++ predicting, batch 36/36 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 31.58, precision = 69.43, recall = 20.44\n",
      "     B-PREDFULL = f1 = 61.85, precision = 54.23, recall = 71.96\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 70.48, precision = 66.07, recall = 75.51\n",
      "              O = f1 = 95.36, precision = 92.57, recall = 98.32\n",
      "------------------------\n",
      "Macro-F1 = 51.853Macro-Prescion = 56.461Macro-Recall = 53.246\n",
      "\n",
      "== eval epoch 42/100 \"f1-macro\" train / dev / test | 99.26 / 47.89 / 51.85.\n",
      "## [no improvement micro-f1 on DEV during the last 35 epochs (best_f1_dev=54.02), 87 seconds].\n",
      "\n",
      "-- train epoch 43/100, batch 243/243 (100.00%), loss = 0.32.\n",
      "\n",
      "++ predicting, batch 243/243 (100.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 99.63, precision = 99.46, recall = 99.79\n",
      "     B-PREDFULL = f1 = 97.45, precision = 97.76, recall = 97.14\n",
      "          I-OBJ = f1 = 100.00, precision = 100.00, recall = 100.00\n",
      "     I-PREDFULL = f1 = 99.23, precision = 99.08, recall = 99.38\n",
      "              O = f1 = 99.94, precision = 99.95, recall = 99.93\n",
      "------------------------\n",
      "Macro-F1 = 99.249Macro-Prescion = 99.250Macro-Recall = 99.249\n",
      "\n",
      "\n",
      "++ predicting, batch 35/35 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 24.14, precision = 67.84, recall = 14.68\n",
      "     B-PREDFULL = f1 = 52.05, precision = 60.32, recall = 45.78\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 68.91, precision = 69.49, recall = 68.33\n",
      "              O = f1 = 95.06, precision = 91.60, recall = 98.80\n",
      "------------------------\n",
      "Macro-F1 = 48.033Macro-Prescion = 57.849Macro-Recall = 45.520\n",
      "\n",
      "\n",
      "++ predicting, batch 36/36 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 40.63, precision = 73.90, recall = 28.02\n",
      "     B-PREDFULL = f1 = 61.14, precision = 57.38, recall = 65.42\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 70.91, precision = 63.93, recall = 79.59\n",
      "              O = f1 = 95.65, precision = 93.09, recall = 98.35\n",
      "------------------------\n",
      "Macro-F1 = 53.666Macro-Prescion = 57.660Macro-Recall = 54.277\n",
      "\n",
      "== eval epoch 43/100 \"f1-macro\" train / dev / test | 99.25 / 48.03 / 53.67.\n",
      "## [no improvement micro-f1 on DEV during the last 36 epochs (best_f1_dev=54.02), 88 seconds].\n",
      "\n",
      "-- train epoch 44/100, batch 243/243 (100.00%), loss = 0.29.\n",
      "\n",
      "++ predicting, batch 243/243 (100.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 99.74, precision = 99.63, recall = 99.85\n",
      "     B-PREDFULL = f1 = 97.53, precision = 98.07, recall = 96.98\n",
      "          I-OBJ = f1 = 100.00, precision = 100.00, recall = 100.00\n",
      "     I-PREDFULL = f1 = 99.23, precision = 99.08, recall = 99.38\n",
      "              O = f1 = 99.95, precision = 99.95, recall = 99.94\n",
      "------------------------\n",
      "Macro-F1 = 99.289Macro-Prescion = 99.346Macro-Recall = 99.232\n",
      "\n",
      "\n",
      "++ predicting, batch 35/35 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 22.39, precision = 67.52, recall = 13.42\n",
      "     B-PREDFULL = f1 = 45.59, precision = 58.49, recall = 37.35\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 64.65, precision = 82.05, recall = 53.33\n",
      "              O = f1 = 95.03, precision = 91.35, recall = 99.02\n",
      "------------------------\n",
      "Macro-F1 = 45.530Macro-Prescion = 59.881Macro-Recall = 40.624\n",
      "\n",
      "\n",
      "++ predicting, batch 36/36 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 39.89, precision = 74.39, recall = 27.25\n",
      "     B-PREDFULL = f1 = 57.92, precision = 56.14, recall = 59.81\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 69.23, precision = 65.45, recall = 73.47\n",
      "              O = f1 = 95.62, precision = 92.95, recall = 98.45\n",
      "------------------------\n",
      "Macro-F1 = 52.532Macro-Prescion = 57.787Macro-Recall = 51.797\n",
      "\n",
      "== eval epoch 44/100 \"f1-macro\" train / dev / test | 99.29 / 45.53 / 52.53.\n",
      "## [no improvement micro-f1 on DEV during the last 37 epochs (best_f1_dev=54.02), 87 seconds].\n",
      "\n",
      "-- train epoch 45/100, batch 243/243 (100.00%), loss = 0.32.\n",
      "\n",
      "++ predicting, batch 243/243 (100.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 99.66, precision = 99.51, recall = 99.81\n",
      "     B-PREDFULL = f1 = 97.53, precision = 97.92, recall = 97.14\n",
      "          I-OBJ = f1 = 100.00, precision = 100.00, recall = 100.00\n",
      "     I-PREDFULL = f1 = 99.38, precision = 99.69, recall = 99.08\n",
      "              O = f1 = 99.94, precision = 99.95, recall = 99.94\n",
      "------------------------\n",
      "Macro-F1 = 99.304Macro-Prescion = 99.415Macro-Recall = 99.193\n",
      "\n",
      "\n",
      "++ predicting, batch 35/35 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 34.74, precision = 71.83, recall = 22.91\n",
      "     B-PREDFULL = f1 = 38.66, precision = 63.89, recall = 27.71\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 43.04, precision = 89.47, recall = 28.33\n",
      "              O = f1 = 95.28, precision = 91.88, recall = 98.95\n",
      "------------------------\n",
      "Macro-F1 = 42.344Macro-Prescion = 63.414Macro-Recall = 35.580\n",
      "\n",
      "\n",
      "++ predicting, batch 36/36 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 49.96, precision = 76.80, recall = 37.02\n",
      "     B-PREDFULL = f1 = 50.00, precision = 50.48, recall = 49.53\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 57.14, precision = 68.57, recall = 48.98\n",
      "              O = f1 = 95.86, precision = 93.47, recall = 98.37\n",
      "------------------------\n",
      "Macro-F1 = 50.592Macro-Prescion = 57.864Macro-Recall = 46.781\n",
      "\n",
      "== eval epoch 45/100 \"f1-macro\" train / dev / test | 99.30 / 42.34 / 50.59.\n",
      "## [no improvement micro-f1 on DEV during the last 38 epochs (best_f1_dev=54.02), 87 seconds].\n",
      "\n",
      "-- train epoch 46/100, batch 243/243 (100.00%), loss = 0.28.\n",
      "\n",
      "++ predicting, batch 243/243 (100.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 99.72, precision = 99.66, recall = 99.77\n",
      "     B-PREDFULL = f1 = 97.85, precision = 98.39, recall = 97.30\n",
      "          I-OBJ = f1 = 100.00, precision = 100.00, recall = 100.00\n",
      "     I-PREDFULL = f1 = 99.54, precision = 100.00, recall = 99.08\n",
      "              O = f1 = 99.95, precision = 99.95, recall = 99.95\n",
      "------------------------\n",
      "Macro-F1 = 99.410Macro-Prescion = 99.601Macro-Recall = 99.222\n",
      "\n",
      "\n",
      "++ predicting, batch 35/35 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 32.97, precision = 73.36, recall = 21.27\n",
      "     B-PREDFULL = f1 = 45.45, precision = 61.22, recall = 36.14\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 38.96, precision = 88.24, recall = 25.00\n",
      "              O = f1 = 95.26, precision = 91.80, recall = 98.99\n",
      "------------------------\n",
      "Macro-F1 = 42.530Macro-Prescion = 62.925Macro-Recall = 36.281\n",
      "\n",
      "\n",
      "++ predicting, batch 36/36 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 53.03, precision = 78.73, recall = 39.97\n",
      "     B-PREDFULL = f1 = 57.14, precision = 54.70, recall = 59.81\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 57.14, precision = 68.57, recall = 48.98\n",
      "              O = f1 = 96.04, precision = 93.80, recall = 98.40\n",
      "------------------------\n",
      "Macro-F1 = 52.671Macro-Prescion = 59.162Macro-Recall = 49.433\n",
      "\n",
      "== eval epoch 46/100 \"f1-macro\" train / dev / test | 99.41 / 42.53 / 52.67.\n",
      "## [no improvement micro-f1 on DEV during the last 39 epochs (best_f1_dev=54.02), 88 seconds].\n",
      "\n",
      "-- train epoch 47/100, batch 243/243 (100.00%), loss = 0.20.\n",
      "\n",
      "++ predicting, batch 243/243 (100.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 99.74, precision = 99.68, recall = 99.79\n",
      "     B-PREDFULL = f1 = 97.63, precision = 97.32, recall = 97.94\n",
      "          I-OBJ = f1 = 100.00, precision = 100.00, recall = 100.00\n",
      "     I-PREDFULL = f1 = 99.69, precision = 100.00, recall = 99.38\n",
      "              O = f1 = 99.95, precision = 99.96, recall = 99.94\n",
      "------------------------\n",
      "Macro-F1 = 99.401Macro-Prescion = 99.392Macro-Recall = 99.412\n",
      "\n",
      "\n",
      "++ predicting, batch 35/35 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 29.58, precision = 72.06, recall = 18.61\n",
      "     B-PREDFULL = f1 = 48.68, precision = 53.62, recall = 44.58\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 56.52, precision = 81.25, recall = 43.33\n",
      "              O = f1 = 95.17, precision = 91.76, recall = 98.84\n",
      "------------------------\n",
      "Macro-F1 = 45.990Macro-Prescion = 59.738Macro-Recall = 41.071\n",
      "\n",
      "\n",
      "++ predicting, batch 36/36 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 42.21, precision = 74.59, recall = 29.43\n",
      "     B-PREDFULL = f1 = 60.66, precision = 54.01, recall = 69.16\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 70.71, precision = 70.00, recall = 71.43\n",
      "              O = f1 = 95.68, precision = 93.19, recall = 98.30\n",
      "------------------------\n",
      "Macro-F1 = 53.851Macro-Prescion = 58.360Macro-Recall = 53.664\n",
      "\n",
      "== eval epoch 47/100 \"f1-macro\" train / dev / test | 99.40 / 45.99 / 53.85.\n",
      "## [no improvement micro-f1 on DEV during the last 40 epochs (best_f1_dev=54.02), 86 seconds].\n",
      "\n",
      "-- train epoch 48/100, batch 243/243 (100.00%), loss = 0.18.\n",
      "\n",
      "++ predicting, batch 243/243 (100.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 99.70, precision = 99.59, recall = 99.81\n",
      "     B-PREDFULL = f1 = 97.62, precision = 97.47, recall = 97.78\n",
      "          I-OBJ = f1 = 100.00, precision = 100.00, recall = 100.00\n",
      "     I-PREDFULL = f1 = 99.69, precision = 100.00, recall = 99.38\n",
      "              O = f1 = 99.95, precision = 99.96, recall = 99.94\n",
      "------------------------\n",
      "Macro-F1 = 99.392Macro-Prescion = 99.403Macro-Recall = 99.383\n",
      "\n",
      "\n",
      "++ predicting, batch 35/35 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 33.53, precision = 72.88, recall = 21.77\n",
      "     B-PREDFULL = f1 = 49.28, precision = 61.82, recall = 40.96\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 58.95, precision = 80.00, recall = 46.67\n",
      "              O = f1 = 95.32, precision = 92.01, recall = 98.87\n",
      "------------------------\n",
      "Macro-F1 = 47.414Macro-Prescion = 61.343Macro-Recall = 41.655\n",
      "\n",
      "\n",
      "++ predicting, batch 36/36 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 39.78, precision = 72.70, recall = 27.38\n",
      "     B-PREDFULL = f1 = 55.61, precision = 53.45, recall = 57.94\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 68.69, precision = 68.00, recall = 69.39\n",
      "              O = f1 = 95.58, precision = 92.93, recall = 98.37\n",
      "------------------------\n",
      "Macro-F1 = 51.929Macro-Prescion = 57.415Macro-Recall = 50.617\n",
      "\n",
      "== eval epoch 48/100 \"f1-macro\" train / dev / test | 99.39 / 47.41 / 51.93.\n",
      "## [no improvement micro-f1 on DEV during the last 41 epochs (best_f1_dev=54.02), 86 seconds].\n",
      "\n",
      "-- train epoch 49/100, batch 243/243 (100.00%), loss = 0.20.\n",
      "\n",
      "++ predicting, batch 243/243 (100.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 99.78, precision = 99.68, recall = 99.87\n",
      "     B-PREDFULL = f1 = 98.23, precision = 99.35, recall = 97.14\n",
      "          I-OBJ = f1 = 100.00, precision = 100.00, recall = 100.00\n",
      "     I-PREDFULL = f1 = 99.69, precision = 100.00, recall = 99.38\n",
      "              O = f1 = 99.96, precision = 99.96, recall = 99.97\n",
      "------------------------\n",
      "Macro-F1 = 99.532Macro-Prescion = 99.798Macro-Recall = 99.272\n",
      "\n",
      "\n",
      "++ predicting, batch 35/35 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 27.99, precision = 70.41, recall = 17.47\n",
      "     B-PREDFULL = f1 = 46.51, precision = 65.22, recall = 36.14\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 55.56, precision = 83.33, recall = 41.67\n",
      "              O = f1 = 95.17, precision = 91.60, recall = 99.03\n",
      "------------------------\n",
      "Macro-F1 = 45.046Macro-Prescion = 62.111Macro-Recall = 38.862\n",
      "\n",
      "\n",
      "++ predicting, batch 36/36 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 42.94, precision = 75.00, recall = 30.08\n",
      "     B-PREDFULL = f1 = 56.07, precision = 56.07, recall = 56.07\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 67.35, precision = 67.35, recall = 67.35\n",
      "              O = f1 = 95.71, precision = 93.10, recall = 98.46\n",
      "------------------------\n",
      "Macro-F1 = 52.413Macro-Prescion = 58.304Macro-Recall = 50.392\n",
      "\n",
      "== eval epoch 49/100 \"f1-macro\" train / dev / test | 99.53 / 45.05 / 52.41.\n",
      "## [no improvement micro-f1 on DEV during the last 42 epochs (best_f1_dev=54.02), 86 seconds].\n",
      "\n",
      "-- train epoch 50/100, batch 243/243 (100.00%), loss = 0.25.\n",
      "\n",
      "++ predicting, batch 243/243 (100.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 99.75, precision = 99.66, recall = 99.83\n",
      "     B-PREDFULL = f1 = 98.72, precision = 99.20, recall = 98.25\n",
      "          I-OBJ = f1 = 100.00, precision = 100.00, recall = 100.00\n",
      "     I-PREDFULL = f1 = 99.69, precision = 100.00, recall = 99.38\n",
      "              O = f1 = 99.96, precision = 99.96, recall = 99.96\n",
      "------------------------\n",
      "Macro-F1 = 99.625Macro-Prescion = 99.765Macro-Recall = 99.486\n",
      "\n",
      "\n",
      "++ predicting, batch 35/35 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 21.47, precision = 66.89, recall = 12.78\n",
      "     B-PREDFULL = f1 = 48.28, precision = 56.45, recall = 42.17\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 59.57, precision = 82.35, recall = 46.67\n",
      "              O = f1 = 94.98, precision = 91.29, recall = 98.98\n",
      "------------------------\n",
      "Macro-F1 = 44.860Macro-Prescion = 59.397Macro-Recall = 40.121\n",
      "\n",
      "\n",
      "++ predicting, batch 36/36 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 38.45, precision = 73.02, recall = 26.09\n",
      "     B-PREDFULL = f1 = 60.18, precision = 57.14, recall = 63.55\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 68.69, precision = 68.00, recall = 69.39\n",
      "              O = f1 = 95.59, precision = 92.89, recall = 98.45\n",
      "------------------------\n",
      "Macro-F1 = 52.580Macro-Prescion = 58.210Macro-Recall = 51.497\n",
      "\n",
      "== eval epoch 50/100 \"f1-macro\" train / dev / test | 99.63 / 44.86 / 52.58.\n",
      "## [no improvement micro-f1 on DEV during the last 43 epochs (best_f1_dev=54.02), 88 seconds].\n",
      "\n",
      "-- train epoch 51/100, batch 243/243 (100.00%), loss = 0.38.\n",
      "\n",
      "++ predicting, batch 243/243 (100.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 99.69, precision = 99.57, recall = 99.81\n",
      "     B-PREDFULL = f1 = 98.64, precision = 99.20, recall = 98.10\n",
      "          I-OBJ = f1 = 100.00, precision = 100.00, recall = 100.00\n",
      "     I-PREDFULL = f1 = 99.69, precision = 100.00, recall = 99.38\n",
      "              O = f1 = 99.96, precision = 99.96, recall = 99.95\n",
      "------------------------\n",
      "Macro-F1 = 99.597Macro-Prescion = 99.746Macro-Recall = 99.449\n",
      "\n",
      "\n",
      "++ predicting, batch 35/35 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 23.77, precision = 67.46, recall = 14.43\n",
      "     B-PREDFULL = f1 = 51.61, precision = 55.56, recall = 48.19\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 63.55, precision = 72.34, recall = 56.67\n",
      "              O = f1 = 95.01, precision = 91.53, recall = 98.77\n",
      "------------------------\n",
      "Macro-F1 = 46.790Macro-Prescion = 57.375Macro-Recall = 43.613\n",
      "\n",
      "\n",
      "++ predicting, batch 36/36 (98.00%).\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 38.82, precision = 74.73, recall = 26.22\n",
      "     B-PREDFULL = f1 = 57.76, precision = 53.60, recall = 62.62\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 70.48, precision = 66.07, recall = 75.51\n",
      "              O = f1 = 95.58, precision = 92.91, recall = 98.41\n",
      "------------------------\n",
      "Macro-F1 = 52.527Macro-Prescion = 57.462Macro-Recall = 52.551\n",
      "\n",
      "== eval epoch 51/100 \"f1-macro\" train / dev / test | 99.60 / 46.79 / 52.53.\n",
      "## [no improvement micro-f1 on DEV during the last 44 epochs (best_f1_dev=54.02), 87 seconds].\n",
      "\n",
      "Evaluation\n",
      "\n",
      "batch_size=10\n",
      "bert=False\n",
      "char_cnn_filter_num=30\n",
      "char_embeddings_dim=25\n",
      "char_window_size=3\n",
      "check_for_lowercase=True\n",
      "clip_grad=5\n",
      "cross_fold_id=-1\n",
      "cross_folds_num=-1\n",
      "data_io='connl-ner-2003'\n",
      "dataset_sort=False\n",
      "dev='/home/vika/targer/data/NER/Varvara/dev.csv'\n",
      "dropout_ratio=0.5\n",
      "elmo=True\n",
      "elmo_options_fn='embeddings/elmo_2x4096_512_2048cnn_2xhighway_5.5B_options.json'\n",
      "elmo_weights_fn='/home/vika/targer/embeddings/elmo_2x4096_512_2048cnn_2xhighway_5.5B_weights.hdf5'\n",
      "emb_delimiter=' '\n",
      "emb_dim=100\n",
      "emb_fn='embeddings/glove.6B.100d.txt'\n",
      "emb_load_all=False\n",
      "epoch_num=100\n",
      "evaluator='f1-macro'\n",
      "freeze_char_embeddings=False\n",
      "freeze_word_embeddings=False\n",
      "gpu=2\n",
      "load=None\n",
      "lr=0.001\n",
      "lr_decay=0.05\n",
      "min_epoch_num=50\n",
      "model='BiRNN'\n",
      "momentum=0.9\n",
      "opt='adam'\n",
      "path_to_bert='pretrained'\n",
      "patience=20\n",
      "report_fn='2019_10_03_22-53_07_report.txt'\n",
      "rnn_hidden_dim=200\n",
      "rnn_type='LSTM'\n",
      "save='2019_10_03_22-53_07_tagger.hdf5'\n",
      "save_best=True\n",
      "seed_num=42\n",
      "test='/home/vika/targer/data/NER/Varvara/test.csv'\n",
      "train='/home/vika/targer/data/NER/Varvara/train.csv'\n",
      "verbose=True\n",
      "word_len=20\n",
      "word_seq_indexer=None\n",
      "\n",
      "         epoch  |     train loss | f1-macro-train |   f1-macro-dev |  f1-macro-test \n",
      "--------------------------------------------------------------------------------------\n",
      "              0 |           0.00 |           3.63 |           2.30 |           3.08 \n",
      "              1 |          15.63 |          55.99 |          52.55 |          53.72 \n",
      "              2 |           7.99 |          47.12 |          37.56 |          39.80 \n",
      "              3 |           6.37 |          57.20 |          52.19 |          52.85 \n",
      "              4 |           6.29 |          63.95 |          38.74 |          38.11 \n",
      "              5 |           5.81 |          71.30 |          31.80 |          34.01 \n",
      "              6 |           5.14 |          79.37 |          48.86 |          53.96 \n",
      "              7 |           4.23 |          80.63 |          54.02 |          56.89 \n",
      "              8 |           3.81 |          82.40 |          49.52 |          50.68 \n",
      "              9 |           3.36 |          86.07 |          43.69 |          50.18 \n",
      "             10 |           2.19 |          77.78 |          35.58 |          40.71 \n",
      "             11 |           3.33 |          85.63 |          42.05 |          41.63 \n",
      "             12 |           2.49 |          88.85 |          44.92 |          47.92 \n",
      "             13 |           2.85 |          88.14 |          45.92 |          50.21 \n",
      "             14 |           2.84 |          89.28 |          51.31 |          54.60 \n",
      "             15 |           2.08 |          90.37 |          49.95 |          51.42 \n",
      "             16 |           2.21 |          90.67 |          46.46 |          52.40 \n",
      "             17 |           1.78 |          91.06 |          39.57 |          41.47 \n",
      "             18 |           2.02 |          90.84 |          41.48 |          45.62 \n",
      "             19 |           1.81 |          91.25 |          40.35 |          45.41 \n",
      "             20 |           1.81 |          91.14 |          38.41 |          41.57 \n",
      "             21 |           1.74 |          92.87 |          41.22 |          45.48 \n",
      "             22 |           1.46 |          93.82 |          41.58 |          45.92 \n",
      "             23 |           1.62 |          93.25 |          43.83 |          47.19 \n",
      "             24 |           1.20 |          93.90 |          37.42 |          42.58 \n",
      "             25 |           1.59 |          95.23 |          50.10 |          51.32 \n",
      "             26 |           1.10 |          95.06 |          50.44 |          54.31 \n",
      "             27 |           1.27 |          96.00 |          43.28 |          50.56 \n",
      "             28 |           0.96 |          95.55 |          41.85 |          47.23 \n",
      "             29 |           1.16 |          95.79 |          44.52 |          52.81 \n",
      "             30 |           0.72 |          95.87 |          47.45 |          53.45 \n",
      "             31 |           0.90 |          94.46 |          47.67 |          53.62 \n",
      "             32 |           0.64 |          96.40 |          40.19 |          49.13 \n",
      "             33 |           0.77 |          96.27 |          44.26 |          53.68 \n",
      "             34 |           0.60 |          96.72 |          43.92 |          53.41 \n",
      "             35 |           1.15 |          97.95 |          44.93 |          51.24 \n",
      "             36 |           0.66 |          98.88 |          43.94 |          52.64 \n",
      "             37 |           0.60 |          99.09 |          43.41 |          50.93 \n",
      "             38 |           0.49 |          98.91 |          44.21 |          52.05 \n",
      "             39 |           0.40 |          99.00 |          46.59 |          51.77 \n",
      "             40 |           0.34 |          99.01 |          46.31 |          53.20 \n",
      "             41 |           0.36 |          98.62 |          47.09 |          53.07 \n",
      "             42 |           0.32 |          99.26 |          47.89 |          51.85 \n",
      "             43 |           0.32 |          99.25 |          48.03 |          53.67 \n",
      "             44 |           0.29 |          99.29 |          45.53 |          52.53 \n",
      "             45 |           0.32 |          99.30 |          42.34 |          50.59 \n",
      "             46 |           0.28 |          99.41 |          42.53 |          52.67 \n",
      "             47 |           0.20 |          99.40 |          45.99 |          53.85 \n",
      "             48 |           0.18 |          99.39 |          47.41 |          51.93 \n",
      "             49 |           0.20 |          99.53 |          45.05 |          52.41 \n",
      "             50 |           0.25 |          99.63 |          44.86 |          52.58 \n",
      "             51 |           0.38 |          99.60 |          46.79 |          52.53 \n",
      "--------------------------------------------------------------------------------------\n",
      "Final eval on test, \"save best\", best epoch on dev 7, f1-macro, test = 56.89)\n",
      "--------------------------------------------------------------------------------------\n",
      "F1 scores\n",
      "------------------------\n",
      "          B-OBJ = f1 = 64.64, precision = 82.31, recall = 53.21\n",
      "     B-PREDFULL = f1 = 58.22, precision = 58.49, recall = 57.94\n",
      "          I-OBJ = f1 = 0.00, precision = 0.00, recall = 0.00\n",
      "     I-PREDFULL = f1 = 65.04, precision = 54.05, recall = 81.63\n",
      "              O = f1 = 96.55, precision = 94.96, recall = 98.20\n",
      "------------------------\n",
      "Macro-F1 = 56.889Macro-Prescion = 57.962Macro-Recall = 58.198\n",
      "Input arguments:\n",
      "python3 main.py --train /home/vika/targer/data/NER/Varvara/train.csv --dev /home/vika/targer/data/NER/Varvara/dev.csv --data-io connl-ner-2003 --evaluator f1-macro --model BiRNN --opt adam --lr 0.001 --save-best yes --patience 20 --rnn-hidden-dim 200 --gpu 2 --test /home/vika/targer/data/NER/Varvara/test.csv --elmo True\n",
      "\n",
      "56.8891\n"
     ]
    }
   ],
   "source": [
    "! python3 main.py --train \"/home/vika/targer/data/NER/Varvara/train.csv\" --dev \"/home/vika/targer/data/NER/Varvara/dev.csv\" --data-io connl-ner-2003 --evaluator f1-macro --model 'BiRNN' --opt adam --lr 0.001 --save-best yes --patience 20 --rnn-hidden-dim 200 --gpu 2 --test \"/home/vika/targer/data/NER/Varvara/test.csv\" --elmo True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.modules.elmo import Elmo, batch_to_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [['1tb', 'of', 'mechanical', 'storage', 'is', \"n't\", 'bad', '\"', 'but', 'toshiba', 'hard', 'drives', 'really', 'are', \"n't\", 'what', 'we', 'want', 'to', 'be', 'seeing', 'as', 'they', 'tend', 'to', 'be', 'a', 'bit', 'slower', 'than', 'competing', 'drives', 'from', 'hgst', '\"', 'western', 'digital', '\"', 'samsung', '\"', 'and', 'seagate', '.'],  ['we', 'have', 'found', 'that', 'blood', 'carbon', 'and', 'nitrogen', 'turnover', 'was', 'roughly', 'equivalent', 'in', 'mice', 'and', 'in', 'rats', '\"', 'and', 'that', 'mouse', 'blood', 'turned', 'over', 'slightly', 'faster', 'than', 'rat', 'blood', '.']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('1tb', 'O')\n",
      "('of', 'O')\n",
      "('mechanical', 'O')\n",
      "('storage', 'O')\n",
      "('is', 'O')\n",
      "(\"n't\", 'O')\n",
      "('bad', 'O')\n",
      "('\"', 'O')\n",
      "('but', 'O')\n",
      "('toshiba', 'B-OTHOBJ')\n",
      "('hard', 'O')\n",
      "('drives', 'O')\n",
      "('really', 'O')\n",
      "('are', 'O')\n",
      "(\"n't\", 'O')\n",
      "('what', 'O')\n",
      "('we', 'O')\n",
      "('want', 'O')\n",
      "('to', 'O')\n",
      "('be', 'O')\n",
      "('seeing', 'O')\n",
      "('as', 'O')\n",
      "('they', 'O')\n",
      "('tend', 'O')\n",
      "('to', 'O')\n",
      "('be', 'O')\n",
      "('a', 'O')\n",
      "('bit', 'O')\n",
      "('slower', 'O')\n",
      "('than', 'O')\n",
      "('competing', 'O')\n",
      "('drives', 'O')\n",
      "('from', 'O')\n",
      "('hgst', 'O')\n",
      "('\"', 'O')\n",
      "('western', 'O')\n",
      "('digital', 'O')\n",
      "('\"', 'O')\n",
      "('samsung', 'B-ASPOBJ')\n",
      "('\"', 'O')\n",
      "('and', 'O')\n",
      "('seagate', 'O')\n",
      "('.', 'O')\n"
     ]
    }
   ],
   "source": [
    "for elem in zip(sentences[0], tags[0]):\n",
    "    print (elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%)."
     ]
    }
   ],
   "source": [
    "from src.factories.factory_tagger import TaggerFactory\n",
    "import torch\n",
    "\n",
    "model = TaggerFactory.load(\"2019_09_24_10-48_48_tagger.hdf5\")\n",
    "model.gpu = 1\n",
    "model.cuda(device = 1)\n",
    "\n",
    "\n",
    "tags = model.predict_tags_from_words(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /opt/anaconda/lib/python3.6/site-packages (18.1)\n",
      "Collecting install\n",
      "\u001b[33m  Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<pip._vendor.urllib3.connection.VerifiedHTTPSConnection object at 0x7f23f7295240>, 'Connection to pypi.org timed out. (connect timeout=15)')': /simple/install/\u001b[0m\n",
      "\u001b[33m  Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<pip._vendor.urllib3.connection.VerifiedHTTPSConnection object at 0x7f23f72951d0>, 'Connection to pypi.org timed out. (connect timeout=15)')': /simple/install/\u001b[0m\n",
      "\u001b[33m  Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<pip._vendor.urllib3.connection.VerifiedHTTPSConnection object at 0x7f23f72950f0>, 'Connection to pypi.org timed out. (connect timeout=15)')': /simple/install/\u001b[0m\n",
      "\u001b[33m  Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<pip._vendor.urllib3.connection.VerifiedHTTPSConnection object at 0x7f23f7295eb8>, 'Connection to pypi.org timed out. (connect timeout=15)')': /simple/install/\u001b[0m\n",
      "^C\n",
      "\u001b[31mOperation cancelled by user\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip3 install pip install --trusted-host=pypi.python.org --trusted-host=pypi.org --trusted-host=files.pythonhosted.org pytorch-pretrained-bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BertTokenizer' object has no attribute 'encode'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-51f29d9cf921>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Let's see all hidden-states and attentions on this text\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'BertTokenizer' object has no attribute 'encode'"
     ]
    }
   ],
   "source": [
    "input_ids = torch.tensor([tokenizer.encode(\"Let's see all hidden-states and attentions on this text\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'string' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-7d756f7a8a8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bert-base-uncased'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'string' is not defined"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "words = string.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [['we', 'have', 'found', 'that', 'blood', 'carbon', 'and', 'nitrogen', 'turnover', 'was', 'roughly', 'equivalent'], ['in', 'mice', 'and', 'in', 'rats', '\"', 'and', 'that', 'mouse', 'blood', 'turned', 'over','.']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', '##ha', '##ve', '##fo', '##und', '##tha', '##t', '##blood', '##carbon', '##and', '##ni', '##tro', '##gent', '##urn', '##over', '##was', '##rou', '##gh', '##ly', '##e', '##qui', '##valent']\n"
     ]
    }
   ],
   "source": [
    "tokenized_texts = [tokenizer.tokenize(''.join(sent)) for sent in sentences]\n",
    "print(tokenized_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "MAX_LEN = np.max(np.array([len(seq) for seq in tokenized_texts]))\n",
    "input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts], maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sequence item 0: expected str instance, list found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-d45856db5fe6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: sequence item 0: expected str instance, list found"
     ]
    }
   ],
   "source": [
    "words = ''.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(indexed_tokens2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_tensor = torch.tensor(input_ids)\n",
    "segments_tensors = torch.tensor(np.ones(input_ids.shape)).to(torch.int64)\n",
    "\n",
    "# Load pre-trained model (weights)\n",
    "model = BertModel.from_pretrained(\"pretrained\")#BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
    "#model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tokens_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(segments_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    encoded_layers, _ = model(tokens_tensor, segments_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoded_layers[2][1][21])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30522"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_embeddings = [] \n",
    "\n",
    "# For each token in the sentence...\n",
    "for token_i in range(len(tokenized_text)):  \n",
    "    # Holds 12 layers of hidden states for each token \n",
    "    hidden_layers = [] \n",
    "    # For each of the 12 layers...\n",
    "    for layer_i in range(len(encoded_layers)):\n",
    "    # Lookup the vector for `token_i` in `layer_i`\n",
    "        vec = encoded_layers[layer_i][0][token_i]\n",
    "        hidden_layers.append(vec)\n",
    "        token_embeddings.append(hidden_layers)\n",
    "\n",
    "summed_last_4_layers = [torch.sum(torch.stack(layer)[-4:], 0) for layer in token_embeddings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "540"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(summed_last_4_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Here is the sentence I want embeddings for.\"\n",
    "text = \"After stealing money from the bank vault, the bank robber was seen fishing on the Mississippi river bank.\"\n",
    "marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "\n",
    "print (marked_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.modules.elmo import Elmo, batch_to_ids\n",
    "\n",
    "options_file = \"embeddings/elmo_2x4096_512_2048cnn_2xhighway_5.5B_options.json\"\n",
    "weight_file = \"/home/vika/targer/embeddings/elmo_2x4096_512_2048cnn_2xhighway_5.5B_weights.hdf5\"\n",
    "\n",
    "# Compute two different representation for each token.\n",
    "# Each representation is a linear weighted combination for the\n",
    "# 3 layers in ELMo (i.e., charcnn, the outputs of the two BiLSTM))\n",
    "elmo = Elmo(options_file, weight_file, 2, dropout=0)\n",
    "\n",
    "# use batch_to_ids to convert sentences to character ids\n",
    "sentences = [['1tb', 'of', 'mechanical', 'storage', 'is', \"n't\", 'bad', '\"', 'but', 'toshiba', 'hard', 'drives', 'really', 'are', \"n't\", 'what', 'we', 'want', 'to', 'be', 'seeing', 'as', 'they', 'tend', 'to', 'be', 'a', 'bit', 'slower', 'than', 'competing', 'drives', 'from', 'hgst', '\"', 'western', 'digital', '\"', 'samsung', '\"', 'and', 'seagate', '.'], ['amazon', 'is', 'another', 'good', 'choice', '\"', 'and', 'i', 'actually', 'prefer', 'their', 'interface', 'better', 'than', 'itunes', '', '(', 'it', 'loads', 'faster', 'for', 'me', ')', '.'], ['well-designed', '\"', 'properly', 'constructed', 'timber', 'buildings', 'can', 'be', 'even', 'safer', 'in', 'earthquakes', 'than', 'ferro-concrete', 'ones', '.'], ['maybe', 'it', 's', 'because', 'i', 'm', 'a', 'ku', 'fan', '\"', 'but', 'i', 'honestly', 'like', 'the', 'looks', 'of', 'adidas', 'uniforms', 'better', 'than', 'nike', '.'], ['soft', 'drinks', 'do', 'not', 'include', 'beverages', 'that', 'contain', 'milk', 'or', 'milk', 'products', '\"', 'soy', '\"', 'rice', 'or', 'similar', 'milk', 'substitutes', '\"', 'or', 'greater', 'than', '50', '%', 'of', 'vegetable', 'or', 'fruit', 'juice', 'by', 'volume', '.'], ['partly', 'because', 'i', 'like', 'apple', 's', 'choice', 'of', 'file', 'format', '-', 'aac', 'is', 'much', 'more', 'modern', 'than', 'mp3', '\"', 'and', 'theoretically', 'an', 'aac', 'file', 'at', '256kbps', '(', 'from', 'itunes', 'plus', ')', 'sounds', 'better', 'than', 'an', 'mp3', 'file', 'at', '256kbps', '(', 'from', 'amazon', ')', '.'], ['and', 'nokia', 'is', 'easier', 'to', 'use', '...', '...', 'it', 'easily', 'gets', 'infected', 'with', 'virus', 'and', 'the', 'net', 'speed', 'is', 'not', 'fast', '...', '..and', 'ofcourse', 'nokia', 'is', 'way', 'more', 'reliable', 'than', 'samsung', '...', '..go', 'for', 'nokia', '...', '..this', 'phone', 'suxxxxxxxxxxxxxxxxxxxxxx', '!'], ['java', 'is', 'a', 'static', 'type', 'language', 'and', 'it', 'is', 'safer', 'than', 'dynamic', 'type', 'languages', 'like', 'ruby', '.'], ['amazon', 'music', 'will', 'be', 'cheaper', '\"', 'faster', 'and', 'perceived', 'to', 'be', 'more', 'honest', 'than', 'itunes', 'both', 'by', 'customers', 'and', 'musicians', '.'], \n",
    "             ['we', 'have', 'found', 'that', 'blood', 'carbon', 'and', 'nitrogen', 'turnover', 'was', 'roughly', 'equivalent', 'in', 'mice', 'and', 'in', 'rats', '\"', 'and', 'that', 'mouse', 'blood', 'turned', 'over', 'slightly', 'faster', 'than', 'rat', 'blood', '.']]\n",
    "\n",
    "character_ids = batch_to_ids(sentences)\n",
    "\n",
    "embeddings = elmo(character_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elmo.get_output_dim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 44, 50])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "character_ids.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([259, 113, 115, 112, 113, 102, 115, 109, 122, 260, 261, 261, 261, 261,\n",
       "        261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "        261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "        261, 261, 261, 261, 261, 261, 261, 261])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "character_ids[2][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4785, -0.4598, -0.0396,  ..., -0.1577, -0.3011, -0.1590],\n",
      "       grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "print (embeddings['elmo_representations'][1][5][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4785, -0.4598, -0.0396,  ..., -0.1577, -0.3011, -0.1590],\n",
      "       grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "print (embeddings['elmo_representations'][0][5][5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## birnn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BiRNNCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args train = /home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_train.csv\n",
      "Loading from /home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_train.csv: 2619 samples, 74616 words.\n",
      "Loading from /home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_test.csv: 523 samples, 14728 words.\n",
      "Loading from /home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_test.csv: 523 samples, 14728 words.\n",
      "word_sequences_dev 523 [['and', 'can', 'i', 'just', 'say', 'that', 'doing', 'the', 'inferno', 'move', 'on', 'the', 'ds', 'is', '50', 'times', 'easier', 'than', 'trying', 'to', 'make', 'an', 'infinity', 'symbol', 'using', 'the', 'wii', 'remote', '.'], ['i', 'go', 'to', 'the', 'amazon', 'mp3', 'store', '(', 'better', 'than', 'itunes', '.'], ['tea', 'dinner', '(', 'sorry', '\"', 'my', 'wife', 'is', 'trying', 'to', 'make', 'me', 'posherer', ')', 'and', 'picking', 'up', 'a', 'phone', 'is', 'easier', '-', 'then', 'i', 'can', 'swig', 'my', 'beer', 'and', 'relaaaaxxxx', '...', '.', '.'], ['actually', 'for', 'many', 'windows', 'xp', 'users', 'it', 'is', 'easier', 'to', 'migrate', 'to', 'linux', 'mint', 'than', 'to', 'windows', '8', '.'], ['this', 'is', 'why', 'the', 'better', 'team', 'wins', 'any', 'given', 'basketball', 'game', 'with', 'far', 'greater', 'frequency', 'than', 'it', 'does', 'in', 'baseball', '\"', 'football', 'or', 'hockey', '.']]\n",
      "tag_sequences_train 523 [['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ASPOBJ', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-OTHOBJ', 'O', 'O'], ['O', 'O', 'O', 'O', 'B-ASPOBJ', 'O', 'O', 'O', 'O', 'O', 'B-OTHOBJ', 'O'], ['B-ASPOBJ', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-OTHOBJ', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'B-ASPOBJ', 'I-ASPOBJ', 'O', 'O', 'O', 'B-ASP', 'I-ASP', 'I-ASP', 'I-ASP', 'I-ASP', 'I-ASP', 'O', 'O', 'B-OTHOBJ', 'I-OTHOBJ', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ASPOBJ', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-OTHOBJ', 'O', 'O', 'O', 'O', 'O']]\n",
      "DatasetsBank: len(unique_words_list) = 7143 unique words.\n",
      "DatasetsBank: len(unique_words_list) = 7753 unique words.\n",
      "DatasetsBank: len(unique_words_list) = 7753 unique words.\n",
      "Reading embeddings file embeddings/glove.6B.100d.txt, line = 0\n",
      "Reading embeddings file embeddings/glove.6B.100d.txt, line = 25000\n",
      "Reading embeddings file embeddings/glove.6B.100d.txt, line = 50000\n",
      "Reading embeddings file embeddings/glove.6B.100d.txt, line = 75000\n",
      "Reading embeddings file embeddings/glove.6B.100d.txt, line = 100000\n",
      "Reading embeddings file embeddings/glove.6B.100d.txt, line = 125000\n",
      "Reading embeddings file embeddings/glove.6B.100d.txt, line = 150000\n",
      "Reading embeddings file embeddings/glove.6B.100d.txt, line = 175000\n",
      "Reading embeddings file embeddings/glove.6B.100d.txt, line = 200000\n",
      "Reading embeddings file embeddings/glove.6B.100d.txt, line = 225000\n",
      "Reading embeddings file embeddings/glove.6B.100d.txt, line = 250000\n",
      "Reading embeddings file embeddings/glove.6B.100d.txt, line = 275000\n",
      "Reading embeddings file embeddings/glove.6B.100d.txt, line = 300000\n",
      "Reading embeddings file embeddings/glove.6B.100d.txt, line = 325000\n",
      "Reading embeddings file embeddings/glove.6B.100d.txt, line = 350000\n",
      "Reading embeddings file embeddings/glove.6B.100d.txt, line = 375000\n",
      "Reading embeddings file embeddings/glove.6B.100d.txt, line = 0\n",
      "Reading embeddings file embeddings/glove.6B.100d.txt, line = 25000\n",
      "Reading embeddings file embeddings/glove.6B.100d.txt, line = 50000\n",
      "Reading embeddings file embeddings/glove.6B.100d.txt, line = 75000\n",
      "Reading embeddings file embeddings/glove.6B.100d.txt, line = 100000\n",
      "Reading embeddings file embeddings/glove.6B.100d.txt, line = 125000\n",
      "Reading embeddings file embeddings/glove.6B.100d.txt, line = 150000\n",
      "Reading embeddings file embeddings/glove.6B.100d.txt, line = 175000\n",
      "Reading embeddings file embeddings/glove.6B.100d.txt, line = 200000\n",
      "Reading embeddings file embeddings/glove.6B.100d.txt, line = 225000\n",
      "Reading embeddings file embeddings/glove.6B.100d.txt, line = 250000\n",
      "Reading embeddings file embeddings/glove.6B.100d.txt, line = 275000\n",
      "Reading embeddings file embeddings/glove.6B.100d.txt, line = 300000\n",
      "Reading embeddings file embeddings/glove.6B.100d.txt, line = 325000\n",
      "Reading embeddings file embeddings/glove.6B.100d.txt, line = 350000\n",
      "Reading embeddings file embeddings/glove.6B.100d.txt, line = 375000\n",
      "\n",
      "load_vocabulary_from_embeddings_file_and_unique_words_list:\n",
      "    First 50 OOV words:\n",
      "        out_of_vocabulary_words_list[0] = b'1tb'\n",
      "        out_of_vocabulary_words_list[1] = b'hgst'\n",
      "        out_of_vocabulary_words_list[2] = b''\n",
      "        out_of_vocabulary_words_list[3] = b'256kbps'\n",
      "        out_of_vocabulary_words_list[4] = b'..and'\n",
      "        out_of_vocabulary_words_list[5] = b'ofcourse'\n",
      "        out_of_vocabulary_words_list[6] = b'..go'\n",
      "        out_of_vocabulary_words_list[7] = b'..this'\n",
      "        out_of_vocabulary_words_list[8] = b'suxxxxxxxxxxxxxxxxxxxxxx'\n",
      "        out_of_vocabulary_words_list[9] = b'e2252'\n",
      "        out_of_vocabulary_words_list[10] = b'monkeypatch'\n",
      "        out_of_vocabulary_words_list[11] = b'mssql'\n",
      "        out_of_vocabulary_words_list[12] = b'eccoboard\\xe2\\x84\\xa2'\n",
      "        out_of_vocabulary_words_list[13] = b'bmw-mercedes'\n",
      "        out_of_vocabulary_words_list[14] = b'goung'\n",
      "        out_of_vocabulary_words_list[15] = b'head-'\n",
      "        out_of_vocabulary_words_list[16] = b'jumbo-shrimp'\n",
      "        out_of_vocabulary_words_list[17] = b'discount-lexus'\n",
      "        out_of_vocabulary_words_list[18] = b'quicker-than-a-cayman'\n",
      "        out_of_vocabulary_words_list[19] = b\"cat's-meow\"\n",
      "        out_of_vocabulary_words_list[20] = b'current-season'\n",
      "        out_of_vocabulary_words_list[21] = b'all-plastic'\n",
      "        out_of_vocabulary_words_list[22] = b'fan-friendly'\n",
      "        out_of_vocabulary_words_list[23] = b'siginificantly'\n",
      "        out_of_vocabulary_words_list[24] = b'games.as'\n",
      "        out_of_vocabulary_words_list[25] = b'for.so'\n",
      "        out_of_vocabulary_words_list[26] = b'power/graphics'\n",
      "        out_of_vocabulary_words_list[27] = b'nv3500'\n",
      "        out_of_vocabulary_words_list[28] = b'350c'\n",
      "        out_of_vocabulary_words_list[29] = b'gretest'\n",
      "        out_of_vocabulary_words_list[30] = b'intoduced'\n",
      "        out_of_vocabulary_words_list[31] = b'mw2'\n",
      "        out_of_vocabulary_words_list[32] = b'yet.it'\n",
      "        out_of_vocabulary_words_list[33] = b'incredebly'\n",
      "        out_of_vocabulary_words_list[34] = b'5000000000000'\n",
      "        out_of_vocabulary_words_list[35] = b'fire-power'\n",
      "        out_of_vocabulary_words_list[36] = b'o3d'\n",
      "        out_of_vocabulary_words_list[37] = b'300x'\n",
      "        out_of_vocabulary_words_list[38] = b'frats'\n",
      "        out_of_vocabulary_words_list[39] = b'jaronczyk'\n",
      "        out_of_vocabulary_words_list[40] = b'import-intenders'\n",
      "        out_of_vocabulary_words_list[41] = b'stodgy-looking'\n",
      "        out_of_vocabulary_words_list[42] = b'sloppy-handling'\n",
      "        out_of_vocabulary_words_list[43] = b'platform-sharing'\n",
      "        out_of_vocabulary_words_list[44] = b'all-weather-wood'\n",
      "        out_of_vocabulary_words_list[45] = b'awwf'\n",
      "        out_of_vocabulary_words_list[46] = b'maniculatus'\n",
      "        out_of_vocabulary_words_list[47] = b'rdbsm'\n",
      "        out_of_vocabulary_words_list[48] = b'hardibacker'\n",
      "        out_of_vocabulary_words_list[49] = b'cement/gypsum'\n",
      "        out_of_vocabulary_words_list[50] = b'atii'\n",
      " -- len(out_of_vocabulary_words_list) = 735\n",
      " -- original_words_num = 7013\n",
      " -- lowercase_words_num = 1\n",
      " -- zero_digits_replaced_num = 4\n",
      " -- zero_digits_replaced_lowercase_num = 0\n",
      "\n",
      "load_vocabulary_from_tag_sequences:\n",
      " -- class_num = 7\n",
      " -- {'<pad>': 0, 'O': 1, 'B-OTHOBJ': 2, 'B-ASPOBJ': 3, 'B-ASP': 4, 'I-ASP': 5, 'I-ASPOBJ': 6, 'I-OTHOBJ': 7}\n",
      "Empirical transition matrix from the train dataset:\n",
      "               <pad>         O  B-OTHOBJ  B-ASPOBJ     B-ASP     I-ASP  I-ASPOBJ  I-OTHOBJ     <sos>\n",
      "\n",
      "     <pad>       0.0       0.0       0.0       0.0       0.0       0.0       0.0       0.0       0.0\n",
      "         O       0.0   58639.0    2722.0    2863.0     792.0     165.0      22.0      21.0    2226.0\n",
      "  B-OTHOBJ       0.0    2713.0       0.0       1.0       3.0       1.0       0.0       0.0      47.0\n",
      "  B-ASPOBJ       0.0    2560.0       8.0       0.0       4.0       3.0       0.0       0.0     341.0\n",
      "     B-ASP       0.0     919.0      14.0      28.0       0.0       0.0       0.0       0.0       5.0\n",
      "     I-ASP       0.0       0.0       0.0       2.0     167.0     307.0       0.0       0.0       0.0\n",
      "  I-ASPOBJ       0.0       0.0       0.0      22.0       0.0       0.0       0.0       0.0       0.0\n",
      "  I-OTHOBJ       0.0       0.0      21.0       0.0       0.0       0.0       0.0       0.0       0.0\n",
      "     <sos>       0.0       0.0       0.0       0.0       0.0       0.0       0.0       0.0       0.0\n",
      "\n",
      "Initialized transition matrix:\n",
      "               <pad>         O  B-OTHOBJ  B-ASPOBJ     B-ASP     I-ASP  I-ASPOBJ  I-OTHOBJ     <sos>\n",
      "\n",
      "     <pad>   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0\n",
      "         O   -9999.0      -1.1      -1.1      -0.9      -1.0      -1.0      -1.1      -1.0      -1.0\n",
      "  B-OTHOBJ   -9999.0      -1.0   -9999.0      -1.0      -1.2      -0.9   -9999.0   -9999.0      -0.9\n",
      "  B-ASPOBJ   -9999.0      -0.9      -1.0   -9999.0      -1.0      -0.8   -9999.0   -9999.0      -1.0\n",
      "     B-ASP   -9999.0      -1.1      -1.0      -1.0   -9999.0   -9999.0   -9999.0   -9999.0      -1.1\n",
      "     I-ASP   -9999.0   -9999.0   -9999.0      -1.1      -0.9      -1.0   -9999.0   -9999.0   -9999.0\n",
      "  I-ASPOBJ   -9999.0   -9999.0   -9999.0      -1.0   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0\n",
      "  I-OTHOBJ   -9999.0   -9999.0      -1.0   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0\n",
      "     <sos>   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0\n",
      "\n",
      "Start training...\n",
      "\n",
      "\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 0/100 \"f1-alpha-match-10\" train / dev / test | 3.48 / 3.55 / 3.55.\n",
      "## [BEST epoch], 11 seconds.\n",
      "\n",
      "-- train epoch 1/100, batch 261/261 (100.00%), loss = 709.25.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 1/100 \"f1-alpha-match-10\" train / dev / test | 60.42 / 59.59 / 59.59.\n",
      "## [BEST epoch], 67 seconds.\n",
      "\n",
      "-- train epoch 2/100, batch 261/261 (100.00%), loss = 394.92.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 2/100 \"f1-alpha-match-10\" train / dev / test | 69.55 / 66.87 / 66.87.\n",
      "## [BEST epoch], 69 seconds.\n",
      "\n",
      "-- train epoch 3/100, batch 261/261 (100.00%), loss = 341.32.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 3/100 \"f1-alpha-match-10\" train / dev / test | 72.22 / 67.51 / 67.51.\n",
      "## [BEST epoch], 69 seconds.\n",
      "\n",
      "-- train epoch 4/100, batch 261/261 (100.00%), loss = 328.28.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 4/100 \"f1-alpha-match-10\" train / dev / test | 74.17 / 71.47 / 71.47.\n",
      "## [BEST epoch], 69 seconds.\n",
      "\n",
      "-- train epoch 5/100, batch 261/261 (100.00%), loss = 305.78.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 5/100 \"f1-alpha-match-10\" train / dev / test | 75.36 / 72.44 / 72.44.\n",
      "## [BEST epoch], 74 seconds.\n",
      "\n",
      "-- train epoch 6/100, batch 261/261 (100.00%), loss = 301.25.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 6/100 \"f1-alpha-match-10\" train / dev / test | 77.64 / 76.34 / 76.34.\n",
      "## [BEST epoch], 73 seconds.\n",
      "\n",
      "-- train epoch 7/100, batch 261/261 (100.00%), loss = 250.16.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 7/100 \"f1-alpha-match-10\" train / dev / test | 76.98 / 75.18 / 75.18.\n",
      "## [no improvement micro-f1 on DEV during the last 1 epochs (best_f1_dev=76.34), 71 seconds].\n",
      "\n",
      "-- train epoch 8/100, batch 261/261 (100.00%), loss = 220.17.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 8/100 \"f1-alpha-match-10\" train / dev / test | 79.53 / 77.39 / 77.39.\n",
      "## [BEST epoch], 73 seconds.\n",
      "\n",
      "-- train epoch 9/100, batch 261/261 (100.00%), loss = 221.51.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 9/100 \"f1-alpha-match-10\" train / dev / test | 80.71 / 78.51 / 78.51.\n",
      "## [BEST epoch], 74 seconds.\n",
      "\n",
      "-- train epoch 10/100, batch 261/261 (100.00%), loss = 228.58.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 10/100 \"f1-alpha-match-10\" train / dev / test | 80.51 / 78.53 / 78.53.\n",
      "## [BEST epoch], 67 seconds.\n",
      "\n",
      "-- train epoch 11/100, batch 261/261 (100.00%), loss = 198.93.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 11/100 \"f1-alpha-match-10\" train / dev / test | 81.92 / 78.74 / 78.74.\n",
      "## [BEST epoch], 71 seconds.\n",
      "\n",
      "-- train epoch 12/100, batch 261/261 (100.00%), loss = 221.02.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 12/100 \"f1-alpha-match-10\" train / dev / test | 84.32 / 80.58 / 80.58.\n",
      "## [BEST epoch], 72 seconds.\n",
      "\n",
      "-- train epoch 13/100, batch 261/261 (100.00%), loss = 199.78.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 13/100 \"f1-alpha-match-10\" train / dev / test | 84.21 / 80.75 / 80.75.\n",
      "## [BEST epoch], 72 seconds.\n",
      "\n",
      "-- train epoch 14/100, batch 261/261 (100.00%), loss = 181.75.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 14/100 \"f1-alpha-match-10\" train / dev / test | 83.41 / 80.27 / 80.27.\n",
      "## [no improvement micro-f1 on DEV during the last 1 epochs (best_f1_dev=80.75), 63 seconds].\n",
      "\n",
      "-- train epoch 15/100, batch 261/261 (100.00%), loss = 153.56.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 15/100 \"f1-alpha-match-10\" train / dev / test | 84.70 / 81.14 / 81.14.\n",
      "## [BEST epoch], 71 seconds.\n",
      "\n",
      "-- train epoch 16/100, batch 261/261 (100.00%), loss = 190.08.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 16/100 \"f1-alpha-match-10\" train / dev / test | 85.51 / 82.05 / 82.05.\n",
      "## [BEST epoch], 71 seconds.\n",
      "\n",
      "-- train epoch 17/100, batch 261/261 (100.00%), loss = 179.52.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 17/100 \"f1-alpha-match-10\" train / dev / test | 85.87 / 82.06 / 82.06.\n",
      "## [BEST epoch], 67 seconds.\n",
      "\n",
      "-- train epoch 18/100, batch 261/261 (100.00%), loss = 188.47.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 18/100 \"f1-alpha-match-10\" train / dev / test | 86.33 / 82.51 / 82.51.\n",
      "## [BEST epoch], 71 seconds.\n",
      "\n",
      "-- train epoch 19/100, batch 261/261 (100.00%), loss = 138.68.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 19/100 \"f1-alpha-match-10\" train / dev / test | 86.83 / 82.65 / 82.65.\n",
      "## [BEST epoch], 67 seconds.\n",
      "\n",
      "-- train epoch 20/100, batch 261/261 (100.00%), loss = 152.09.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 20/100 \"f1-alpha-match-10\" train / dev / test | 87.10 / 82.42 / 82.42.\n",
      "## [no improvement micro-f1 on DEV during the last 1 epochs (best_f1_dev=82.65), 72 seconds].\n",
      "\n",
      "-- train epoch 21/100, batch 261/261 (100.00%), loss = 160.41.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 21/100 \"f1-alpha-match-10\" train / dev / test | 87.50 / 82.73 / 82.73.\n",
      "## [BEST epoch], 71 seconds.\n",
      "\n",
      "-- train epoch 22/100, batch 261/261 (100.00%), loss = 171.16.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 22/100 \"f1-alpha-match-10\" train / dev / test | 87.50 / 82.93 / 82.93.\n",
      "## [BEST epoch], 68 seconds.\n",
      "\n",
      "-- train epoch 23/100, batch 261/261 (100.00%), loss = 157.21.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 23/100 \"f1-alpha-match-10\" train / dev / test | 89.01 / 82.67 / 82.67.\n",
      "## [no improvement micro-f1 on DEV during the last 1 epochs (best_f1_dev=82.93), 68 seconds].\n",
      "\n",
      "-- train epoch 24/100, batch 261/261 (100.00%), loss = 148.83.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 24/100 \"f1-alpha-match-10\" train / dev / test | 88.11 / 81.74 / 81.74.\n",
      "## [no improvement micro-f1 on DEV during the last 2 epochs (best_f1_dev=82.93), 69 seconds].\n",
      "\n",
      "-- train epoch 25/100, batch 261/261 (100.00%), loss = 142.88.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 25/100 \"f1-alpha-match-10\" train / dev / test | 89.19 / 83.50 / 83.50.\n",
      "## [BEST epoch], 71 seconds.\n",
      "\n",
      "-- train epoch 26/100, batch 261/261 (100.00%), loss = 129.07.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 26/100 \"f1-alpha-match-10\" train / dev / test | 89.51 / 83.66 / 83.66.\n",
      "## [BEST epoch], 71 seconds.\n",
      "\n",
      "-- train epoch 27/100, batch 261/261 (100.00%), loss = 123.05.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 27/100 \"f1-alpha-match-10\" train / dev / test | 88.88 / 82.74 / 82.74.\n",
      "## [no improvement micro-f1 on DEV during the last 1 epochs (best_f1_dev=83.66), 68 seconds].\n",
      "\n",
      "-- train epoch 28/100, batch 261/261 (100.00%), loss = 122.57.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 28/100 \"f1-alpha-match-10\" train / dev / test | 89.96 / 83.32 / 83.32.\n",
      "## [no improvement micro-f1 on DEV during the last 2 epochs (best_f1_dev=83.66), 62 seconds].\n",
      "\n",
      "-- train epoch 29/100, batch 261/261 (100.00%), loss = 133.82.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 29/100 \"f1-alpha-match-10\" train / dev / test | 89.92 / 83.82 / 83.82.\n",
      "## [BEST epoch], 69 seconds.\n",
      "\n",
      "-- train epoch 30/100, batch 261/261 (100.00%), loss = 123.55.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 30/100 \"f1-alpha-match-10\" train / dev / test | 90.04 / 82.99 / 82.99.\n",
      "## [no improvement micro-f1 on DEV during the last 1 epochs (best_f1_dev=83.82), 64 seconds].\n",
      "\n",
      "-- train epoch 31/100, batch 261/261 (100.00%), loss = 112.52.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 31/100 \"f1-alpha-match-10\" train / dev / test | 90.58 / 83.10 / 83.10.\n",
      "## [no improvement micro-f1 on DEV during the last 2 epochs (best_f1_dev=83.82), 64 seconds].\n",
      "\n",
      "-- train epoch 32/100, batch 261/261 (100.00%), loss = 99.79.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 32/100 \"f1-alpha-match-10\" train / dev / test | 90.62 / 83.30 / 83.30.\n",
      "## [no improvement micro-f1 on DEV during the last 3 epochs (best_f1_dev=83.82), 63 seconds].\n",
      "\n",
      "-- train epoch 33/100, batch 261/261 (100.00%), loss = 121.00.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 33/100 \"f1-alpha-match-10\" train / dev / test | 90.76 / 82.75 / 82.75.\n",
      "## [no improvement micro-f1 on DEV during the last 4 epochs (best_f1_dev=83.82), 66 seconds].\n",
      "\n",
      "-- train epoch 34/100, batch 261/261 (100.00%), loss = 102.97.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 34/100 \"f1-alpha-match-10\" train / dev / test | 91.08 / 82.92 / 82.92.\n",
      "## [no improvement micro-f1 on DEV during the last 5 epochs (best_f1_dev=83.82), 69 seconds].\n",
      "\n",
      "-- train epoch 35/100, batch 261/261 (100.00%), loss = 119.15.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 35/100 \"f1-alpha-match-10\" train / dev / test | 91.61 / 82.79 / 82.79.\n",
      "## [no improvement micro-f1 on DEV during the last 6 epochs (best_f1_dev=83.82), 70 seconds].\n",
      "\n",
      "-- train epoch 36/100, batch 261/261 (100.00%), loss = 110.34.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 36/100 \"f1-alpha-match-10\" train / dev / test | 91.58 / 83.79 / 83.79.\n",
      "## [no improvement micro-f1 on DEV during the last 7 epochs (best_f1_dev=83.82), 69 seconds].\n",
      "\n",
      "-- train epoch 37/100, batch 261/261 (100.00%), loss = 121.83.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 37/100 \"f1-alpha-match-10\" train / dev / test | 91.49 / 82.79 / 82.79.\n",
      "## [no improvement micro-f1 on DEV during the last 8 epochs (best_f1_dev=83.82), 70 seconds].\n",
      "\n",
      "-- train epoch 38/100, batch 261/261 (100.00%), loss = 114.21.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 38/100 \"f1-alpha-match-10\" train / dev / test | 92.35 / 83.30 / 83.30.\n",
      "## [no improvement micro-f1 on DEV during the last 9 epochs (best_f1_dev=83.82), 73 seconds].\n",
      "\n",
      "-- train epoch 39/100, batch 261/261 (100.00%), loss = 117.00.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 39/100 \"f1-alpha-match-10\" train / dev / test | 92.31 / 84.83 / 84.83.\n",
      "## [BEST epoch], 73 seconds.\n",
      "\n",
      "-- train epoch 40/100, batch 261/261 (100.00%), loss = 97.10.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 40/100 \"f1-alpha-match-10\" train / dev / test | 92.69 / 83.19 / 83.19.\n",
      "## [no improvement micro-f1 on DEV during the last 1 epochs (best_f1_dev=84.83), 72 seconds].\n",
      "\n",
      "-- train epoch 41/100, batch 261/261 (100.00%), loss = 94.96.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 41/100 \"f1-alpha-match-10\" train / dev / test | 92.77 / 84.27 / 84.27.\n",
      "## [no improvement micro-f1 on DEV during the last 2 epochs (best_f1_dev=84.83), 67 seconds].\n",
      "\n",
      "-- train epoch 42/100, batch 261/261 (100.00%), loss = 113.93.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 42/100 \"f1-alpha-match-10\" train / dev / test | 92.10 / 82.92 / 82.92.\n",
      "## [no improvement micro-f1 on DEV during the last 3 epochs (best_f1_dev=84.83), 70 seconds].\n",
      "\n",
      "-- train epoch 43/100, batch 261/261 (100.00%), loss = 95.82.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 43/100 \"f1-alpha-match-10\" train / dev / test | 92.90 / 83.62 / 83.62.\n",
      "## [no improvement micro-f1 on DEV during the last 4 epochs (best_f1_dev=84.83), 69 seconds].\n",
      "\n",
      "-- train epoch 44/100, batch 261/261 (100.00%), loss = 96.58.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 44/100 \"f1-alpha-match-10\" train / dev / test | 93.39 / 84.31 / 84.31.\n",
      "## [no improvement micro-f1 on DEV during the last 5 epochs (best_f1_dev=84.83), 68 seconds].\n",
      "\n",
      "-- train epoch 45/100, batch 261/261 (100.00%), loss = 96.02.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 45/100 \"f1-alpha-match-10\" train / dev / test | 93.06 / 83.96 / 83.96.\n",
      "## [no improvement micro-f1 on DEV during the last 6 epochs (best_f1_dev=84.83), 72 seconds].\n",
      "\n",
      "-- train epoch 46/100, batch 261/261 (100.00%), loss = 108.50.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 46/100 \"f1-alpha-match-10\" train / dev / test | 93.27 / 84.47 / 84.47.\n",
      "## [no improvement micro-f1 on DEV during the last 7 epochs (best_f1_dev=84.83), 72 seconds].\n",
      "\n",
      "-- train epoch 47/100, batch 261/261 (100.00%), loss = 106.51.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 47/100 \"f1-alpha-match-10\" train / dev / test | 93.14 / 84.07 / 84.07.\n",
      "## [no improvement micro-f1 on DEV during the last 8 epochs (best_f1_dev=84.83), 72 seconds].\n",
      "\n",
      "-- train epoch 48/100, batch 261/261 (100.00%), loss = 102.06.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 48/100 \"f1-alpha-match-10\" train / dev / test | 93.64 / 84.04 / 84.04.\n",
      "## [no improvement micro-f1 on DEV during the last 9 epochs (best_f1_dev=84.83), 69 seconds].\n",
      "\n",
      "-- train epoch 49/100, batch 261/261 (100.00%), loss = 97.60.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 49/100 \"f1-alpha-match-10\" train / dev / test | 94.11 / 84.24 / 84.24.\n",
      "## [no improvement micro-f1 on DEV during the last 10 epochs (best_f1_dev=84.83), 69 seconds].\n",
      "\n",
      "-- train epoch 50/100, batch 261/261 (100.00%), loss = 92.51.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 50/100 \"f1-alpha-match-10\" train / dev / test | 93.97 / 84.08 / 84.08.\n",
      "## [no improvement micro-f1 on DEV during the last 11 epochs (best_f1_dev=84.83), 67 seconds].\n",
      "\n",
      "-- train epoch 51/100, batch 261/261 (100.00%), loss = 91.43.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 51/100 \"f1-alpha-match-10\" train / dev / test | 94.32 / 85.04 / 85.04.\n",
      "## [BEST epoch], 70 seconds.\n",
      "\n",
      "-- train epoch 52/100, batch 261/261 (100.00%), loss = 88.85.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 52/100 \"f1-alpha-match-10\" train / dev / test | 94.63 / 85.07 / 85.07.\n",
      "## [BEST epoch], 67 seconds.\n",
      "\n",
      "-- train epoch 53/100, batch 261/261 (100.00%), loss = 73.28.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 53/100 \"f1-alpha-match-10\" train / dev / test | 93.51 / 84.07 / 84.07.\n",
      "## [no improvement micro-f1 on DEV during the last 1 epochs (best_f1_dev=85.07), 70 seconds].\n",
      "\n",
      "-- train epoch 54/100, batch 261/261 (100.00%), loss = 94.17.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 54/100 \"f1-alpha-match-10\" train / dev / test | 94.92 / 84.98 / 84.98.\n",
      "## [no improvement micro-f1 on DEV during the last 2 epochs (best_f1_dev=85.07), 73 seconds].\n",
      "\n",
      "-- train epoch 55/100, batch 261/261 (100.00%), loss = 90.98.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 55/100 \"f1-alpha-match-10\" train / dev / test | 94.52 / 84.40 / 84.40.\n",
      "## [no improvement micro-f1 on DEV during the last 3 epochs (best_f1_dev=85.07), 72 seconds].\n",
      "\n",
      "-- train epoch 56/100, batch 261/261 (100.00%), loss = 69.39.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 56/100 \"f1-alpha-match-10\" train / dev / test | 94.66 / 84.66 / 84.66.\n",
      "## [no improvement micro-f1 on DEV during the last 4 epochs (best_f1_dev=85.07), 70 seconds].\n",
      "\n",
      "-- train epoch 57/100, batch 261/261 (100.00%), loss = 81.71.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 57/100 \"f1-alpha-match-10\" train / dev / test | 94.62 / 85.06 / 85.06.\n",
      "## [no improvement micro-f1 on DEV during the last 5 epochs (best_f1_dev=85.07), 70 seconds].\n",
      "\n",
      "-- train epoch 58/100, batch 261/261 (100.00%), loss = 78.84.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 58/100 \"f1-alpha-match-10\" train / dev / test | 94.92 / 83.56 / 83.56.\n",
      "## [no improvement micro-f1 on DEV during the last 6 epochs (best_f1_dev=85.07), 69 seconds].\n",
      "\n",
      "-- train epoch 59/100, batch 261/261 (100.00%), loss = 83.32.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 59/100 \"f1-alpha-match-10\" train / dev / test | 94.87 / 84.47 / 84.47.\n",
      "## [no improvement micro-f1 on DEV during the last 7 epochs (best_f1_dev=85.07), 69 seconds].\n",
      "\n",
      "-- train epoch 60/100, batch 261/261 (100.00%), loss = 82.65.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 60/100 \"f1-alpha-match-10\" train / dev / test | 95.05 / 84.93 / 84.93.\n",
      "## [no improvement micro-f1 on DEV during the last 8 epochs (best_f1_dev=85.07), 70 seconds].\n",
      "\n",
      "-- train epoch 61/100, batch 261/261 (100.00%), loss = 64.26.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 61/100 \"f1-alpha-match-10\" train / dev / test | 95.02 / 84.74 / 84.74.\n",
      "## [no improvement micro-f1 on DEV during the last 9 epochs (best_f1_dev=85.07), 68 seconds].\n",
      "\n",
      "-- train epoch 62/100, batch 261/261 (100.00%), loss = 90.81.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 62/100 \"f1-alpha-match-10\" train / dev / test | 94.59 / 84.58 / 84.58.\n",
      "## [no improvement micro-f1 on DEV during the last 10 epochs (best_f1_dev=85.07), 68 seconds].\n",
      "\n",
      "-- train epoch 63/100, batch 261/261 (100.00%), loss = 77.32.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 63/100 \"f1-alpha-match-10\" train / dev / test | 95.50 / 84.52 / 84.52.\n",
      "## [no improvement micro-f1 on DEV during the last 11 epochs (best_f1_dev=85.07), 69 seconds].\n",
      "\n",
      "-- train epoch 64/100, batch 261/261 (100.00%), loss = 86.82.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 64/100 \"f1-alpha-match-10\" train / dev / test | 95.48 / 84.06 / 84.06.\n",
      "## [no improvement micro-f1 on DEV during the last 12 epochs (best_f1_dev=85.07), 69 seconds].\n",
      "\n",
      "-- train epoch 65/100, batch 261/261 (100.00%), loss = 65.77.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 65/100 \"f1-alpha-match-10\" train / dev / test | 95.64 / 84.29 / 84.29.\n",
      "## [no improvement micro-f1 on DEV during the last 13 epochs (best_f1_dev=85.07), 64 seconds].\n",
      "\n",
      "-- train epoch 66/100, batch 261/261 (100.00%), loss = 82.67.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 66/100 \"f1-alpha-match-10\" train / dev / test | 95.49 / 84.61 / 84.61.\n",
      "## [no improvement micro-f1 on DEV during the last 14 epochs (best_f1_dev=85.07), 68 seconds].\n",
      "\n",
      "-- train epoch 67/100, batch 261/261 (100.00%), loss = 78.83.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 67/100 \"f1-alpha-match-10\" train / dev / test | 95.16 / 84.77 / 84.77.\n",
      "## [no improvement micro-f1 on DEV during the last 15 epochs (best_f1_dev=85.07), 69 seconds].\n",
      "\n",
      "-- train epoch 68/100, batch 261/261 (100.00%), loss = 80.57.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 68/100 \"f1-alpha-match-10\" train / dev / test | 95.31 / 84.56 / 84.56.\n",
      "## [no improvement micro-f1 on DEV during the last 16 epochs (best_f1_dev=85.07), 64 seconds].\n",
      "\n",
      "-- train epoch 69/100, batch 261/261 (100.00%), loss = 72.96.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 69/100 \"f1-alpha-match-10\" train / dev / test | 95.56 / 84.60 / 84.60.\n",
      "## [no improvement micro-f1 on DEV during the last 17 epochs (best_f1_dev=85.07), 66 seconds].\n",
      "\n",
      "-- train epoch 70/100, batch 261/261 (100.00%), loss = 79.23.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 70/100 \"f1-alpha-match-10\" train / dev / test | 95.49 / 84.55 / 84.55.\n",
      "## [no improvement micro-f1 on DEV during the last 18 epochs (best_f1_dev=85.07), 69 seconds].\n",
      "\n",
      "-- train epoch 71/100, batch 261/261 (100.00%), loss = 71.18.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 71/100 \"f1-alpha-match-10\" train / dev / test | 95.55 / 84.34 / 84.34.\n",
      "## [no improvement micro-f1 on DEV during the last 19 epochs (best_f1_dev=85.07), 71 seconds].\n",
      "\n",
      "-- train epoch 72/100, batch 261/261 (100.00%), loss = 68.98.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 72/100 \"f1-alpha-match-10\" train / dev / test | 95.71 / 84.57 / 84.57.\n",
      "## [no improvement micro-f1 on DEV during the last 20 epochs (best_f1_dev=85.07), 65 seconds].\n",
      "\n",
      "-- train epoch 73/100, batch 261/261 (100.00%), loss = 63.54.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 73/100 \"f1-alpha-match-10\" train / dev / test | 95.56 / 84.14 / 84.14.\n",
      "## [no improvement micro-f1 on DEV during the last 21 epochs (best_f1_dev=85.07), 69 seconds].\n",
      "\n",
      "Evaluation\n",
      "\n",
      "batch_size=10\n",
      "char_cnn_filter_num=30\n",
      "char_embeddings_dim=25\n",
      "char_window_size=3\n",
      "check_for_lowercase=True\n",
      "clip_grad=5\n",
      "cross_fold_id=-1\n",
      "cross_folds_num=-1\n",
      "data_io='connl-ner-2003'\n",
      "dataset_sort=False\n",
      "dev='/home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_test.csv'\n",
      "dropout_ratio=0.5\n",
      "emb_delimiter=' '\n",
      "emb_dim=100\n",
      "emb_fn='embeddings/glove.6B.100d.txt'\n",
      "emb_load_all=False\n",
      "epoch_num=100\n",
      "evaluator='f1-alpha-match-10'\n",
      "freeze_char_embeddings=False\n",
      "freeze_word_embeddings=False\n",
      "gpu=1\n",
      "load=None\n",
      "lr=0.001\n",
      "lr_decay=0.05\n",
      "min_epoch_num=50\n",
      "model='BiRNNCRF'\n",
      "momentum=0.9\n",
      "opt='adam'\n",
      "patience=20\n",
      "report_fn='2019_08_22_12-07_55_report.txt'\n",
      "rnn_hidden_dim=200\n",
      "rnn_type='LSTM'\n",
      "save='BiRNNCFR.hdf5'\n",
      "save_best=True\n",
      "seed_num=42\n",
      "test='/home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_test.csv'\n",
      "train='/home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_train.csv'\n",
      "verbose=True\n",
      "word_len=20\n",
      "word_seq_indexer=None\n",
      "\n",
      "         epoch  |     train loss | f1-alpha-match-10-train | f1-alpha-match-10-dev | f1-alpha-match-10-test \n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "              0 |           0.00 |           3.48 |           3.55 |           3.55 \n",
      "              1 |         709.25 |          60.42 |          59.59 |          59.59 \n",
      "              2 |         394.92 |          69.55 |          66.87 |          66.87 \n",
      "              3 |         341.32 |          72.22 |          67.51 |          67.51 \n",
      "              4 |         328.28 |          74.17 |          71.47 |          71.47 \n",
      "              5 |         305.78 |          75.36 |          72.44 |          72.44 \n",
      "              6 |         301.25 |          77.64 |          76.34 |          76.34 \n",
      "              7 |         250.16 |          76.98 |          75.18 |          75.18 \n",
      "              8 |         220.17 |          79.53 |          77.39 |          77.39 \n",
      "              9 |         221.51 |          80.71 |          78.51 |          78.51 \n",
      "             10 |         228.58 |          80.51 |          78.53 |          78.53 \n",
      "             11 |         198.93 |          81.92 |          78.74 |          78.74 \n",
      "             12 |         221.02 |          84.32 |          80.58 |          80.58 \n",
      "             13 |         199.78 |          84.21 |          80.75 |          80.75 \n",
      "             14 |         181.75 |          83.41 |          80.27 |          80.27 \n",
      "             15 |         153.56 |          84.70 |          81.14 |          81.14 \n",
      "             16 |         190.08 |          85.51 |          82.05 |          82.05 \n",
      "             17 |         179.52 |          85.87 |          82.06 |          82.06 \n",
      "             18 |         188.47 |          86.33 |          82.51 |          82.51 \n",
      "             19 |         138.68 |          86.83 |          82.65 |          82.65 \n",
      "             20 |         152.09 |          87.10 |          82.42 |          82.42 \n",
      "             21 |         160.41 |          87.50 |          82.73 |          82.73 \n",
      "             22 |         171.16 |          87.50 |          82.93 |          82.93 \n",
      "             23 |         157.21 |          89.01 |          82.67 |          82.67 \n",
      "             24 |         148.83 |          88.11 |          81.74 |          81.74 \n",
      "             25 |         142.88 |          89.19 |          83.50 |          83.50 \n",
      "             26 |         129.07 |          89.51 |          83.66 |          83.66 \n",
      "             27 |         123.05 |          88.88 |          82.74 |          82.74 \n",
      "             28 |         122.57 |          89.96 |          83.32 |          83.32 \n",
      "             29 |         133.82 |          89.92 |          83.82 |          83.82 \n",
      "             30 |         123.55 |          90.04 |          82.99 |          82.99 \n",
      "             31 |         112.52 |          90.58 |          83.10 |          83.10 \n",
      "             32 |          99.79 |          90.62 |          83.30 |          83.30 \n",
      "             33 |         121.00 |          90.76 |          82.75 |          82.75 \n",
      "             34 |         102.97 |          91.08 |          82.92 |          82.92 \n",
      "             35 |         119.15 |          91.61 |          82.79 |          82.79 \n",
      "             36 |         110.34 |          91.58 |          83.79 |          83.79 \n",
      "             37 |         121.83 |          91.49 |          82.79 |          82.79 \n",
      "             38 |         114.21 |          92.35 |          83.30 |          83.30 \n",
      "             39 |         117.00 |          92.31 |          84.83 |          84.83 \n",
      "             40 |          97.10 |          92.69 |          83.19 |          83.19 \n",
      "             41 |          94.96 |          92.77 |          84.27 |          84.27 \n",
      "             42 |         113.93 |          92.10 |          82.92 |          82.92 \n",
      "             43 |          95.82 |          92.90 |          83.62 |          83.62 \n",
      "             44 |          96.58 |          93.39 |          84.31 |          84.31 \n",
      "             45 |          96.02 |          93.06 |          83.96 |          83.96 \n",
      "             46 |         108.50 |          93.27 |          84.47 |          84.47 \n",
      "             47 |         106.51 |          93.14 |          84.07 |          84.07 \n",
      "             48 |         102.06 |          93.64 |          84.04 |          84.04 \n",
      "             49 |          97.60 |          94.11 |          84.24 |          84.24 \n",
      "             50 |          92.51 |          93.97 |          84.08 |          84.08 \n",
      "             51 |          91.43 |          94.32 |          85.04 |          85.04 \n",
      "             52 |          88.85 |          94.63 |          85.07 |          85.07 \n",
      "             53 |          73.28 |          93.51 |          84.07 |          84.07 \n",
      "             54 |          94.17 |          94.92 |          84.98 |          84.98 \n",
      "             55 |          90.98 |          94.52 |          84.40 |          84.40 \n",
      "             56 |          69.39 |          94.66 |          84.66 |          84.66 \n",
      "             57 |          81.71 |          94.62 |          85.06 |          85.06 \n",
      "             58 |          78.84 |          94.92 |          83.56 |          83.56 \n",
      "             59 |          83.32 |          94.87 |          84.47 |          84.47 \n",
      "             60 |          82.65 |          95.05 |          84.93 |          84.93 \n",
      "             61 |          64.26 |          95.02 |          84.74 |          84.74 \n",
      "             62 |          90.81 |          94.59 |          84.58 |          84.58 \n",
      "             63 |          77.32 |          95.50 |          84.52 |          84.52 \n",
      "             64 |          86.82 |          95.48 |          84.06 |          84.06 \n",
      "             65 |          65.77 |          95.64 |          84.29 |          84.29 \n",
      "             66 |          82.67 |          95.49 |          84.61 |          84.61 \n",
      "             67 |          78.83 |          95.16 |          84.77 |          84.77 \n",
      "             68 |          80.57 |          95.31 |          84.56 |          84.56 \n",
      "             69 |          72.96 |          95.56 |          84.60 |          84.60 \n",
      "             70 |          79.23 |          95.49 |          84.55 |          84.55 \n",
      "             71 |          71.18 |          95.55 |          84.34 |          84.34 \n",
      "             72 |          68.98 |          95.71 |          84.57 |          84.57 \n",
      "             73 |          63.54 |          95.56 |          84.14 |          84.14 \n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Final eval on test, \"save best\", best epoch on dev 52, f1-alpha-match-10, test = 85.07)\n",
      "--------------------------------------------------------------------------------------------------------------*** f1 alpha match, alpha = 1.0\n",
      "*** f1 = 85.07, precision = 87.37, recall = 82.89\n",
      "*** TP = 1114, FP = 161, FN = 230\n",
      "Input arguments:\n",
      "python3 main.py --train /home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_train.csv --dev /home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_test.csv --test /home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_dev.csv --data-io connl-ner-2003 --evaluator f1-alpha-match-10 --model BiRNNCRF --opt adam --lr 0.001 --save-best yes --patience 20 --rnn-hidden-dim 200 --gpu 1 --test /home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_test.csv --save BiRNNCFR.hdf5\n",
      "\n",
      "85.0706\n"
     ]
    }
   ],
   "source": [
    "! python3 main.py --train \"/home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_train.csv\" --dev \"/home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_test.csv\" --test \"/home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_dev.csv\" --data-io connl-ner-2003 --evaluator f1-alpha-match-10 --model BiRNNCRF --opt adam --lr 0.001 --save-best yes --patience 20 --rnn-hidden-dim 200 --gpu 1 --test \"/home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_test.csv\" --save \"BiRNNCFR.hdf5\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args train = /home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_train.csv\n",
      "Loading from /home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_train.csv: 2619 samples, 74616 words.\n",
      "Loading from /home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_dev.csv: 350 samples, 10092 words.\n",
      "Loading from /home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_test.csv: 523 samples, 14728 words.\n",
      "DatasetsBank: len(unique_words_list) = 7143 unique words.\n",
      "DatasetsBank: len(unique_words_list) = 7600 unique words.\n",
      "DatasetsBank: len(unique_words_list) = 8167 unique words.\n",
      "\n",
      "load_vocabulary_from_tag_sequences:\n",
      " -- class_num = 7\n",
      " -- {'<pad>': 0, 'O': 1, 'B-OTHOBJ': 2, 'B-ASPOBJ': 3, 'B-ASP': 4, 'I-ASP': 5, 'I-ASPOBJ': 6, 'I-OTHOBJ': 7}\n",
      "in main\n",
      "True\n",
      "/home/vika/NER_RNN/targer/embeddings/elmo_2x4096_512_2048cnn_2xhighway_5.5B_weights.hdf5\n",
      "/home/vika/NER_RNN/targer/embeddings/elmo_2x4096_512_2048cnn_2xhighway_5.5B_options.json\n",
      "init targer base\n",
      "True\n",
      "/home/vika/NER_RNN/targer/embeddings/elmo_2x4096_512_2048cnn_2xhighway_5.5B_weights.hdf5\n",
      "/home/vika/NER_RNN/targer/embeddings/elmo_2x4096_512_2048cnn_2xhighway_5.5B_options.json\n",
      "elmo is initiated\n",
      "init targer BiRNNCNNCRF\n",
      "True\n",
      "/home/vika/NER_RNN/targer/embeddings/elmo_2x4096_512_2048cnn_2xhighway_5.5B_weights.hdf5\n",
      "/home/vika/NER_RNN/targer/embeddings/elmo_2x4096_512_2048cnn_2xhighway_5.5B_options.json\n",
      "Empirical transition matrix from the train dataset:\n",
      "               <pad>         O  B-OTHOBJ  B-ASPOBJ     B-ASP     I-ASP  I-ASPOBJ  I-OTHOBJ     <sos>\n",
      "\n",
      "     <pad>       0.0       0.0       0.0       0.0       0.0       0.0       0.0       0.0       0.0\n",
      "         O       0.0   58639.0    2722.0    2863.0     792.0     165.0      22.0      21.0    2226.0\n",
      "  B-OTHOBJ       0.0    2713.0       0.0       1.0       3.0       1.0       0.0       0.0      47.0\n",
      "  B-ASPOBJ       0.0    2560.0       8.0       0.0       4.0       3.0       0.0       0.0     341.0\n",
      "     B-ASP       0.0     919.0      14.0      28.0       0.0       0.0       0.0       0.0       5.0\n",
      "     I-ASP       0.0       0.0       0.0       2.0     167.0     307.0       0.0       0.0       0.0\n",
      "  I-ASPOBJ       0.0       0.0       0.0      22.0       0.0       0.0       0.0       0.0       0.0\n",
      "  I-OTHOBJ       0.0       0.0      21.0       0.0       0.0       0.0       0.0       0.0       0.0\n",
      "     <sos>       0.0       0.0       0.0       0.0       0.0       0.0       0.0       0.0       0.0\n",
      "\n",
      "Initialized transition matrix:\n",
      "               <pad>         O  B-OTHOBJ  B-ASPOBJ     B-ASP     I-ASP  I-ASPOBJ  I-OTHOBJ     <sos>\n",
      "\n",
      "     <pad>   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0\n",
      "         O   -9999.0      -1.0      -0.9      -1.1      -1.0      -1.1      -1.1      -1.0      -1.0\n",
      "  B-OTHOBJ   -9999.0      -1.0   -9999.0      -0.8      -1.1      -1.1   -9999.0   -9999.0      -1.1\n",
      "  B-ASPOBJ   -9999.0      -1.0      -1.0   -9999.0      -1.2      -0.9   -9999.0   -9999.0      -0.9\n",
      "     B-ASP   -9999.0      -1.0      -0.8      -1.1   -9999.0   -9999.0   -9999.0   -9999.0      -1.0\n",
      "     I-ASP   -9999.0   -9999.0   -9999.0      -1.1      -1.0      -0.9   -9999.0   -9999.0   -9999.0\n",
      "  I-ASPOBJ   -9999.0   -9999.0   -9999.0      -0.9   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0\n",
      "  I-OTHOBJ   -9999.0   -9999.0      -0.9   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0\n",
      "     <sos>   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0\n",
      "\n",
      "Start training...\n",
      "\n",
      "\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 0/50 \"f1-alpha-match-10\" train / dev / test | 4.90 / 4.60 / 4.71.\n",
      "## [BEST epoch], 18 seconds.\n",
      "\n",
      "-- train epoch 1/50, batch 261/261 (100.00%), loss = 481.85.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 1/50 \"f1-alpha-match-10\" train / dev / test | 59.00 / 55.35 / 57.57.\n",
      "## [BEST epoch], 105 seconds.\n",
      "\n",
      "-- train epoch 2/50, batch 261/261 (100.00%), loss = 295.73.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 2/50 \"f1-alpha-match-10\" train / dev / test | 62.07 / 57.16 / 60.13.\n",
      "## [BEST epoch], 102 seconds.\n",
      "\n",
      "-- train epoch 3/50, batch 261/261 (100.00%), loss = 269.04.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 3/50 \"f1-alpha-match-10\" train / dev / test | 68.30 / 64.60 / 67.97.\n",
      "## [BEST epoch], 105 seconds.\n",
      "\n",
      "-- train epoch 4/50, batch 261/261 (100.00%), loss = 251.46.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 4/50 \"f1-alpha-match-10\" train / dev / test | 68.73 / 61.71 / 64.08.\n",
      "## [no improvement micro-f1 on DEV during the last 1 epochs (best_f1_dev=64.60), 103 seconds].\n",
      "\n",
      "-- train epoch 5/50, batch 261/261 (100.00%), loss = 236.51.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 5/50 \"f1-alpha-match-10\" train / dev / test | 72.35 / 67.72 / 67.84.\n",
      "## [BEST epoch], 106 seconds.\n",
      "\n",
      "-- train epoch 6/50, batch 261/261 (100.00%), loss = 199.35.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 6/50 \"f1-alpha-match-10\" train / dev / test | 76.23 / 70.89 / 73.64.\n",
      "## [BEST epoch], 102 seconds.\n",
      "\n",
      "-- train epoch 7/50, batch 261/261 (100.00%), loss = 191.80.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 7/50 \"f1-alpha-match-10\" train / dev / test | 77.89 / 71.71 / 73.26.\n",
      "## [BEST epoch], 105 seconds.\n",
      "\n",
      "-- train epoch 8/50, batch 261/261 (100.00%), loss = 194.80.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 8/50 \"f1-alpha-match-10\" train / dev / test | 80.15 / 72.80 / 74.81.\n",
      "## [BEST epoch], 105 seconds.\n",
      "\n",
      "-- train epoch 9/50, batch 261/261 (100.00%), loss = 182.43.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 9/50 \"f1-alpha-match-10\" train / dev / test | 82.59 / 75.04 / 76.26.\n",
      "## [BEST epoch], 103 seconds.\n",
      "\n",
      "-- train epoch 10/50, batch 261/261 (100.00%), loss = 161.46.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 10/50 \"f1-alpha-match-10\" train / dev / test | 81.40 / 74.15 / 76.13.\n",
      "## [no improvement micro-f1 on DEV during the last 1 epochs (best_f1_dev=75.04), 103 seconds].\n",
      "\n",
      "-- train epoch 11/50, batch 261/261 (100.00%), loss = 155.96.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 11/50 \"f1-alpha-match-10\" train / dev / test | 83.04 / 75.93 / 75.98.\n",
      "## [BEST epoch], 102 seconds.\n",
      "\n",
      "-- train epoch 12/50, batch 261/261 (100.00%), loss = 133.37.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 12/50 \"f1-alpha-match-10\" train / dev / test | 84.07 / 76.17 / 77.15.\n",
      "## [BEST epoch], 105 seconds.\n",
      "\n",
      "-- train epoch 13/50, batch 261/261 (100.00%), loss = 132.98.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 13/50 \"f1-alpha-match-10\" train / dev / test | 85.94 / 79.86 / 78.64.\n",
      "## [BEST epoch], 101 seconds.\n",
      "\n",
      "-- train epoch 14/50, batch 261/261 (100.00%), loss = 126.90.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 14/50 \"f1-alpha-match-10\" train / dev / test | 85.51 / 79.51 / 78.18.\n",
      "## [no improvement micro-f1 on DEV during the last 1 epochs (best_f1_dev=79.86), 101 seconds].\n",
      "\n",
      "-- train epoch 15/50, batch 261/261 (100.00%), loss = 121.69.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 15/50 \"f1-alpha-match-10\" train / dev / test | 86.60 / 79.70 / 80.15.\n",
      "## [no improvement micro-f1 on DEV during the last 2 epochs (best_f1_dev=79.86), 104 seconds].\n",
      "\n",
      "-- train epoch 16/50, batch 261/261 (100.00%), loss = 138.85.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 16/50 \"f1-alpha-match-10\" train / dev / test | 88.35 / 80.11 / 80.03.\n",
      "## [BEST epoch], 105 seconds.\n",
      "\n",
      "-- train epoch 17/50, batch 261/261 (100.00%), loss = 122.46.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 17/50 \"f1-alpha-match-10\" train / dev / test | 88.16 / 79.81 / 79.69.\n",
      "## [no improvement micro-f1 on DEV during the last 1 epochs (best_f1_dev=80.11), 102 seconds].\n",
      "\n",
      "-- train epoch 18/50, batch 261/261 (100.00%), loss = 131.72.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 18/50 \"f1-alpha-match-10\" train / dev / test | 87.68 / 78.88 / 80.22.\n",
      "## [no improvement micro-f1 on DEV during the last 2 epochs (best_f1_dev=80.11), 100 seconds].\n",
      "\n",
      "-- train epoch 19/50, batch 261/261 (100.00%), loss = 88.13.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 19/50 \"f1-alpha-match-10\" train / dev / test | 89.13 / 79.72 / 81.47.\n",
      "## [no improvement micro-f1 on DEV during the last 3 epochs (best_f1_dev=80.11), 107 seconds].\n",
      "\n",
      "-- train epoch 20/50, batch 261/261 (100.00%), loss = 87.74.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 20/50 \"f1-alpha-match-10\" train / dev / test | 90.42 / 80.82 / 81.98.\n",
      "## [BEST epoch], 107 seconds.\n",
      "\n",
      "-- train epoch 21/50, batch 261/261 (100.00%), loss = 104.64.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 21/50 \"f1-alpha-match-10\" train / dev / test | 90.00 / 79.43 / 79.02.\n",
      "## [no improvement micro-f1 on DEV during the last 1 epochs (best_f1_dev=80.82), 98 seconds].\n",
      "\n",
      "-- train epoch 22/50, batch 261/261 (100.00%), loss = 122.44.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 22/50 \"f1-alpha-match-10\" train / dev / test | 90.90 / 81.32 / 82.05.\n",
      "## [BEST epoch], 103 seconds.\n",
      "\n",
      "-- train epoch 23/50, batch 261/261 (100.00%), loss = 105.05.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 23/50 \"f1-alpha-match-10\" train / dev / test | 91.73 / 81.25 / 82.00.\n",
      "## [no improvement micro-f1 on DEV during the last 1 epochs (best_f1_dev=81.32), 99 seconds].\n",
      "\n",
      "-- train epoch 24/50, batch 261/261 (100.00%), loss = 94.19.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 24/50 \"f1-alpha-match-10\" train / dev / test | 91.42 / 80.27 / 80.49.\n",
      "## [no improvement micro-f1 on DEV during the last 2 epochs (best_f1_dev=81.32), 101 seconds].\n",
      "\n",
      "-- train epoch 25/50, batch 261/261 (100.00%), loss = 90.64.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 25/50 \"f1-alpha-match-10\" train / dev / test | 92.18 / 81.37 / 81.72.\n",
      "## [BEST epoch], 104 seconds.\n",
      "\n",
      "-- train epoch 26/50, batch 261/261 (100.00%), loss = 74.65.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 26/50 \"f1-alpha-match-10\" train / dev / test | 92.34 / 81.23 / 82.26.\n",
      "## [no improvement micro-f1 on DEV during the last 1 epochs (best_f1_dev=81.37), 101 seconds].\n",
      "\n",
      "-- train epoch 27/50, batch 261/261 (100.00%), loss = 86.79.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 27/50 \"f1-alpha-match-10\" train / dev / test | 92.77 / 81.65 / 81.60.\n",
      "## [BEST epoch], 99 seconds.\n",
      "\n",
      "-- train epoch 28/50, batch 261/261 (100.00%), loss = 82.92.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 28/50 \"f1-alpha-match-10\" train / dev / test | 92.88 / 81.36 / 82.40.\n",
      "## [no improvement micro-f1 on DEV during the last 1 epochs (best_f1_dev=81.65), 100 seconds].\n",
      "\n",
      "-- train epoch 29/50, batch 261/261 (100.00%), loss = 85.63.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 29/50 \"f1-alpha-match-10\" train / dev / test | 93.46 / 82.59 / 83.06.\n",
      "## [BEST epoch], 99 seconds.\n",
      "\n",
      "-- train epoch 30/50, batch 261/261 (100.00%), loss = 77.07.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 30/50 \"f1-alpha-match-10\" train / dev / test | 93.13 / 81.27 / 81.97.\n",
      "## [no improvement micro-f1 on DEV during the last 1 epochs (best_f1_dev=82.59), 106 seconds].\n",
      "\n",
      "-- train epoch 31/50, batch 261/261 (100.00%), loss = 68.34.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 31/50 \"f1-alpha-match-10\" train / dev / test | 94.18 / 82.32 / 82.26.\n",
      "## [no improvement micro-f1 on DEV during the last 2 epochs (best_f1_dev=82.59), 104 seconds].\n",
      "\n",
      "-- train epoch 32/50, batch 261/261 (100.00%), loss = 47.47.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 32/50 \"f1-alpha-match-10\" train / dev / test | 94.13 / 82.28 / 83.40.\n",
      "## [no improvement micro-f1 on DEV during the last 3 epochs (best_f1_dev=82.59), 106 seconds].\n",
      "\n",
      "-- train epoch 33/50, batch 261/261 (100.00%), loss = 63.96.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 33/50 \"f1-alpha-match-10\" train / dev / test | 93.06 / 80.52 / 81.88.\n",
      "## [no improvement micro-f1 on DEV during the last 4 epochs (best_f1_dev=82.59), 96 seconds].\n",
      "\n",
      "-- train epoch 34/50, batch 261/261 (100.00%), loss = 52.10.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 34/50 \"f1-alpha-match-10\" train / dev / test | 94.05 / 81.69 / 82.91.\n",
      "## [no improvement micro-f1 on DEV during the last 5 epochs (best_f1_dev=82.59), 99 seconds].\n",
      "\n",
      "-- train epoch 35/50, batch 261/261 (100.00%), loss = 73.22.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 35/50 \"f1-alpha-match-10\" train / dev / test | 94.47 / 81.35 / 83.31.\n",
      "## [no improvement micro-f1 on DEV during the last 6 epochs (best_f1_dev=82.59), 101 seconds].\n",
      "\n",
      "-- train epoch 36/50, batch 261/261 (100.00%), loss = 60.37.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 36/50 \"f1-alpha-match-10\" train / dev / test | 94.69 / 82.40 / 83.21.\n",
      "## [no improvement micro-f1 on DEV during the last 7 epochs (best_f1_dev=82.59), 101 seconds].\n",
      "\n",
      "-- train epoch 37/50, batch 71/261 (27.00%), loss = 10.78."
     ]
    }
   ],
   "source": [
    "! python3 main.py --train \"/home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_train.csv\" --dev \"/home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_dev.csv\" --data-io connl-ner-2003 --evaluator f1-alpha-match-10 --opt adam --lr 0.001 --save-best yes --patience 20 --rnn-hidden-dim 200 --gpu 1 --test \"/home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_test.csv\" --epoch-num 50 --isElmo True --save \"regular_elmo.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args train = /home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_train.csv\n",
      "Loading from /home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_train.csv: 2619 samples, 74616 words.\n",
      "Loading from /home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_dev.csv: 350 samples, 10092 words.\n",
      "Loading from /home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_qw_new.csv: 63 samples, 322 words.\n",
      "DatasetsBank: len(unique_words_list) = 7143 unique words.\n",
      "DatasetsBank: len(unique_words_list) = 7600 unique words.\n",
      "DatasetsBank: len(unique_words_list) = 7604 unique words.\n",
      "\n",
      "load_vocabulary_from_tag_sequences:\n",
      " -- class_num = 7\n",
      " -- {'<pad>': 0, 'O': 1, 'B-OTHOBJ': 2, 'B-ASPOBJ': 3, 'B-ASP': 4, 'I-ASP': 5, 'I-ASPOBJ': 6, 'I-OTHOBJ': 7}\n",
      "in main\n",
      "True\n",
      "/home/vika/NER_RNN/targer/embeddings/elmo_2x4096_512_2048cnn_2xhighway_5.5B_weights.hdf5\n",
      "/home/vika/NER_RNN/targer/embeddings/elmo_2x4096_512_2048cnn_2xhighway_5.5B_options.json\n",
      "init targer base\n",
      "True\n",
      "/home/vika/NER_RNN/targer/embeddings/elmo_2x4096_512_2048cnn_2xhighway_5.5B_weights.hdf5\n",
      "/home/vika/NER_RNN/targer/embeddings/elmo_2x4096_512_2048cnn_2xhighway_5.5B_options.json\n",
      "elmo is initiated\n",
      "init targer BiRNNCNNCRF\n",
      "True\n",
      "/home/vika/NER_RNN/targer/embeddings/elmo_2x4096_512_2048cnn_2xhighway_5.5B_weights.hdf5\n",
      "/home/vika/NER_RNN/targer/embeddings/elmo_2x4096_512_2048cnn_2xhighway_5.5B_options.json\n",
      "Empirical transition matrix from the train dataset:\n",
      "               <pad>         O  B-OTHOBJ  B-ASPOBJ     B-ASP     I-ASP  I-ASPOBJ  I-OTHOBJ     <sos>\n",
      "\n",
      "     <pad>       0.0       0.0       0.0       0.0       0.0       0.0       0.0       0.0       0.0\n",
      "         O       0.0   58639.0    2722.0    2863.0     792.0     165.0      22.0      21.0    2226.0\n",
      "  B-OTHOBJ       0.0    2713.0       0.0       1.0       3.0       1.0       0.0       0.0      47.0\n",
      "  B-ASPOBJ       0.0    2560.0       8.0       0.0       4.0       3.0       0.0       0.0     341.0\n",
      "     B-ASP       0.0     919.0      14.0      28.0       0.0       0.0       0.0       0.0       5.0\n",
      "     I-ASP       0.0       0.0       0.0       2.0     167.0     307.0       0.0       0.0       0.0\n",
      "  I-ASPOBJ       0.0       0.0       0.0      22.0       0.0       0.0       0.0       0.0       0.0\n",
      "  I-OTHOBJ       0.0       0.0      21.0       0.0       0.0       0.0       0.0       0.0       0.0\n",
      "     <sos>       0.0       0.0       0.0       0.0       0.0       0.0       0.0       0.0       0.0\n",
      "\n",
      "Initialized transition matrix:\n",
      "               <pad>         O  B-OTHOBJ  B-ASPOBJ     B-ASP     I-ASP  I-ASPOBJ  I-OTHOBJ     <sos>\n",
      "\n",
      "     <pad>   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0\n",
      "         O   -9999.0      -1.0      -0.9      -1.1      -1.0      -1.1      -1.1      -1.0      -1.0\n",
      "  B-OTHOBJ   -9999.0      -1.0   -9999.0      -0.8      -1.1      -1.1   -9999.0   -9999.0      -1.1\n",
      "  B-ASPOBJ   -9999.0      -1.0      -1.0   -9999.0      -1.2      -0.9   -9999.0   -9999.0      -0.9\n",
      "     B-ASP   -9999.0      -1.0      -0.8      -1.1   -9999.0   -9999.0   -9999.0   -9999.0      -1.0\n",
      "     I-ASP   -9999.0   -9999.0   -9999.0      -1.1      -1.0      -0.9   -9999.0   -9999.0   -9999.0\n",
      "  I-ASPOBJ   -9999.0   -9999.0   -9999.0      -0.9   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0\n",
      "  I-OTHOBJ   -9999.0   -9999.0      -0.9   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0\n",
      "     <sos>   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0\n",
      "\n",
      "Start training...\n",
      "\n",
      "\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 0/50 \"f1-alpha-match-10\" train / dev / test | 4.90 / 4.60 / 12.08.\n",
      "## [BEST epoch], 16 seconds.\n",
      "\n",
      "-- train epoch 1/50, batch 261/261 (100.00%), loss = 482.29.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 1/50 \"f1-alpha-match-10\" train / dev / test | 60.09 / 58.18 / 44.87.\n",
      "## [BEST epoch], 104 seconds.\n",
      "\n",
      "-- train epoch 2/50, batch 261/261 (100.00%), loss = 297.58.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 2/50 \"f1-alpha-match-10\" train / dev / test | 63.26 / 58.87 / 42.55.\n",
      "## [BEST epoch], 103 seconds.\n",
      "\n",
      "-- train epoch 3/50, batch 261/261 (100.00%), loss = 271.47.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 3/50 \"f1-alpha-match-10\" train / dev / test | 68.38 / 64.74 / 46.43.\n",
      "## [BEST epoch], 102 seconds.\n",
      "\n",
      "-- train epoch 4/50, batch 261/261 (100.00%), loss = 246.57.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 4/50 \"f1-alpha-match-10\" train / dev / test | 70.43 / 64.01 / 34.43.\n",
      "## [no improvement micro-f1 on DEV during the last 1 epochs (best_f1_dev=64.74), 106 seconds].\n",
      "\n",
      "-- train epoch 5/50, batch 261/261 (100.00%), loss = 234.79.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 5/50 \"f1-alpha-match-10\" train / dev / test | 72.03 / 67.81 / 45.49.\n",
      "## [BEST epoch], 101 seconds.\n",
      "\n",
      "-- train epoch 6/50, batch 261/261 (100.00%), loss = 197.57.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 6/50 \"f1-alpha-match-10\" train / dev / test | 76.58 / 70.35 / 45.19.\n",
      "## [BEST epoch], 96 seconds.\n",
      "\n",
      "-- train epoch 7/50, batch 261/261 (100.00%), loss = 182.52.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 7/50 \"f1-alpha-match-10\" train / dev / test | 77.64 / 70.21 / 45.28.\n",
      "## [no improvement micro-f1 on DEV during the last 1 epochs (best_f1_dev=70.35), 99 seconds].\n",
      "\n",
      "-- train epoch 8/50, batch 261/261 (100.00%), loss = 193.16.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 8/50 \"f1-alpha-match-10\" train / dev / test | 79.05 / 72.93 / 50.97.\n",
      "## [BEST epoch], 98 seconds.\n",
      "\n",
      "-- train epoch 9/50, batch 261/261 (100.00%), loss = 183.23.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 9/50 \"f1-alpha-match-10\" train / dev / test | 82.60 / 76.35 / 42.69.\n",
      "## [BEST epoch], 102 seconds.\n",
      "\n",
      "-- train epoch 10/50, batch 261/261 (100.00%), loss = 157.00.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 10/50 \"f1-alpha-match-10\" train / dev / test | 81.92 / 74.99 / 42.97.\n",
      "## [no improvement micro-f1 on DEV during the last 1 epochs (best_f1_dev=76.35), 101 seconds].\n",
      "\n",
      "-- train epoch 11/50, batch 261/261 (100.00%), loss = 152.17.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 11/50 \"f1-alpha-match-10\" train / dev / test | 83.08 / 76.47 / 42.80.\n",
      "## [BEST epoch], 106 seconds.\n",
      "\n",
      "-- train epoch 12/50, batch 261/261 (100.00%), loss = 127.66.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 12/50 \"f1-alpha-match-10\" train / dev / test | 83.59 / 76.03 / 40.34.\n",
      "## [no improvement micro-f1 on DEV during the last 1 epochs (best_f1_dev=76.47), 102 seconds].\n",
      "\n",
      "-- train epoch 13/50, batch 261/261 (100.00%), loss = 132.64.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 13/50 \"f1-alpha-match-10\" train / dev / test | 85.58 / 77.95 / 34.75.\n",
      "## [BEST epoch], 99 seconds.\n",
      "\n",
      "-- train epoch 14/50, batch 261/261 (100.00%), loss = 130.28.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 14/50 \"f1-alpha-match-10\" train / dev / test | 84.71 / 78.42 / 48.19.\n",
      "## [BEST epoch], 104 seconds.\n",
      "\n",
      "-- train epoch 15/50, batch 261/261 (100.00%), loss = 120.01.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 15/50 \"f1-alpha-match-10\" train / dev / test | 85.55 / 78.11 / 49.41.\n",
      "## [no improvement micro-f1 on DEV during the last 1 epochs (best_f1_dev=78.42), 103 seconds].\n",
      "\n",
      "-- train epoch 16/50, batch 261/261 (100.00%), loss = 134.78.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 16/50 \"f1-alpha-match-10\" train / dev / test | 88.04 / 79.42 / 46.04.\n",
      "## [BEST epoch], 105 seconds.\n",
      "\n",
      "-- train epoch 17/50, batch 261/261 (100.00%), loss = 124.69.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 17/50 \"f1-alpha-match-10\" train / dev / test | 88.31 / 78.95 / 42.19.\n",
      "## [no improvement micro-f1 on DEV during the last 1 epochs (best_f1_dev=79.42), 97 seconds].\n",
      "\n",
      "-- train epoch 18/50, batch 261/261 (100.00%), loss = 137.27.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 18/50 \"f1-alpha-match-10\" train / dev / test | 88.30 / 80.43 / 38.06.\n",
      "## [BEST epoch], 101 seconds.\n",
      "\n",
      "-- train epoch 19/50, batch 261/261 (100.00%), loss = 88.62.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 19/50 \"f1-alpha-match-10\" train / dev / test | 89.44 / 79.88 / 32.92.\n",
      "## [no improvement micro-f1 on DEV during the last 1 epochs (best_f1_dev=80.43), 102 seconds].\n",
      "\n",
      "-- train epoch 20/50, batch 261/261 (100.00%), loss = 85.18.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 20/50 \"f1-alpha-match-10\" train / dev / test | 90.75 / 81.99 / 41.27.\n",
      "## [BEST epoch], 99 seconds.\n",
      "\n",
      "-- train epoch 21/50, batch 261/261 (100.00%), loss = 107.26.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 21/50 \"f1-alpha-match-10\" train / dev / test | 89.94 / 80.27 / 34.78.\n",
      "## [no improvement micro-f1 on DEV during the last 1 epochs (best_f1_dev=81.99), 103 seconds].\n",
      "\n",
      "-- train epoch 22/50, batch 261/261 (100.00%), loss = 120.54.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 22/50 \"f1-alpha-match-10\" train / dev / test | 90.99 / 81.55 / 39.66.\n",
      "## [no improvement micro-f1 on DEV during the last 2 epochs (best_f1_dev=81.99), 96 seconds].\n",
      "\n",
      "-- train epoch 23/50, batch 261/261 (100.00%), loss = 103.42.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 23/50 \"f1-alpha-match-10\" train / dev / test | 91.88 / 81.28 / 44.36.\n",
      "## [no improvement micro-f1 on DEV during the last 3 epochs (best_f1_dev=81.99), 97 seconds].\n",
      "\n",
      "-- train epoch 24/50, batch 261/261 (100.00%), loss = 94.27.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 24/50 \"f1-alpha-match-10\" train / dev / test | 91.23 / 79.44 / 44.26.\n",
      "## [no improvement micro-f1 on DEV during the last 4 epochs (best_f1_dev=81.99), 96 seconds].\n",
      "\n",
      "-- train epoch 25/50, batch 261/261 (100.00%), loss = 90.57.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 25/50 \"f1-alpha-match-10\" train / dev / test | 92.44 / 80.88 / 48.00.\n",
      "## [no improvement micro-f1 on DEV during the last 5 epochs (best_f1_dev=81.99), 98 seconds].\n",
      "\n",
      "-- train epoch 26/50, batch 261/261 (100.00%), loss = 74.31.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 26/50 \"f1-alpha-match-10\" train / dev / test | 92.19 / 80.35 / 45.45.\n",
      "## [no improvement micro-f1 on DEV during the last 6 epochs (best_f1_dev=81.99), 97 seconds].\n",
      "\n",
      "-- train epoch 27/50, batch 261/261 (100.00%), loss = 79.91.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 27/50 \"f1-alpha-match-10\" train / dev / test | 92.21 / 80.28 / 47.88.\n",
      "## [no improvement micro-f1 on DEV during the last 7 epochs (best_f1_dev=81.99), 96 seconds].\n",
      "\n",
      "-- train epoch 28/50, batch 261/261 (100.00%), loss = 86.83.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 28/50 \"f1-alpha-match-10\" train / dev / test | 93.30 / 81.06 / 43.33.\n",
      "## [no improvement micro-f1 on DEV during the last 8 epochs (best_f1_dev=81.99), 97 seconds].\n",
      "\n",
      "-- train epoch 29/50, batch 261/261 (100.00%), loss = 79.07.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 29/50 \"f1-alpha-match-10\" train / dev / test | 92.80 / 81.12 / 43.65.\n",
      "## [no improvement micro-f1 on DEV during the last 9 epochs (best_f1_dev=81.99), 102 seconds].\n",
      "\n",
      "-- train epoch 30/50, batch 261/261 (100.00%), loss = 79.53.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 30/50 \"f1-alpha-match-10\" train / dev / test | 93.12 / 81.97 / 45.45.\n",
      "## [no improvement micro-f1 on DEV during the last 10 epochs (best_f1_dev=81.99), 99 seconds].\n",
      "\n",
      "-- train epoch 31/50, batch 261/261 (100.00%), loss = 71.21.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 31/50 \"f1-alpha-match-10\" train / dev / test | 94.07 / 82.15 / 41.43.\n",
      "## [BEST epoch], 101 seconds.\n",
      "\n",
      "-- train epoch 32/50, batch 261/261 (100.00%), loss = 47.15.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 32/50 \"f1-alpha-match-10\" train / dev / test | 94.20 / 82.37 / 38.89.\n",
      "## [BEST epoch], 104 seconds.\n",
      "\n",
      "-- train epoch 33/50, batch 261/261 (100.00%), loss = 64.21.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 33/50 \"f1-alpha-match-10\" train / dev / test | 93.03 / 81.21 / 47.19.\n",
      "## [no improvement micro-f1 on DEV during the last 1 epochs (best_f1_dev=82.37), 102 seconds].\n",
      "\n",
      "-- train epoch 34/50, batch 261/261 (100.00%), loss = 51.36.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 34/50 \"f1-alpha-match-10\" train / dev / test | 94.08 / 81.68 / 44.44.\n",
      "## [no improvement micro-f1 on DEV during the last 2 epochs (best_f1_dev=82.37), 97 seconds].\n",
      "\n",
      "-- train epoch 35/50, batch 261/261 (100.00%), loss = 69.79.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 35/50 \"f1-alpha-match-10\" train / dev / test | 94.54 / 81.42 / 46.64.\n",
      "## [no improvement micro-f1 on DEV during the last 3 epochs (best_f1_dev=82.37), 97 seconds].\n",
      "\n",
      "-- train epoch 36/50, batch 261/261 (100.00%), loss = 61.80.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 36/50 \"f1-alpha-match-10\" train / dev / test | 94.93 / 80.98 / 46.88.\n",
      "## [no improvement micro-f1 on DEV during the last 4 epochs (best_f1_dev=82.37), 95 seconds].\n",
      "\n",
      "-- train epoch 37/50, batch 261/261 (100.00%), loss = 77.17.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 37/50 \"f1-alpha-match-10\" train / dev / test | 94.04 / 81.85 / 43.92.\n",
      "## [no improvement micro-f1 on DEV during the last 5 epochs (best_f1_dev=82.37), 97 seconds].\n",
      "\n",
      "-- train epoch 38/50, batch 261/261 (100.00%), loss = 67.29.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 38/50 \"f1-alpha-match-10\" train / dev / test | 94.54 / 81.54 / 41.60.\n",
      "## [no improvement micro-f1 on DEV during the last 6 epochs (best_f1_dev=82.37), 99 seconds].\n",
      "\n",
      "-- train epoch 39/50, batch 261/261 (100.00%), loss = 70.26.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 39/50 \"f1-alpha-match-10\" train / dev / test | 94.75 / 82.11 / 41.32.\n",
      "## [no improvement micro-f1 on DEV during the last 7 epochs (best_f1_dev=82.37), 98 seconds].\n",
      "\n",
      "-- train epoch 40/50, batch 261/261 (100.00%), loss = 61.19.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 40/50 \"f1-alpha-match-10\" train / dev / test | 95.10 / 81.77 / 38.40.\n",
      "## [no improvement micro-f1 on DEV during the last 8 epochs (best_f1_dev=82.37), 101 seconds].\n",
      "\n",
      "-- train epoch 41/50, batch 261/261 (100.00%), loss = 48.37.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 41/50 \"f1-alpha-match-10\" train / dev / test | 95.26 / 81.73 / 38.91.\n",
      "## [no improvement micro-f1 on DEV during the last 9 epochs (best_f1_dev=82.37), 96 seconds].\n",
      "\n",
      "-- train epoch 42/50, batch 261/261 (100.00%), loss = 65.36.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 42/50 \"f1-alpha-match-10\" train / dev / test | 95.11 / 81.01 / 37.45.\n",
      "## [no improvement micro-f1 on DEV during the last 10 epochs (best_f1_dev=82.37), 99 seconds].\n",
      "\n",
      "-- train epoch 43/50, batch 261/261 (100.00%), loss = 44.95.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 43/50 \"f1-alpha-match-10\" train / dev / test | 95.16 / 82.13 / 37.94.\n",
      "## [no improvement micro-f1 on DEV during the last 11 epochs (best_f1_dev=82.37), 97 seconds].\n",
      "\n",
      "-- train epoch 44/50, batch 261/261 (100.00%), loss = 49.34.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 44/50 \"f1-alpha-match-10\" train / dev / test | 95.17 / 81.70 / 42.47.\n",
      "## [no improvement micro-f1 on DEV during the last 12 epochs (best_f1_dev=82.37), 98 seconds].\n",
      "\n",
      "-- train epoch 45/50, batch 261/261 (100.00%), loss = 52.43.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 45/50 \"f1-alpha-match-10\" train / dev / test | 95.61 / 81.37 / 34.24.\n",
      "## [no improvement micro-f1 on DEV during the last 13 epochs (best_f1_dev=82.37), 98 seconds].\n",
      "\n",
      "-- train epoch 46/50, batch 261/261 (100.00%), loss = 70.05.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 46/50 \"f1-alpha-match-10\" train / dev / test | 95.10 / 81.02 / 41.86.\n",
      "## [no improvement micro-f1 on DEV during the last 14 epochs (best_f1_dev=82.37), 99 seconds].\n",
      "\n",
      "-- train epoch 47/50, batch 261/261 (100.00%), loss = 68.13.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 47/50 \"f1-alpha-match-10\" train / dev / test | 95.54 / 82.24 / 36.58.\n",
      "## [no improvement micro-f1 on DEV during the last 15 epochs (best_f1_dev=82.37), 100 seconds].\n",
      "\n",
      "-- train epoch 48/50, batch 261/261 (100.00%), loss = 51.89.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 48/50 \"f1-alpha-match-10\" train / dev / test | 95.67 / 80.87 / 41.70.\n",
      "## [no improvement micro-f1 on DEV during the last 16 epochs (best_f1_dev=82.37), 102 seconds].\n",
      "\n",
      "-- train epoch 49/50, batch 261/261 (100.00%), loss = 51.79.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 49/50 \"f1-alpha-match-10\" train / dev / test | 95.84 / 81.43 / 41.30.\n",
      "## [no improvement micro-f1 on DEV during the last 17 epochs (best_f1_dev=82.37), 102 seconds].\n",
      "\n",
      "-- train epoch 50/50, batch 261/261 (100.00%), loss = 66.44.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 50/50 \"f1-alpha-match-10\" train / dev / test | 95.83 / 81.55 / 46.74.\n",
      "## [no improvement micro-f1 on DEV during the last 18 epochs (best_f1_dev=82.37), 95 seconds].\n",
      "\n",
      "Evaluation\n",
      "\n",
      "batch_size=10\n",
      "char_cnn_filter_num=30\n",
      "char_embeddings_dim=25\n",
      "char_window_size=3\n",
      "check_for_lowercase=True\n",
      "clip_grad=5\n",
      "cross_fold_id=-1\n",
      "cross_folds_num=-1\n",
      "data_io='connl-ner-2003'\n",
      "dataset_sort=False\n",
      "dev='/home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_dev.csv'\n",
      "dropout_ratio=0.5\n",
      "elmo_options='/home/vika/NER_RNN/targer/embeddings/elmo_2x4096_512_2048cnn_2xhighway_5.5B_options.json'\n",
      "elmo_weights='/home/vika/NER_RNN/targer/embeddings/elmo_2x4096_512_2048cnn_2xhighway_5.5B_weights.hdf5'\n",
      "emb_delimiter=' '\n",
      "emb_dim=100\n",
      "emb_fn='embeddings/glove.6B.100d.txt'\n",
      "emb_load_all=False\n",
      "epoch_num=50\n",
      "evaluator='f1-alpha-match-10'\n",
      "freeze_char_embeddings=False\n",
      "freeze_word_embeddings=False\n",
      "gpu=1\n",
      "isElmo=True\n",
      "load=None\n",
      "lr=0.001\n",
      "lr_decay=0.05\n",
      "min_epoch_num=50\n",
      "model='BiRNNCNNCRF'\n",
      "momentum=0.9\n",
      "opt='adam'\n",
      "patience=20\n",
      "report_fn='2019_09_06_05-34_58_report.txt'\n",
      "rnn_hidden_dim=200\n",
      "rnn_type='LSTM'\n",
      "save='new_tagger1.hdf5'\n",
      "save_best=True\n",
      "seed_num=42\n",
      "test='/home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_qw_new.csv'\n",
      "train='/home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_train.csv'\n",
      "verbose=True\n",
      "word_len=20\n",
      "word_seq_indexer=None\n",
      "\n",
      "         epoch  |     train loss | f1-alpha-match-10-train | f1-alpha-match-10-dev | f1-alpha-match-10-test \n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "              0 |           0.00 |           4.90 |           4.60 |          12.08 \n",
      "              1 |         482.29 |          60.09 |          58.18 |          44.87 \n",
      "              2 |         297.58 |          63.26 |          58.87 |          42.55 \n",
      "              3 |         271.47 |          68.38 |          64.74 |          46.43 \n",
      "              4 |         246.57 |          70.43 |          64.01 |          34.43 \n",
      "              5 |         234.79 |          72.03 |          67.81 |          45.49 \n",
      "              6 |         197.57 |          76.58 |          70.35 |          45.19 \n",
      "              7 |         182.52 |          77.64 |          70.21 |          45.28 \n",
      "              8 |         193.16 |          79.05 |          72.93 |          50.97 \n",
      "              9 |         183.23 |          82.60 |          76.35 |          42.69 \n",
      "             10 |         157.00 |          81.92 |          74.99 |          42.97 \n",
      "             11 |         152.17 |          83.08 |          76.47 |          42.80 \n",
      "             12 |         127.66 |          83.59 |          76.03 |          40.34 \n",
      "             13 |         132.64 |          85.58 |          77.95 |          34.75 \n",
      "             14 |         130.28 |          84.71 |          78.42 |          48.19 \n",
      "             15 |         120.01 |          85.55 |          78.11 |          49.41 \n",
      "             16 |         134.78 |          88.04 |          79.42 |          46.04 \n",
      "             17 |         124.69 |          88.31 |          78.95 |          42.19 \n",
      "             18 |         137.27 |          88.30 |          80.43 |          38.06 \n",
      "             19 |          88.62 |          89.44 |          79.88 |          32.92 \n",
      "             20 |          85.18 |          90.75 |          81.99 |          41.27 \n",
      "             21 |         107.26 |          89.94 |          80.27 |          34.78 \n",
      "             22 |         120.54 |          90.99 |          81.55 |          39.66 \n",
      "             23 |         103.42 |          91.88 |          81.28 |          44.36 \n",
      "             24 |          94.27 |          91.23 |          79.44 |          44.26 \n",
      "             25 |          90.57 |          92.44 |          80.88 |          48.00 \n",
      "             26 |          74.31 |          92.19 |          80.35 |          45.45 \n",
      "             27 |          79.91 |          92.21 |          80.28 |          47.88 \n",
      "             28 |          86.83 |          93.30 |          81.06 |          43.33 \n",
      "             29 |          79.07 |          92.80 |          81.12 |          43.65 \n",
      "             30 |          79.53 |          93.12 |          81.97 |          45.45 \n",
      "             31 |          71.21 |          94.07 |          82.15 |          41.43 \n",
      "             32 |          47.15 |          94.20 |          82.37 |          38.89 \n",
      "             33 |          64.21 |          93.03 |          81.21 |          47.19 \n",
      "             34 |          51.36 |          94.08 |          81.68 |          44.44 \n",
      "             35 |          69.79 |          94.54 |          81.42 |          46.64 \n",
      "             36 |          61.80 |          94.93 |          80.98 |          46.88 \n",
      "             37 |          77.17 |          94.04 |          81.85 |          43.92 \n",
      "             38 |          67.29 |          94.54 |          81.54 |          41.60 \n",
      "             39 |          70.26 |          94.75 |          82.11 |          41.32 \n",
      "             40 |          61.19 |          95.10 |          81.77 |          38.40 \n",
      "             41 |          48.37 |          95.26 |          81.73 |          38.91 \n",
      "             42 |          65.36 |          95.11 |          81.01 |          37.45 \n",
      "             43 |          44.95 |          95.16 |          82.13 |          37.94 \n",
      "             44 |          49.34 |          95.17 |          81.70 |          42.47 \n",
      "             45 |          52.43 |          95.61 |          81.37 |          34.24 \n",
      "             46 |          70.05 |          95.10 |          81.02 |          41.86 \n",
      "             47 |          68.13 |          95.54 |          82.24 |          36.58 \n",
      "             48 |          51.89 |          95.67 |          80.87 |          41.70 \n",
      "             49 |          51.79 |          95.84 |          81.43 |          41.30 \n",
      "             50 |          66.44 |          95.83 |          81.55 |          46.74 \n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Final eval on test, \"save best\", best epoch on dev 32, f1-alpha-match-10, test = 38.89)\n",
      "--------------------------------------------------------------------------------------------------------------*** f1 alpha match, alpha = 1.0\n",
      "*** f1 = 38.89, precision = 51.58, recall = 31.21\n",
      "*** TP = 49, FP = 46, FN = 108\n",
      "Input arguments:\n",
      "python3 main.py --train /home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_train.csv --dev /home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_dev.csv --data-io connl-ner-2003 --evaluator f1-alpha-match-10 --opt adam --lr 0.001 --save-best yes --patience 20 --rnn-hidden-dim 200 --gpu 1 --test /home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_qw_new.csv --epoch-num 50 --isElmo True --save new_tagger1.hdf5\n",
      "\n",
      "38.8889\n"
     ]
    }
   ],
   "source": [
    "! python3 main.py --train \"/home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_train.csv\" --dev \"/home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_dev.csv\" --data-io connl-ner-2003 --evaluator f1-alpha-match-10 --opt adam --lr 0.001 --save-best yes --patience 20 --rnn-hidden-dim 200 --gpu 1 --test \"/home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_qw_new.csv\" --epoch-num 50 --isElmo True --save \"new_tagger1.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.modules.elmo import Elmo, batch_to_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/vika/NER_RNN/targer')\n",
    "from src.factories.factory_tagger import TaggerFactory\n",
    "\n",
    "model = TaggerFactory.load(PATH_TO_PRETRAINED + MODEL_NAME)\n",
    "model.cuda(device=1)\n",
    "model.gpu = 1\n",
    "tags = model.predict_tags_from_words(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args train = /home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_train_new.csv\n",
      "Loading from /home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_train_new.csv: 2719 samples, 75117 words.\n",
      "Loading from /home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_dev.csv: 350 samples, 10092 words.\n",
      "Loading from /home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_test_new.csv: 584 samples, 15032 words.\n",
      "DatasetsBank: len(unique_words_list) = 7144 unique words.\n",
      "DatasetsBank: len(unique_words_list) = 7601 unique words.\n",
      "DatasetsBank: len(unique_words_list) = 8171 unique words.\n",
      "\n",
      "load_vocabulary_from_tag_sequences:\n",
      " -- class_num = 8\n",
      " -- {'<pad>': 0, 'tag': 1, 'O': 2, 'B-OTHOBJ': 3, 'B-ASPOBJ': 4, 'B-ASP': 5, 'I-ASP': 6, 'I-ASPOBJ': 7, 'I-OTHOBJ': 8}\n",
      "in main\n",
      "True\n",
      "/home/vika/NER_RNN/targer/embeddings/elmo_2x4096_512_2048cnn_2xhighway_5.5B_weights.hdf5\n",
      "/home/vika/NER_RNN/targer/embeddings/elmo_2x4096_512_2048cnn_2xhighway_5.5B_options.json\n",
      "init targer base\n",
      "True\n",
      "/home/vika/NER_RNN/targer/embeddings/elmo_2x4096_512_2048cnn_2xhighway_5.5B_weights.hdf5\n",
      "/home/vika/NER_RNN/targer/embeddings/elmo_2x4096_512_2048cnn_2xhighway_5.5B_options.json\n",
      "elmo is initiated\n",
      "init targer BiRNNCNNCRF\n",
      "True\n",
      "/home/vika/NER_RNN/targer/embeddings/elmo_2x4096_512_2048cnn_2xhighway_5.5B_weights.hdf5\n",
      "/home/vika/NER_RNN/targer/embeddings/elmo_2x4096_512_2048cnn_2xhighway_5.5B_options.json\n",
      "Empirical transition matrix from the train dataset:\n",
      "               <pad>       tag         O  B-OTHOBJ  B-ASPOBJ     B-ASP     I-ASP  I-ASPOBJ  I-OTHOBJ     <sos>\n",
      "\n",
      "     <pad>       0.0       0.0       0.0       0.0       0.0       0.0       0.0       0.0       0.0       0.0\n",
      "       tag       0.0       0.0       0.0       0.0       0.0       0.0       0.0       0.0       0.0       1.0\n",
      "         O       0.0       1.0   58723.0    2722.0    2947.0     808.0     165.0      22.0      21.0    2307.0\n",
      "  B-OTHOBJ       0.0       0.0    2813.0       0.0       1.0       3.0       1.0       0.0       0.0      47.0\n",
      "  B-ASPOBJ       0.0       0.0    2624.0       8.0       0.0      22.0       3.0       0.0       0.0     359.0\n",
      "     B-ASP       0.0       0.0     937.0      14.0      44.0       0.0       0.0       0.0       0.0       5.0\n",
      "     I-ASP       0.0       0.0       0.0       0.0       2.0     167.0     307.0       0.0       0.0       0.0\n",
      "  I-ASPOBJ       0.0       0.0       0.0       0.0      22.0       0.0       0.0       0.0       0.0       0.0\n",
      "  I-OTHOBJ       0.0       0.0       0.0      21.0       0.0       0.0       0.0       0.0       0.0       0.0\n",
      "     <sos>       0.0       0.0       0.0       0.0       0.0       0.0       0.0       0.0       0.0       0.0\n",
      "\n",
      "Initialized transition matrix:\n",
      "               <pad>       tag         O  B-OTHOBJ  B-ASPOBJ     B-ASP     I-ASP  I-ASPOBJ  I-OTHOBJ     <sos>\n",
      "\n",
      "     <pad>   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0\n",
      "       tag   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0      -0.9\n",
      "         O   -9999.0      -1.1      -1.1      -0.9      -0.9      -0.8      -0.9      -0.9      -1.0      -0.8\n",
      "  B-OTHOBJ   -9999.0   -9999.0      -1.0   -9999.0      -1.1      -1.1      -0.9   -9999.0   -9999.0      -1.2\n",
      "  B-ASPOBJ   -9999.0   -9999.0      -1.0      -0.9   -9999.0      -1.0      -0.9   -9999.0   -9999.0      -1.2\n",
      "     B-ASP   -9999.0   -9999.0      -0.9      -0.9      -1.0   -9999.0   -9999.0   -9999.0   -9999.0      -1.1\n",
      "     I-ASP   -9999.0   -9999.0   -9999.0   -9999.0      -1.2      -1.0      -1.1   -9999.0   -9999.0   -9999.0\n",
      "  I-ASPOBJ   -9999.0   -9999.0   -9999.0   -9999.0      -1.0   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0\n",
      "  I-OTHOBJ   -9999.0   -9999.0   -9999.0      -0.9   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0\n",
      "     <sos>   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0\n",
      "\n",
      "Start training...\n",
      "\n",
      "\n",
      "\n",
      "++ predicting, batch 27/27 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 0/50 \"f1-alpha-match-10\" train / dev / test | 4.39 / 4.55 / 4.49.\n",
      "## [BEST epoch], 19 seconds.\n",
      "\n",
      "-- train epoch 1/50, batch 271/271 (100.00%), loss = 471.46.\n",
      "\n",
      "++ predicting, batch 27/27 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 1/50 \"f1-alpha-match-10\" train / dev / test | 59.43 / 56.88 / 60.68.\n",
      "## [BEST epoch], 111 seconds.\n",
      "\n",
      "-- train epoch 2/50, batch 271/271 (100.00%), loss = 311.63.\n",
      "\n",
      "++ predicting, batch 27/27 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 2/50 \"f1-alpha-match-10\" train / dev / test | 65.54 / 61.71 / 64.25.\n",
      "## [BEST epoch], 107 seconds.\n",
      "\n",
      "-- train epoch 3/50, batch 271/271 (100.00%), loss = 263.07.\n",
      "\n",
      "++ predicting, batch 27/27 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 3/50 \"f1-alpha-match-10\" train / dev / test | 65.42 / 60.86 / 63.47.\n",
      "## [no improvement micro-f1 on DEV during the last 1 epochs (best_f1_dev=61.71), 111 seconds].\n",
      "\n",
      "-- train epoch 4/50, batch 271/271 (100.00%), loss = 241.10.\n",
      "\n",
      "++ predicting, batch 27/27 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 4/50 \"f1-alpha-match-10\" train / dev / test | 72.40 / 64.60 / 68.90.\n",
      "## [BEST epoch], 112 seconds.\n",
      "\n",
      "-- train epoch 5/50, batch 271/271 (100.00%), loss = 226.24.\n",
      "\n",
      "++ predicting, batch 27/27 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 5/50 \"f1-alpha-match-10\" train / dev / test | 76.05 / 69.95 / 74.28.\n",
      "## [BEST epoch], 104 seconds.\n",
      "\n",
      "-- train epoch 6/50, batch 271/271 (100.00%), loss = 213.57.\n",
      "\n",
      "++ predicting, batch 27/27 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 6/50 \"f1-alpha-match-10\" train / dev / test | 77.31 / 70.24 / 74.36.\n",
      "## [BEST epoch], 111 seconds.\n",
      "\n",
      "-- train epoch 7/50, batch 271/271 (100.00%), loss = 169.04.\n",
      "\n",
      "++ predicting, batch 27/27 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 7/50 \"f1-alpha-match-10\" train / dev / test | 79.29 / 72.59 / 77.10.\n",
      "## [BEST epoch], 127 seconds.\n",
      "\n",
      "-- train epoch 8/50, batch 271/271 (100.00%), loss = 170.33.\n",
      "\n",
      "++ predicting, batch 27/27 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 8/50 \"f1-alpha-match-10\" train / dev / test | 77.94 / 71.17 / 73.04.\n",
      "## [no improvement micro-f1 on DEV during the last 1 epochs (best_f1_dev=72.59), 155 seconds].\n",
      "\n",
      "-- train epoch 9/50, batch 271/271 (100.00%), loss = 134.57.\n",
      "\n",
      "++ predicting, batch 27/27 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 9/50 \"f1-alpha-match-10\" train / dev / test | 82.77 / 74.56 / 76.31.\n",
      "## [BEST epoch], 153 seconds.\n",
      "\n",
      "-- train epoch 10/50, batch 271/271 (100.00%), loss = 179.24.\n",
      "\n",
      "++ predicting, batch 27/27 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 10/50 \"f1-alpha-match-10\" train / dev / test | 83.55 / 76.47 / 78.44.\n",
      "## [BEST epoch], 155 seconds.\n",
      "\n",
      "-- train epoch 11/50, batch 271/271 (100.00%), loss = 140.36.\n",
      "\n",
      "++ predicting, batch 27/27 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 11/50 \"f1-alpha-match-10\" train / dev / test | 86.31 / 77.43 / 80.45.\n",
      "## [BEST epoch], 160 seconds.\n",
      "\n",
      "-- train epoch 12/50, batch 271/271 (100.00%), loss = 147.24.\n",
      "\n",
      "++ predicting, batch 27/27 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 12/50 \"f1-alpha-match-10\" train / dev / test | 86.70 / 79.10 / 80.21.\n",
      "## [BEST epoch], 153 seconds.\n",
      "\n",
      "-- train epoch 13/50, batch 271/271 (100.00%), loss = 134.88.\n",
      "\n",
      "++ predicting, batch 27/27 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 13/50 \"f1-alpha-match-10\" train / dev / test | 86.60 / 77.57 / 79.79.\n",
      "## [no improvement micro-f1 on DEV during the last 1 epochs (best_f1_dev=79.10), 155 seconds].\n",
      "\n",
      "-- train epoch 14/50, batch 271/271 (100.00%), loss = 125.42.\n",
      "\n",
      "++ predicting, batch 27/27 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 14/50 \"f1-alpha-match-10\" train / dev / test | 87.39 / 76.45 / 81.97.\n",
      "## [no improvement micro-f1 on DEV during the last 2 epochs (best_f1_dev=79.10), 154 seconds].\n",
      "\n",
      "-- train epoch 15/50, batch 271/271 (100.00%), loss = 110.34.\n",
      "\n",
      "++ predicting, batch 27/27 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 15/50 \"f1-alpha-match-10\" train / dev / test | 87.51 / 76.90 / 80.79.\n",
      "## [no improvement micro-f1 on DEV during the last 3 epochs (best_f1_dev=79.10), 155 seconds].\n",
      "\n",
      "-- train epoch 16/50, batch 271/271 (100.00%), loss = 114.84.\n",
      "\n",
      "++ predicting, batch 27/27 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 16/50 \"f1-alpha-match-10\" train / dev / test | 88.69 / 78.76 / 81.54.\n",
      "## [no improvement micro-f1 on DEV during the last 4 epochs (best_f1_dev=79.10), 153 seconds].\n",
      "\n",
      "-- train epoch 17/50, batch 271/271 (100.00%), loss = 123.46.\n",
      "\n",
      "++ predicting, batch 27/27 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 17/50 \"f1-alpha-match-10\" train / dev / test | 89.21 / 77.54 / 81.22.\n",
      "## [no improvement micro-f1 on DEV during the last 5 epochs (best_f1_dev=79.10), 155 seconds].\n",
      "\n",
      "-- train epoch 18/50, batch 271/271 (100.00%), loss = 105.34.\n",
      "\n",
      "++ predicting, batch 27/27 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 18/50 \"f1-alpha-match-10\" train / dev / test | 90.26 / 78.83 / 82.23.\n",
      "## [no improvement micro-f1 on DEV during the last 6 epochs (best_f1_dev=79.10), 152 seconds].\n",
      "\n",
      "-- train epoch 19/50, batch 271/271 (100.00%), loss = 94.80.\n",
      "\n",
      "++ predicting, batch 27/27 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 19/50 \"f1-alpha-match-10\" train / dev / test | 90.78 / 79.01 / 82.49.\n",
      "## [no improvement micro-f1 on DEV during the last 7 epochs (best_f1_dev=79.10), 154 seconds].\n",
      "\n",
      "-- train epoch 20/50, batch 271/271 (100.00%), loss = 100.66.\n",
      "\n",
      "++ predicting, batch 27/27 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 20/50 \"f1-alpha-match-10\" train / dev / test | 91.18 / 79.14 / 82.98.\n",
      "## [BEST epoch], 159 seconds.\n",
      "\n",
      "-- train epoch 21/50, batch 271/271 (100.00%), loss = 103.85.\n",
      "\n",
      "++ predicting, batch 27/27 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 21/50 \"f1-alpha-match-10\" train / dev / test | 91.58 / 79.06 / 82.96.\n",
      "## [no improvement micro-f1 on DEV during the last 1 epochs (best_f1_dev=79.14), 159 seconds].\n",
      "\n",
      "-- train epoch 22/50, batch 271/271 (100.00%), loss = 94.58.\n",
      "\n",
      "++ predicting, batch 27/27 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 22/50 \"f1-alpha-match-10\" train / dev / test | 92.08 / 80.40 / 82.67.\n",
      "## [BEST epoch], 159 seconds.\n",
      "\n",
      "-- train epoch 23/50, batch 271/271 (100.00%), loss = 79.92.\n",
      "\n",
      "++ predicting, batch 27/27 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 23/50 \"f1-alpha-match-10\" train / dev / test | 92.18 / 80.04 / 82.04.\n",
      "## [no improvement micro-f1 on DEV during the last 1 epochs (best_f1_dev=80.40), 156 seconds].\n",
      "\n",
      "-- train epoch 24/50, batch 271/271 (100.00%), loss = 86.33.\n",
      "\n",
      "++ predicting, batch 27/27 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 24/50 \"f1-alpha-match-10\" train / dev / test | 93.03 / 80.11 / 82.47.\n",
      "## [no improvement micro-f1 on DEV during the last 2 epochs (best_f1_dev=80.40), 151 seconds].\n",
      "\n",
      "-- train epoch 25/50, batch 271/271 (100.00%), loss = 74.16.\n",
      "\n",
      "++ predicting, batch 27/27 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 25/50 \"f1-alpha-match-10\" train / dev / test | 92.42 / 79.60 / 82.39.\n",
      "## [no improvement micro-f1 on DEV during the last 3 epochs (best_f1_dev=80.40), 153 seconds].\n",
      "\n",
      "-- train epoch 26/50, batch 271/271 (100.00%), loss = 71.81.\n",
      "\n",
      "++ predicting, batch 27/27 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 26/50 \"f1-alpha-match-10\" train / dev / test | 92.62 / 80.86 / 82.83.\n",
      "## [BEST epoch], 156 seconds.\n",
      "\n",
      "-- train epoch 27/50, batch 271/271 (100.00%), loss = 59.15.\n",
      "\n",
      "++ predicting, batch 27/27 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 27/50 \"f1-alpha-match-10\" train / dev / test | 93.20 / 81.53 / 83.38.\n",
      "## [BEST epoch], 125 seconds.\n",
      "\n",
      "-- train epoch 28/50, batch 271/271 (100.00%), loss = 68.64.\n",
      "\n",
      "++ predicting, batch 27/27 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 28/50 \"f1-alpha-match-10\" train / dev / test | 93.54 / 80.92 / 83.33.\n",
      "## [no improvement micro-f1 on DEV during the last 1 epochs (best_f1_dev=81.53), 113 seconds].\n",
      "\n",
      "-- train epoch 29/50, batch 271/271 (100.00%), loss = 75.70.\n",
      "\n",
      "++ predicting, batch 27/27 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 29/50 \"f1-alpha-match-10\" train / dev / test | 94.03 / 79.51 / 83.45.\n",
      "## [no improvement micro-f1 on DEV during the last 2 epochs (best_f1_dev=81.53), 145 seconds].\n",
      "\n",
      "-- train epoch 30/50, batch 271/271 (100.00%), loss = 74.57.\n",
      "\n",
      "++ predicting, batch 27/27 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 30/50 \"f1-alpha-match-10\" train / dev / test | 93.99 / 80.29 / 83.44.\n",
      "## [no improvement micro-f1 on DEV during the last 3 epochs (best_f1_dev=81.53), 154 seconds].\n",
      "\n",
      "-- train epoch 31/50, batch 271/271 (100.00%), loss = 69.73.\n",
      "\n",
      "++ predicting, batch 27/27 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 31/50 \"f1-alpha-match-10\" train / dev / test | 94.17 / 79.95 / 83.26.\n",
      "## [no improvement micro-f1 on DEV during the last 4 epochs (best_f1_dev=81.53), 155 seconds].\n",
      "\n",
      "-- train epoch 32/50, batch 271/271 (100.00%), loss = 49.83.\n",
      "\n",
      "++ predicting, batch 27/27 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 32/50 \"f1-alpha-match-10\" train / dev / test | 94.59 / 79.64 / 83.37.\n",
      "## [no improvement micro-f1 on DEV during the last 5 epochs (best_f1_dev=81.53), 155 seconds].\n",
      "\n",
      "-- train epoch 33/50, batch 271/271 (100.00%), loss = 62.78.\n",
      "\n",
      "++ predicting, batch 27/27 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 33/50 \"f1-alpha-match-10\" train / dev / test | 94.39 / 81.25 / 83.60.\n",
      "## [no improvement micro-f1 on DEV during the last 6 epochs (best_f1_dev=81.53), 154 seconds].\n",
      "\n",
      "-- train epoch 34/50, batch 271/271 (100.00%), loss = 66.57.\n",
      "\n",
      "++ predicting, batch 27/27 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 34/50 \"f1-alpha-match-10\" train / dev / test | 94.53 / 80.56 / 84.14.\n",
      "## [no improvement micro-f1 on DEV during the last 7 epochs (best_f1_dev=81.53), 154 seconds].\n",
      "\n",
      "-- train epoch 35/50, batch 271/271 (100.00%), loss = 66.50.\n",
      "\n",
      "++ predicting, batch 27/27 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 35/50 \"f1-alpha-match-10\" train / dev / test | 95.07 / 81.85 / 84.08.\n",
      "## [BEST epoch], 154 seconds.\n",
      "\n",
      "-- train epoch 36/50, batch 271/271 (100.00%), loss = 58.16.\n",
      "\n",
      "++ predicting, batch 27/27 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 36/50 \"f1-alpha-match-10\" train / dev / test | 95.00 / 82.00 / 83.44.\n",
      "## [BEST epoch], 155 seconds.\n",
      "\n",
      "-- train epoch 37/50, batch 271/271 (100.00%), loss = 61.50.\n",
      "\n",
      "++ predicting, batch 27/27 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 37/50 \"f1-alpha-match-10\" train / dev / test | 95.23 / 81.94 / 83.28.\n",
      "## [no improvement micro-f1 on DEV during the last 1 epochs (best_f1_dev=82.00), 154 seconds].\n",
      "\n",
      "-- train epoch 38/50, batch 271/271 (100.00%), loss = 52.78.\n",
      "\n",
      "++ predicting, batch 27/27 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 38/50 \"f1-alpha-match-10\" train / dev / test | 95.31 / 81.44 / 84.11.\n",
      "## [no improvement micro-f1 on DEV during the last 2 epochs (best_f1_dev=82.00), 150 seconds].\n",
      "\n",
      "-- train epoch 39/50, batch 271/271 (100.00%), loss = 60.88.\n",
      "\n",
      "++ predicting, batch 27/27 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 39/50 \"f1-alpha-match-10\" train / dev / test | 95.74 / 81.48 / 83.83.\n",
      "## [no improvement micro-f1 on DEV during the last 3 epochs (best_f1_dev=82.00), 153 seconds].\n",
      "\n",
      "-- train epoch 40/50, batch 271/271 (100.00%), loss = 62.90.\n",
      "\n",
      "++ predicting, batch 27/27 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 40/50 \"f1-alpha-match-10\" train / dev / test | 95.62 / 81.39 / 83.59.\n",
      "## [no improvement micro-f1 on DEV during the last 4 epochs (best_f1_dev=82.00), 153 seconds].\n",
      "\n",
      "-- train epoch 41/50, batch 271/271 (100.00%), loss = 60.31.\n",
      "\n",
      "++ predicting, batch 27/27 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 41/50 \"f1-alpha-match-10\" train / dev / test | 95.92 / 80.92 / 83.96.\n",
      "## [no improvement micro-f1 on DEV during the last 5 epochs (best_f1_dev=82.00), 153 seconds].\n",
      "\n",
      "-- train epoch 42/50, batch 271/271 (100.00%), loss = 38.39.\n",
      "\n",
      "++ predicting, batch 27/27 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 42/50 \"f1-alpha-match-10\" train / dev / test | 95.92 / 82.22 / 84.12.\n",
      "## [BEST epoch], 154 seconds.\n",
      "\n",
      "-- train epoch 43/50, batch 271/271 (100.00%), loss = 50.95.\n",
      "\n",
      "++ predicting, batch 27/27 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 43/50 \"f1-alpha-match-10\" train / dev / test | 95.46 / 80.78 / 83.16.\n",
      "## [no improvement micro-f1 on DEV during the last 1 epochs (best_f1_dev=82.22), 152 seconds].\n",
      "\n",
      "-- train epoch 44/50, batch 271/271 (100.00%), loss = 52.35.\n",
      "\n",
      "++ predicting, batch 27/27 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 44/50 \"f1-alpha-match-10\" train / dev / test | 95.78 / 81.72 / 83.66.\n",
      "## [no improvement micro-f1 on DEV during the last 2 epochs (best_f1_dev=82.22), 158 seconds].\n",
      "\n",
      "-- train epoch 45/50, batch 271/271 (100.00%), loss = 71.44.\n",
      "\n",
      "++ predicting, batch 27/27 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 45/50 \"f1-alpha-match-10\" train / dev / test | 95.57 / 81.92 / 83.27.\n",
      "## [no improvement micro-f1 on DEV during the last 3 epochs (best_f1_dev=82.22), 152 seconds].\n",
      "\n",
      "-- train epoch 46/50, batch 271/271 (100.00%), loss = 39.98.\n",
      "\n",
      "++ predicting, batch 27/27 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 46/50 \"f1-alpha-match-10\" train / dev / test | 95.96 / 81.67 / 83.85.\n",
      "## [no improvement micro-f1 on DEV during the last 4 epochs (best_f1_dev=82.22), 153 seconds].\n",
      "\n",
      "-- train epoch 47/50, batch 271/271 (100.00%), loss = 45.98.\n",
      "\n",
      "++ predicting, batch 27/27 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 47/50 \"f1-alpha-match-10\" train / dev / test | 96.16 / 81.73 / 83.41.\n",
      "## [no improvement micro-f1 on DEV during the last 5 epochs (best_f1_dev=82.22), 153 seconds].\n",
      "\n",
      "-- train epoch 48/50, batch 271/271 (100.00%), loss = 53.98.\n",
      "\n",
      "++ predicting, batch 27/27 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 48/50 \"f1-alpha-match-10\" train / dev / test | 96.17 / 81.69 / 83.71.\n",
      "## [no improvement micro-f1 on DEV during the last 6 epochs (best_f1_dev=82.22), 152 seconds].\n",
      "\n",
      "-- train epoch 49/50, batch 271/271 (100.00%), loss = 51.61.\n",
      "\n",
      "++ predicting, batch 27/27 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 49/50 \"f1-alpha-match-10\" train / dev / test | 95.92 / 80.31 / 83.83.\n",
      "## [no improvement micro-f1 on DEV during the last 7 epochs (best_f1_dev=82.22), 155 seconds].\n",
      "\n",
      "-- train epoch 50/50, batch 271/271 (100.00%), loss = 43.00.\n",
      "\n",
      "++ predicting, batch 27/27 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 50/50 \"f1-alpha-match-10\" train / dev / test | 96.08 / 81.34 / 84.22.\n",
      "## [no improvement micro-f1 on DEV during the last 8 epochs (best_f1_dev=82.22), 147 seconds].\n",
      "\n",
      "Evaluation\n",
      "\n",
      "batch_size=10\n",
      "char_cnn_filter_num=30\n",
      "char_embeddings_dim=25\n",
      "char_window_size=3\n",
      "check_for_lowercase=True\n",
      "clip_grad=5\n",
      "cross_fold_id=-1\n",
      "cross_folds_num=-1\n",
      "data_io='connl-ner-2003'\n",
      "dataset_sort=False\n",
      "dev='/home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_dev.csv'\n",
      "dropout_ratio=0.5\n",
      "elmo_options='/home/vika/NER_RNN/targer/embeddings/elmo_2x4096_512_2048cnn_2xhighway_5.5B_options.json'\n",
      "elmo_weights='/home/vika/NER_RNN/targer/embeddings/elmo_2x4096_512_2048cnn_2xhighway_5.5B_weights.hdf5'\n",
      "emb_delimiter=' '\n",
      "emb_dim=100\n",
      "emb_fn='embeddings/glove.6B.100d.txt'\n",
      "emb_load_all=False\n",
      "epoch_num=50\n",
      "evaluator='f1-alpha-match-10'\n",
      "freeze_char_embeddings=False\n",
      "freeze_word_embeddings=False\n",
      "gpu=1\n",
      "isElmo=True\n",
      "load=None\n",
      "lr=0.001\n",
      "lr_decay=0.05\n",
      "min_epoch_num=50\n",
      "model='BiRNNCNNCRF'\n",
      "momentum=0.9\n",
      "opt='adam'\n",
      "patience=20\n",
      "report_fn='2019_09_16_17-51_34_report.txt'\n",
      "rnn_hidden_dim=200\n",
      "rnn_type='LSTM'\n",
      "save='new_tagger1.hdf5'\n",
      "save_best=True\n",
      "seed_num=42\n",
      "test='/home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_test_new.csv'\n",
      "train='/home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_train_new.csv'\n",
      "verbose=True\n",
      "word_len=20\n",
      "word_seq_indexer=None\n",
      "\n",
      "         epoch  |     train loss | f1-alpha-match-10-train | f1-alpha-match-10-dev | f1-alpha-match-10-test \n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "              0 |           0.00 |           4.39 |           4.55 |           4.49 \n",
      "              1 |         471.46 |          59.43 |          56.88 |          60.68 \n",
      "              2 |         311.63 |          65.54 |          61.71 |          64.25 \n",
      "              3 |         263.07 |          65.42 |          60.86 |          63.47 \n",
      "              4 |         241.10 |          72.40 |          64.60 |          68.90 \n",
      "              5 |         226.24 |          76.05 |          69.95 |          74.28 \n",
      "              6 |         213.57 |          77.31 |          70.24 |          74.36 \n",
      "              7 |         169.04 |          79.29 |          72.59 |          77.10 \n",
      "              8 |         170.33 |          77.94 |          71.17 |          73.04 \n",
      "              9 |         134.57 |          82.77 |          74.56 |          76.31 \n",
      "             10 |         179.24 |          83.55 |          76.47 |          78.44 \n",
      "             11 |         140.36 |          86.31 |          77.43 |          80.45 \n",
      "             12 |         147.24 |          86.70 |          79.10 |          80.21 \n",
      "             13 |         134.88 |          86.60 |          77.57 |          79.79 \n",
      "             14 |         125.42 |          87.39 |          76.45 |          81.97 \n",
      "             15 |         110.34 |          87.51 |          76.90 |          80.79 \n",
      "             16 |         114.84 |          88.69 |          78.76 |          81.54 \n",
      "             17 |         123.46 |          89.21 |          77.54 |          81.22 \n",
      "             18 |         105.34 |          90.26 |          78.83 |          82.23 \n",
      "             19 |          94.80 |          90.78 |          79.01 |          82.49 \n",
      "             20 |         100.66 |          91.18 |          79.14 |          82.98 \n",
      "             21 |         103.85 |          91.58 |          79.06 |          82.96 \n",
      "             22 |          94.58 |          92.08 |          80.40 |          82.67 \n",
      "             23 |          79.92 |          92.18 |          80.04 |          82.04 \n",
      "             24 |          86.33 |          93.03 |          80.11 |          82.47 \n",
      "             25 |          74.16 |          92.42 |          79.60 |          82.39 \n",
      "             26 |          71.81 |          92.62 |          80.86 |          82.83 \n",
      "             27 |          59.15 |          93.20 |          81.53 |          83.38 \n",
      "             28 |          68.64 |          93.54 |          80.92 |          83.33 \n",
      "             29 |          75.70 |          94.03 |          79.51 |          83.45 \n",
      "             30 |          74.57 |          93.99 |          80.29 |          83.44 \n",
      "             31 |          69.73 |          94.17 |          79.95 |          83.26 \n",
      "             32 |          49.83 |          94.59 |          79.64 |          83.37 \n",
      "             33 |          62.78 |          94.39 |          81.25 |          83.60 \n",
      "             34 |          66.57 |          94.53 |          80.56 |          84.14 \n",
      "             35 |          66.50 |          95.07 |          81.85 |          84.08 \n",
      "             36 |          58.16 |          95.00 |          82.00 |          83.44 \n",
      "             37 |          61.50 |          95.23 |          81.94 |          83.28 \n",
      "             38 |          52.78 |          95.31 |          81.44 |          84.11 \n",
      "             39 |          60.88 |          95.74 |          81.48 |          83.83 \n",
      "             40 |          62.90 |          95.62 |          81.39 |          83.59 \n",
      "             41 |          60.31 |          95.92 |          80.92 |          83.96 \n",
      "             42 |          38.39 |          95.92 |          82.22 |          84.12 \n",
      "             43 |          50.95 |          95.46 |          80.78 |          83.16 \n",
      "             44 |          52.35 |          95.78 |          81.72 |          83.66 \n",
      "             45 |          71.44 |          95.57 |          81.92 |          83.27 \n",
      "             46 |          39.98 |          95.96 |          81.67 |          83.85 \n",
      "             47 |          45.98 |          96.16 |          81.73 |          83.41 \n",
      "             48 |          53.98 |          96.17 |          81.69 |          83.71 \n",
      "             49 |          51.61 |          95.92 |          80.31 |          83.83 \n",
      "             50 |          43.00 |          96.08 |          81.34 |          84.22 \n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Final eval on test, \"save best\", best epoch on dev 42, f1-alpha-match-10, test = 84.12)\n",
      "--------------------------------------------------------------------------------------------------------------*** f1 alpha match, alpha = 1.0\n",
      "*** f1 = 84.12, precision = 86.43, recall = 81.94\n",
      "*** TP = 1216, FP = 191, FN = 268\n",
      "Input arguments:\n",
      "python3 main.py --train /home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_train_new.csv --dev /home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_dev.csv --data-io connl-ner-2003 --evaluator f1-alpha-match-10 --opt adam --lr 0.001 --save-best yes --patience 20 --rnn-hidden-dim 200 --gpu 1 --test /home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_test_new.csv --epoch-num 50 --isElmo True --save new_tagger1.hdf5\n",
      "\n",
      "84.1231\n"
     ]
    }
   ],
   "source": [
    "! python3 main.py --train \"/home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_train_new.csv\" --dev \"/home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_dev.csv\" --data-io connl-ner-2003 --evaluator f1-alpha-match-10 --opt adam --lr 0.001 --save-best yes --patience 20 --rnn-hidden-dim 200 --gpu 1 --test \"/home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_test_new.csv\" --epoch-num 50 --isElmo True --save \"new_tagger1.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vika/NER_RNN/targer\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
